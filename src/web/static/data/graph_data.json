{"metaElements": [{"data": {"id": "comm-0", "label": "Community Knowledge Hub", "type": "COMMUNITY", "community": 0, "member_count": 13, "top_members": ["GLOBAL ANSWER", "QUERY-FOCUSED SUMMARIZATI", "ENTITY EXTRACTOR", "COMMUNITY ANSWERS", "KNOWLEDGE GRAPH"], "color": "#e6194b", "size": 120, "pagerank_sum": 0.0278}}, {"data": {"id": "comm-1", "label": "GraphRAG and Related Technologies C", "type": "COMMUNITY", "community": 1, "member_count": 13, "top_members": ["NEBULAGRAPH", "LANGCHAIN", "LLAMAINDEX", "GRAPHRAG", "NEO4J"], "color": "#3cb44b", "size": 120, "pagerank_sum": 0.0535}}, {"data": {"id": "comm-2", "label": "Contributor Community Network", "type": "COMMUNITY", "community": 2, "member_count": 10, "top_members": ["DAVID TITTWORTH", "DOUGLAS ORBAKER", "CHRIS TREVIÑO", "ANDR´ES MORALES ESQUIVEL", "BILLIE RINALDI"], "color": "#4363d8", "size": 98, "pagerank_sum": 0.0085}}, {"data": {"id": "comm-3", "label": "Knowledge Graph Extraction Communit", "type": "COMMUNITY", "community": 3, "member_count": 10, "top_members": ["NAACL-HLT", "OPENAI", "KAU", "YAO ET AL.", "TRAJANOSSKA ET AL."], "color": "#f58231", "size": 98, "pagerank_sum": 0.0122}}, {"data": {"id": "comm-4", "label": "Text Summarization and Stock Market", "type": "COMMUNITY", "community": 4, "member_count": 10, "top_members": ["SS", "TS", "VECTOR RAG (SS)", "COMPREHENSIVENESS", "C3"], "color": "#911eb4", "size": 98, "pagerank_sum": 0.0306}}, {"data": {"id": "comm-5", "label": "Graph Analysis Community Report", "type": "COMMUNITY", "community": 5, "member_count": 8, "top_members": ["APPENDIX E", "CHUNG ET AL.", "EXPERIMENT 1", "APPENDIX F", "EXPERIMENT 2"], "color": "#42d4f4", "size": 83, "pagerank_sum": 0.0114}}, {"data": {"id": "comm-6", "label": "Knowledge Graph Community Analysis", "type": "COMMUNITY", "community": 6, "member_count": 6, "top_members": ["ARXIV", "ETZIONI", "IEEE TRANSACTIONS ON KNOW", "KNOWITALL", "SCIENTIFIC REPORTS"], "color": "#f032e6", "size": 69, "pagerank_sum": 0.0131}}, {"data": {"id": "comm-7", "label": "Knowledge Graph Community Overview", "type": "COMMUNITY", "community": 7, "member_count": 6, "top_members": ["PRIVATE DOCUMENT COLLECTI", "PRIOR QFS METHODS", "EXTERNAL KNOWLEDGE SOURCE", "LARGE LANGUAGE MODELS", "QUERY-FOCUSED SUMMARIZATI"], "color": "#bfef45", "size": 69, "pagerank_sum": 0.0117}}, {"data": {"id": "comm-8", "label": "Example Corp Community Overview", "type": "COMMUNITY", "community": 8, "member_count": 4, "top_members": ["EXAMPLE CORP", "STARTUPXYZ", "JOHN SMITH", "COMUNITY"], "color": "#fabed4", "size": 54, "pagerank_sum": 0.0121}}, {"data": {"id": "comm-9", "label": "Science and Medicine Knowledge Comm", "type": "COMMUNITY", "community": 9, "member_count": 4, "top_members": ["LAW", "MEDICINE", "SCIENCE", "BROWN"], "color": "#469990", "size": 54, "pagerank_sum": 0.0082}}, {"data": {"id": "comm-10", "label": "Knowledge Graph Collaboration Netwo", "type": "COMMUNITY", "community": 10, "member_count": 4, "top_members": ["CANADIAN CONFERENCE ON AR", "GOALY", "KARPUKHIN", "PETRONI"], "color": "#dcbeff", "size": 54, "pagerank_sum": 0.0146}}, {"data": {"id": "comm-11", "label": "Unity March Community", "type": "COMMUNITY", "community": 11, "member_count": 4, "top_members": ["VERDANT OASIS PLAZA", "UNITY MARCH", "HARMONY ASSEMBLY", "TRIBUNE SPOTLIGHT"], "color": "#9A6324", "size": 54, "pagerank_sum": 0.0126}}, {"data": {"id": "comm-12", "label": "Microsoft Research and Strategic Mi", "type": "COMMUNITY", "community": 12, "member_count": 3, "top_members": ["MICROSOFT OFFICE OF THE C", "MICROSOFT STRATEGIC MISSI", "MICROSOFT RESEARCH"], "color": "#fffac8", "size": 47, "pagerank_sum": 0.0092}}, {"data": {"id": "comm-13", "label": "Transformer Models in Summarization", "type": "COMMUNITY", "community": 13, "member_count": 3, "top_members": ["HOQUE", "HUANG", "LASKAR"], "color": "#800000", "size": 47, "pagerank_sum": 0.0079}}, {"data": {"id": "comm-14", "label": "Community Detection Analysis Networ", "type": "COMMUNITY", "community": 14, "member_count": 3, "top_members": ["TRAAG", "FORTUNATO", "JIN"], "color": "#aaffc3", "size": 47, "pagerank_sum": 0.0079}}, {"data": {"id": "comm-15", "label": "Authorship Network in AI Research", "type": "COMMUNITY", "community": 15, "member_count": 3, "top_members": ["SHIN ET AL.", "SALMINEN ET AL.", "KOSINKSI"], "color": "#e6194b", "size": 47, "pagerank_sum": 0.0065}}, {"data": {"id": "comm-16", "label": "GraphRAG Validation Community", "type": "COMMUNITY", "community": 16, "member_count": 3, "top_members": ["RAG GENERATED ANSWERS", "VERIFIABLE FACTS", "GLOBAL"], "color": "#3cb44b", "size": 47, "pagerank_sum": 0.0092}}, {"data": {"id": "comm-17", "label": "NeoChip Community Overview", "type": "COMMUNITY", "community": 17, "member_count": 3, "top_members": ["QUANTUM SYSTEMS", "NEWTECH EXCHANGE", "NEOCHIP"], "color": "#4363d8", "size": 47, "pagerank_sum": 0.0065}}, {"data": {"id": "comm-18", "label": "Factual Claim Community", "type": "COMMUNITY", "community": 18, "member_count": 3, "top_members": ["NI ET AL", "NEW YORK", "CALIFORNIA"], "color": "#f58231", "size": 47, "pagerank_sum": 0.0079}}, {"data": {"id": "comm-19", "label": "ArXiv Preprint Collaboration Networ", "type": "COMMUNITY", "community": 19, "member_count": 3, "top_members": ["ARXIV:202310.13848", "A.JOSHI", "P.P.RANADE"], "color": "#911eb4", "size": 47, "pagerank_sum": 0.0079}}, {"data": {"id": "comm-20", "label": "Entity Extraction Community", "type": "COMMUNITY", "community": 20, "member_count": 3, "top_members": ["DEFAULT GRAPH EXTRACTION ", "CLAIM EXTRACTION PROMPT", "ENTITY EXTRACTION"], "color": "#42d4f4", "size": 47, "pagerank_sum": 0.0065}}, {"data": {"id": "comm-21", "label": "Entrepreneurial Controversies and I", "type": "COMMUNITY", "community": 21, "member_count": 3, "top_members": ["ENTREPRENEURS", "PUBLIC FIGURES IN CONTROV", "INFLUENCERS"], "color": "#f032e6", "size": 47, "pagerank_sum": 0.0079}}, {"data": {"id": "comm-22", "label": "Knowledge Graph Extraction Studies ", "type": "COMMUNITY", "community": 22, "member_count": 2, "top_members": ["YATES ET AL.", "MOONEY AND BUNESCU"], "color": "#bfef45", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-23", "label": "AI Ethics and Collaboration Communi", "type": "COMMUNITY", "community": 23, "member_count": 2, "top_members": ["ES", "ZHENG"], "color": "#fabed4", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-24", "label": "Podcast vs. News Articles Community", "type": "COMMUNITY", "community": 24, "member_count": 2, "top_members": ["NEWS ARTICLES", "PODCAST"], "color": "#469990", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-25", "label": "Graph Index and RAG Approaches Comm", "type": "COMMUNITY", "community": 25, "member_count": 2, "top_members": ["RAG APPROACHES", "GRAPH INDEX"], "color": "#dcbeff", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-26", "label": "Text Summarization and Vector RAG C", "type": "COMMUNITY", "community": 26, "member_count": 2, "top_members": ["MAP-REDUCE SOURCE TEXT SU", "VECTOR RAG BASELINE"], "color": "#9A6324", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-27", "label": "Fernández and Alonso Guevara Collab", "type": "COMMUNITY", "community": 27, "member_count": 2, "top_members": ["FERN´ANDEZ", "ALONSO GUEVARA"], "color": "#fffac8", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-28", "label": "Survey Research Community", "type": "COMMUNITY", "community": 28, "member_count": 2, "top_members": ["A SURVEY", "ARXIV:20231210997"], "color": "#800000", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-29", "label": "CIKM and IEEE Community", "type": "COMMUNITY", "community": 29, "member_count": 2, "top_members": ["CIKM", "IEEE"], "color": "#aaffc3", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-30", "label": "Retrieval-augmented Generation Comm", "type": "COMMUNITY", "community": 30, "member_count": 2, "top_members": ["PEREZ", "LEWIS"], "color": "#e6194b", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-31", "label": "Language Model Diversity Research C", "type": "COMMUNITY", "community": 31, "member_count": 2, "top_members": ["HE HONG", "PADMAKUMAR"], "color": "#3cb44b", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-32", "label": "Computational Linguistics Preprint ", "type": "COMMUNITY", "community": 32, "member_count": 2, "top_members": ["ARXIV PREPRINT", "COMPUTATIONAL LINGUISTICS"], "color": "#4363d8", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-33", "label": "Turbo Product Analysis Community", "type": "COMMUNITY", "community": 33, "member_count": 2, "top_members": ["TURBO", "YANG ET AL"], "color": "#f58231", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-34", "label": "Leiden Algorithm Community", "type": "COMMUNITY", "community": 34, "member_count": 2, "top_members": ["TRAAG ET AL.", "LEEDEN ALGORITHM"], "color": "#911eb4", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-35", "label": "MultiHop-RAG Community Analysis", "type": "COMMUNITY", "community": 35, "member_count": 2, "top_members": ["TANG AND YANG", "MULTIHOPE-RAG"], "color": "#42d4f4", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-36", "label": "Actors and Directors Community", "type": "COMMUNITY", "community": 36, "member_count": 2, "top_members": ["DIRECTORS", "ACTORS"], "color": "#f032e6", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-37", "label": "Music Industry Executives and Music", "type": "COMMUNITY", "community": 37, "member_count": 2, "top_members": ["EXECUTIVES", "MUSICIANS"], "color": "#bfef45", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-38", "label": "Athlete-Coach Community", "type": "COMMUNITY", "community": 38, "member_count": 2, "top_members": ["COACHES", "ATHLETES"], "color": "#fabed4", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-39", "label": "Federal Reserve Committee Insights", "type": "COMMUNITY", "community": 39, "member_count": 2, "top_members": ["JEROME POWELL", "FEDERAL OPEN MARKET COMMI"], "color": "#469990", "size": 40, "pagerank_sum": 0.0048}}, {"data": {"id": "comm-8-->comm-1", "source": "comm-8", "target": "comm-1", "weight": 1, "description": "1 cross-community relationships", "details": ["EXAMPLE CORP → GRAPHRAG: Example Corp is the entity using GraphRAG approach presented in the paper"]}}, {"data": {"id": "comm-4-->comm-1", "source": "comm-4", "target": "comm-1", "weight": 1, "description": "1 cross-community relationships", "details": ["C1 → GRAPHRAG: GraphRAG is used in C1 condition"]}}], "communityData": {"0": {"entities": [{"data": {"id": "USER QUERY", "label": "USER QUERY", "parent": "comm-0", "type": "CONCEPT", "description": "The concept is related to user input for generating a final answer", "community": 0, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 25, "chunk_count": 1}}, {"data": {"id": "DOMAIN-TAILORED SUMMARIZATION", "label": "DOMAIN-TAILORED SUMMARIZATION", "parent": "comm-0", "type": "EVENT", "description": "Process of summarizing documents tailored to specific domains", "community": 0, "pagerank": 0.003023, "degree_centrality": 0.0043, "betweenness": 0.0001, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 30, "chunk_count": 1}}, {"data": {"id": "ENTITY EXTRACTOR", "label": "ENTITY EXTRACTOR", "parent": "comm-0", "type": "CONCEPT", "description": "Tool used to extract entities from text", "community": 0, "pagerank": 0.004351, "degree_centrality": 0.0086, "betweenness": 0.0004, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 36, "chunk_count": 1}}, {"data": {"id": "COMMUNITY SUMMARIZATION", "label": "COMMUNITY SUMMARIZATION", "parent": "comm-0", "type": "EVENT", "description": "Summarizing community information for better understanding", "community": 0, "pagerank": 0.004009, "degree_centrality": 0.0043, "betweenness": 0.0003, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 34, "chunk_count": 1}}, {"data": {"id": "KNOWLEDGE GRAPH", "label": "KNOWLEDGE GRAPH", "parent": "comm-0", "type": "CONCEPT", "description": "Graph structure representing knowledge in a domain", "community": 0, "pagerank": 0.004261, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 35, "chunk_count": 1}}, {"data": {"id": "QUERY-FOCUSED SUMMARIZATION", "label": "QUERY-FOCUSED SUMMARIZATION", "parent": "comm-0", "type": "EVENT", "description": "Summarization focused on specific queries or tasks", "community": 0, "pagerank": 0.0051, "degree_centrality": 0.0043, "betweenness": 0.0003, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 39, "chunk_count": 1}}, {"data": {"id": "SOURCE DOCUMENTS", "label": "SOURCE DOCUMENTS", "parent": "comm-0", "type": "CONCEPT", "description": "General term for source documents | Collection of documents for text chunk extraction", "community": 0, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 25, "chunk_count": 2}}, {"data": {"id": "GLOBAL ANSWER", "label": "GLOBAL ANSWER", "parent": "comm-0", "type": "CONCEPT", "description": "General term for a global answer in the context of summarization | Final answer generated from community summaries and answers", "community": 0, "pagerank": 0.009727, "degree_centrality": 0.0043, "betweenness": 0.0003, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 58, "chunk_count": 2}}, {"data": {"id": "COMMUNITY ANSWERS", "label": "COMMUNITY ANSWERS", "parent": "comm-0", "type": "PRODUCT", "description": "Generated answers based on community summaries", "community": 0, "pagerank": 0.004351, "degree_centrality": 0.0043, "betweenness": 0.0002, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 36, "chunk_count": 1}}, {"data": {"id": "TEXT CHUNKS", "label": "TEXT CHUNKS", "parent": "comm-0", "type": "CONCEPT", "description": "Individual parts of a text document | Divided portions of source documents used in downstream processing", "community": 0, "pagerank": 0.003129, "degree_centrality": 0.0043, "betweenness": 0.0001, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 30, "chunk_count": 2}}, {"data": {"id": "GRAPH RAG PIPELINE", "label": "GRAPH RAG PIPELINE", "parent": "comm-0", "type": "EVENT", "description": "Pipeline for generating summaries using a graph index and an LLM", "community": 0, "pagerank": 0.003023, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 30, "chunk_count": 1}}, {"data": {"id": "COMMUNITY SUMMARIES", "label": "COMMUNITY SUMMARIES", "parent": "comm-0", "type": "CONCEPT", "description": "Concept in the text | Generated summaries used in the multi-stage process", "community": 0, "pagerank": 0.003129, "degree_centrality": 0.0043, "betweenness": 0.0001, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 30, "chunk_count": 2}}, {"data": {"id": "COMMUNITY DETECTION", "label": "COMMUNITY DETECTION", "parent": "comm-0", "type": "EVENT", "description": "Process of identifying communities within a network", "community": 0, "pagerank": 0.002727, "degree_centrality": 0.0043, "betweenness": 0.0003, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 29, "chunk_count": 1}}], "edges": [{"data": {"id": "SOURCE DOCUMENTS-->TEXT CHUNKS", "source": "SOURCE DOCUMENTS", "target": "TEXT CHUNKS", "description": "Source Documents are split into Text Chunks", "weight": 0.8}}, {"data": {"id": "TEXT CHUNKS-->ENTITY EXTRACTOR", "source": "TEXT CHUNKS", "target": "ENTITY EXTRACTOR", "description": "Text Chunks are processed by Entity Extractor to identify Entities & Relationships", "weight": 0.8}}, {"data": {"id": "ENTITY EXTRACTOR-->DOMAIN-TAILORED SUMMARIZATION", "source": "ENTITY EXTRACTOR", "target": "DOMAIN-TAILORED SUMMARIZATION", "description": "Entities & Relationships are further processed for Domain-Tailored Summarization", "weight": 0.9}}, {"data": {"id": "ENTITY EXTRACTOR-->COMMUNITY DETECTION", "source": "ENTITY EXTRACTOR", "target": "COMMUNITY DETECTION", "description": "Entities & Relationships are used for Community Detection", "weight": 0.7}}, {"data": {"id": "ENTITY EXTRACTOR-->GRAPH RAG PIPELINE", "source": "ENTITY EXTRACTOR", "target": "GRAPH RAG PIPELINE", "description": "Entities & Relationships are part of the Graph RAG Pipeline using an LLM-derived graph index of source document text", "weight": 0.9}}, {"data": {"id": "DOMAIN-TAILORED SUMMARIZATION-->KNOWLEDGE GRAPH", "source": "DOMAIN-TAILORED SUMMARIZATION", "target": "KNOWLEDGE GRAPH", "description": "Domain-Tailored Summaries contribute to the Knowledge Graph", "weight": 0.8}}, {"data": {"id": "COMMUNITY DETECTION-->COMMUNITY SUMMARIZATION", "source": "COMMUNITY DETECTION", "target": "COMMUNITY SUMMARIZATION", "description": "Communities are summarized using Domain-Tailored Summarization techniques", "weight": 0.8}}, {"data": {"id": "COMMUNITY SUMMARIZATION-->QUERY-FOCUSED SUMMARIZATION", "source": "COMMUNITY SUMMARIZATION", "target": "QUERY-FOCUSED SUMMARIZATION", "description": "Community Summaries are further refined for Query-Focused Summarization", "weight": 0.9}}, {"data": {"id": "QUERY-FOCUSED SUMMARIZATION-->GLOBAL ANSWER", "source": "QUERY-FOCUSED SUMMARIZATION", "target": "GLOBAL ANSWER", "description": "Query-Focused Summaries contribute to Global Answer generation", "weight": 0.8}}, {"data": {"id": "COMMUNITY SUMMARIES-->COMMUNITY ANSWERS", "source": "COMMUNITY SUMMARIES", "target": "COMMUNITY ANSWERS", "description": "Community summaries are used to generate community answers", "weight": 0.8}}, {"data": {"id": "USER QUERY-->COMMUNITY SUMMARIES", "source": "USER QUERY", "target": "COMMUNITY SUMMARIES", "description": "User query is processed to generate community summaries", "weight": 0.7}}, {"data": {"id": "COMMUNITY ANSWERS-->GLOBAL ANSWER", "source": "COMMUNITY ANSWERS", "target": "GLOBAL ANSWER", "description": "Community answers are combined into a final global answer", "weight": 0.9}}], "semantic_groups": []}, "1": {"entities": [{"data": {"id": "NEWMAN", "label": "NEWMAN", "parent": "comm-1", "type": "CONCEPT", "description": "Author of a study on graph modularity | Author of a scientific paper on network modularity", "community": 1, "pagerank": 0.003747, "degree_centrality": 0.0043, "betweenness": 0.0002, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 33, "chunk_count": 2}}, {"data": {"id": "VECTOR RAG", "label": "VECTOR RAG", "parent": "comm-1", "type": "CONCEPT", "description": "Implementation concept for Retrieval-Augmented Generation | Technological method used for producing responses | Comparison reference to GraphRAG", "community": 1, "pagerank": 0.001691, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 25, "chunk_count": 3}}, {"data": {"id": "GRAPHRAG", "label": "GRAPHRAG", "parent": "comm-1", "type": "PRODUCT", "description": "Proposed graph-based approach for question answering | A method for improving the comprehensiveness and diversity of generated answers | Framework for generating community-level summaries | Methodology for performing global sensemaking over an entire corpus | Method used for global sensemaking over an entire corpus | Approach to compare with vector RAG | A method for creating summaries | Graph-based index product | Text summarization method that applies the map-reduce approach directly to source texts | Technological method used for summarization | Model used in the study to generate low-level community summaries | Proposed method for mitigating downstream risks in decision-making tasks | A RAG approach that combines knowledge graph generation and query-focused summarization (QFS) | Framework or concept related to graph and LLM integration | Framework for Entity and Relationship Extraction Approach", "community": 1, "pagerank": 0.008475, "degree_centrality": 0.0172, "betweenness": 0.0023, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 53, "chunk_count": 15}}, {"data": {"id": "AFACTA", "label": "AFACTA", "parent": "comm-1", "type": "CONCEPT", "description": "Project name for assisting factual claim detection with LLMs", "community": 1, "pagerank": 0.004868, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 38, "chunk_count": 1}}, {"data": {"id": "NEBULAGRAPH", "label": "NEBULAGRAPH", "parent": "comm-1", "type": "PRODUCT", "description": "Database Management System | Company launching an industry-first graph RAG technology", "community": 1, "pagerank": 0.017338, "degree_centrality": 0.0151, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 90, "chunk_count": 2}}, {"data": {"id": "GPT-4", "label": "GPT-4", "parent": "comm-1", "type": "PRODUCT", "description": "Language model used for evaluation | AI model used in the initialization pipeline", "community": 1, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 25, "chunk_count": 3}}, {"data": {"id": "LLM", "label": "LLM", "parent": "comm-1", "type": "CONCEPT", "description": "Large language model used in the approach | Large language model used in the process | Language model used in the context | Large Language Model | Large Language Model used in evaluation | Language model used in text chunk processing | Large Language Model used in the context of RAG systems for generating questions | Large Language Model used in evaluations | Large language model technology | Large Language Model used in the evaluation process | Language model that interacts with the system", "community": 1, "pagerank": 0.005116, "degree_centrality": 0.0108, "betweenness": 0.0007, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 39, "chunk_count": 13}}, {"data": {"id": "NEO4J", "label": "NEO4J", "parent": "comm-1", "type": "PRODUCT", "description": "Graph Database | Graph database management system", "community": 1, "pagerank": 0.006876, "degree_centrality": 0.0129, "betweenness": 0.0005, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 46, "chunk_count": 2}}, {"data": {"id": "YUAN ET AL_", "label": "YUAN ET AL.", "parent": "comm-1", "type": "CONCEPT", "description": "", "community": 1, "pagerank": 0.003014, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 30, "chunk_count": 1}}, {"data": {"id": "ZHAO ET AL_", "label": "ZHAO ET AL.", "parent": "comm-1", "type": "CONCEPT", "description": "", "community": 1, "pagerank": 0.003014, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 30, "chunk_count": 1}}, {"data": {"id": "LANGCHAIN", "label": "LANGCHAIN", "parent": "sg-26", "type": "ORGANIZATION", "description": "Open-source library extension of GraphRAG approach | Library", "community": 1, "pagerank": 0.010936, "degree_centrality": 0.0151, "betweenness": 0.0001, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 63, "chunk_count": 2}}, {"data": {"id": "COMMUNITIES", "label": "COMMUNITIES", "parent": "comm-1", "type": "CONCEPT", "description": "Hierarchical structure of communities of closely related entities", "community": 1, "pagerank": 0.003392, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 32, "chunk_count": 1}}, {"data": {"id": "LLAMAINDEX", "label": "LLAMAINDEX", "parent": "sg-26", "type": "ORGANIZATION", "description": "Open-source library extension of GraphRAG approach | Library | Organization providing documentation and implementation examples", "community": 1, "pagerank": 0.009851, "degree_centrality": 0.0129, "betweenness": 0.0001, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 58, "chunk_count": 3}}], "edges": [{"data": {"id": "GRAPHRAG-->LLM", "source": "GRAPHRAG", "target": "LLM", "description": "GraphRAG uses an LLM to construct a knowledge graph", "weight": 0.8}}, {"data": {"id": "GRAPHRAG-->LANGCHAIN", "source": "GRAPHRAG", "target": "LANGCHAIN", "description": "GraphRAG is available as an extension to LangChain", "weight": 0.7}}, {"data": {"id": "GRAPHRAG-->LLAMAINDEX", "source": "GRAPHRAG", "target": "LLAMAINDEX", "description": "GraphRAG is available as an extension to LlamaIndex", "weight": 0.7}}, {"data": {"id": "LLM-->COMMUNITIES", "source": "LLM", "target": "COMMUNITIES", "description": "LLM partitions the graph into communities of closely related entities", "weight": 0.9}}, {"data": {"id": "LLM-->YUAN ET AL_", "source": "LLM", "target": "YUAN ET AL_", "description": "LLMs are used for adaptive benchmarking in work by Yuan et al.", "weight": 0.7}}, {"data": {"id": "LLM-->ZHAO ET AL_", "source": "LLM", "target": "ZHAO ET AL_", "description": "LLMs are used for adaptive benchmarking in work by ZHAO et al.", "weight": 0.7}}, {"data": {"id": "GPT-4-->GRAPHRAG", "source": "GPT-4", "target": "GRAPHRAG", "description": "GPT-4 is used by GraphRAG to judge the answers of two different RAG systems", "weight": 0.8}}, {"data": {"id": "LANGCHAIN-->NEBULAGRAPH", "source": "LANGCHAIN", "target": "NEBULAGRAPH", "description": "Both are mentioned as source libraries in the text", "weight": 0.2}}, {"data": {"id": "LANGCHAIN-->LLAMAINDEX", "source": "LANGCHAIN", "target": "LLAMAINDEX", "description": "Both are mentioned as source libraries in the text", "weight": 0.2}}, {"data": {"id": "LANGCHAIN-->NEO4J", "source": "LANGCHAIN", "target": "NEO4J", "description": "Both are mentioned as source libraries in the text", "weight": 0.2}}, {"data": {"id": "LLAMAINDEX-->NEBULAGRAPH", "source": "LLAMAINDEX", "target": "NEBULAGRAPH", "description": "Both are mentioned as source libraries in the text", "weight": 0.2}}, {"data": {"id": "LLAMAINDEX-->LANGCHAIN", "source": "LLAMAINDEX", "target": "LANGCHAIN", "description": "Both are mentioned as source libraries in the text", "weight": 0.2}}, {"data": {"id": "NEBULAGRAPH-->LANGCHAIN", "source": "NEBULAGRAPH", "target": "LANGCHAIN", "description": "Both are mentioned as source libraries in the text", "weight": 0.2}}, {"data": {"id": "NEBULAGRAPH-->LLAMAINDEX", "source": "NEBULAGRAPH", "target": "LLAMAINDEX", "description": "Both are mentioned as source libraries in the text", "weight": 0.2}}, {"data": {"id": "NEBULAGRAPH-->NEO4J", "source": "NEBULAGRAPH", "target": "NEO4J", "description": "Both are mentioned as source libraries in the text", "weight": 0.2}}, {"data": {"id": "NEBULAGRAPH-->NEBULAGRAPH", "source": "NEBULAGRAPH", "target": "NEBULAGRAPH", "description": "NebulaGraph launched an industry-first graph RAG technology in 2024", "weight": 0.8}}, {"data": {"id": "NEO4J-->LANGCHAIN", "source": "NEO4J", "target": "LANGCHAIN", "description": "Both are mentioned as source libraries in the text", "weight": 0.2}}, {"data": {"id": "NEO4J-->LLAMAINDEX", "source": "NEO4J", "target": "LLAMAINDEX", "description": "Both are mentioned as source libraries in the text", "weight": 0.2}}, {"data": {"id": "NEO4J-->GRAPHRAG", "source": "NEO4J", "target": "GRAPHRAG", "description": "Neo4j provides ecosystem tools for GraphRAG", "weight": 0.7}}, {"data": {"id": "NEO4J-->NEWMAN", "source": "NEO4J", "target": "NEWMAN", "description": "Neo4j is a graph database mentioned in Newman's work", "weight": 0.6}}, {"data": {"id": "NEWMAN-->AFACTA", "source": "NEWMAN", "target": "AFACTA", "description": "Newman's work discusses AFaCTA", "weight": 0.5}}, {"data": {"id": "VECTOR RAG-->LLM", "source": "VECTOR RAG", "target": "LLM", "description": "Vector RAG produces the most direct responses across all comparisons", "weight": 0.9}}, {"data": {"id": "VECTOR RAG-->GRAPHRAG", "source": "VECTOR RAG", "target": "GRAPHRAG", "description": "VECTOR RAG is compared to GRAPHRAG", "weight": 0.7}}], "semantic_groups": [{"data": {"id": "sg-26", "label": "LLAMAINDEX", "parent": "comm-1", "type": "SEMANTIC_GROUP", "group_id": 26, "canonical": "LLAMAINDEX", "member_count": 2, "color": "#bfef45"}}]}, "2": {"entities": [{"data": {"id": "DAVID TITTWORTH", "label": "DAVID TITTWORTH", "parent": "sg-2", "type": "PERSON", "description": "Contributor who worked on the project", "community": 2, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#4363d8", "size": 25, "chunk_count": 1}}, {"data": {"id": "DOUGLAS ORBAKER", "label": "DOUGLAS ORBAKER", "parent": "sg-2", "type": "PERSON", "description": "Contributor who worked on the project", "community": 2, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#4363d8", "size": 25, "chunk_count": 1}}, {"data": {"id": "CHRIS TREVIÑO", "label": "CHRIS TREVIÑO", "parent": "sg-2", "type": "PERSON", "description": "Contributor who worked on the project", "community": 2, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#4363d8", "size": 25, "chunk_count": 1}}, {"data": {"id": "ANDR´ES MORALES ESQUIVEL", "label": "ANDR´ES MORALES ESQUIVEL", "parent": "sg-2", "type": "PERSON", "description": "Contributor who worked on the project", "community": 2, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#4363d8", "size": 25, "chunk_count": 1}}, {"data": {"id": "BILLIE RINALDI", "label": "BILLIE RINALDI", "parent": "sg-2", "type": "PERSON", "description": "Contributor who worked on the project", "community": 2, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#4363d8", "size": 25, "chunk_count": 1}}, {"data": {"id": "AMBER HOAK", "label": "AMBER HOAK", "parent": "sg-2", "type": "PERSON", "description": "Contributor who worked on the project", "community": 2, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#4363d8", "size": 25, "chunk_count": 1}}, {"data": {"id": "ED", "label": "ED", "parent": "sg-2", "type": "PERSON", "description": "Contributor who worked on the project", "community": 2, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#4363d8", "size": 25, "chunk_count": 1}}, {"data": {"id": "DAYENNE DE SOUZA", "label": "DAYENNE DE SOUZA", "parent": "sg-2", "type": "PERSON", "description": "Contributor who worked on the project", "community": 2, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#4363d8", "size": 25, "chunk_count": 1}}, {"data": {"id": "BEN CUTLER", "label": "BEN CUTLER", "parent": "sg-2", "type": "PERSON", "description": "Contributor who worked on the project", "community": 2, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#4363d8", "size": 25, "chunk_count": 1}}, {"data": {"id": "CHRIS SANCHEZ", "label": "CHRIS SANCHEZ", "parent": "sg-2", "type": "PERSON", "description": "Contributor who worked on the project", "community": 2, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#4363d8", "size": 25, "chunk_count": 1}}], "edges": [], "semantic_groups": [{"data": {"id": "sg-2", "label": "ALONSO GUEVARA", "parent": "comm-2", "type": "SEMANTIC_GROUP", "group_id": 2, "canonical": "ALONSO GUEVARA", "member_count": 10, "color": "#bfef45"}}]}, "3": {"entities": [{"data": {"id": "ASSOCIATION FOR COMPUTATIONAL LINGUISTICS", "label": "ASSOCIATION FOR COMPUTATIONAL LINGUISTICS", "parent": "comm-3", "type": "ORGANIZATION", "description": "Conference organization and publisher | Organization", "community": 3, "pagerank": 0.001691, "degree_centrality": 0.0065, "betweenness": 0.0002, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f58231", "size": 25, "chunk_count": 2}}, {"data": {"id": "OPENAI", "label": "OPENAI", "parent": "comm-3", "type": "ORGANIZATION", "description": "Organization that released a study on knowledge graph extraction | OpenAI endpoint used for gpt-4-turbo | Company that developed ChatGPT language model", "community": 3, "pagerank": 0.002415, "degree_centrality": 0.0043, "betweenness": 0.0002, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f58231", "size": 28, "chunk_count": 3}}, {"data": {"id": "NAACL-HLT", "label": "NAACL-HLT", "parent": "comm-3", "type": "ORGANIZATION", "description": "Conference", "community": 3, "pagerank": 0.003652, "degree_centrality": 0.0043, "betweenness": 0.0001, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f58231", "size": 33, "chunk_count": 1}}, {"data": {"id": "YAO ET AL_", "label": "YAO ET AL.", "parent": "comm-3", "type": "PERSON", "description": "Authors of a study on RAG approaches using a knowledge graph as an index", "community": 3, "pagerank": 0.001968, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f58231", "size": 26, "chunk_count": 1}}, {"data": {"id": "J_ D_", "label": "J. D.", "parent": "comm-3", "type": "PERSON", "description": "Editor of Proceedings publication", "community": 3, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f58231", "size": 25, "chunk_count": 1}}, {"data": {"id": "TRAJANOSSKA ET AL_", "label": "TRAJANOSSKA ET AL.", "parent": "comm-3", "type": "PERSON", "description": "Authors of a study on RAG approaches using a knowledge graph as an index", "community": 3, "pagerank": 0.001968, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f58231", "size": 26, "chunk_count": 1}}, {"data": {"id": "ZHANG ET AL_", "label": "ZHANG ET AL.", "parent": "comm-3", "type": "PERSON", "description": "Authors of a study on RAG approaches using a knowledge graph as an index", "community": 3, "pagerank": 0.001968, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f58231", "size": 26, "chunk_count": 1}}, {"data": {"id": "MELNYK ET AL_", "label": "MELNYK ET AL.", "parent": "comm-3", "type": "PERSON", "description": "Authors of a study on using LLMs for knowledge graph extraction", "community": 3, "pagerank": 0.001968, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f58231", "size": 26, "chunk_count": 1}}, {"data": {"id": "TAN ET AL_", "label": "TAN ET AL.", "parent": "comm-3", "type": "PERSON", "description": "Authors of a study on RAG approaches using a knowledge graph as an index", "community": 3, "pagerank": 0.001691, "degree_centrality": 0.0108, "betweenness": 0.0002, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f58231", "size": 25, "chunk_count": 1}}, {"data": {"id": "KAU", "label": "KAU", "parent": "comm-3", "type": "LOCATION", "description": "City where the conference was held", "community": 3, "pagerank": 0.002214, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f58231", "size": 27, "chunk_count": 1}}], "edges": [{"data": {"id": "TAN ET AL_-->OPENAI", "source": "TAN ET AL_", "target": "OPENAI", "description": "OpenAI is mentioned alongside Tan et al. in the context of LLMs for knowledge graph extraction", "weight": 0.6}}, {"data": {"id": "TAN ET AL_-->MELNYK ET AL_", "source": "TAN ET AL_", "target": "MELNYK ET AL_", "description": "Melnyk et al. is mentioned alongside Tan et al. in the context of LLMs for knowledge graph extraction", "weight": 0.5}}, {"data": {"id": "TAN ET AL_-->TRAJANOSSKA ET AL_", "source": "TAN ET AL_", "target": "TRAJANOSSKA ET AL_", "description": "Trajanoska et al. is mentioned alongside Tan et al. in the context of LLMs for knowledge graph extraction", "weight": 0.5}}, {"data": {"id": "TAN ET AL_-->YAO ET AL_", "source": "TAN ET AL_", "target": "YAO ET AL_", "description": "Yao et al. is mentioned alongside Tan et al. in the context of LLMs for knowledge graph extraction", "weight": 0.5}}, {"data": {"id": "TAN ET AL_-->ZHANG ET AL_", "source": "TAN ET AL_", "target": "ZHANG ET AL_", "description": "Zhang et al. is mentioned alongside Tan et al. in the context of LLMs for knowledge graph extraction", "weight": 0.5}}, {"data": {"id": "ASSOCIATION FOR COMPUTATIONAL LINGUISTICS-->KAU", "source": "ASSOCIATION FOR COMPUTATIONAL LINGUISTICS", "target": "KAU", "description": "Association for Computational Linguistics is the editor of Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics", "weight": 0.8}}, {"data": {"id": "ASSOCIATION FOR COMPUTATIONAL LINGUISTICS-->OPENAI", "source": "ASSOCIATION FOR COMPUTATIONAL LINGUISTICS", "target": "OPENAI", "description": "Association for Computational Linguistics is the publisher of OpenAI's ChatGPT paper", "weight": 0.6}}, {"data": {"id": "ASSOCIATION FOR COMPUTATIONAL LINGUISTICS-->NAACL-HLT", "source": "ASSOCIATION FOR COMPUTATIONAL LINGUISTICS", "target": "NAACL-HLT", "description": "Association for Computational Linguistics is the publisher of NAACL-HLT conference proceedings", "weight": 0.8}}, {"data": {"id": "J_ D_-->NAACL-HLT", "source": "J_ D_", "target": "NAACL-HLT", "description": "J.D. is an editor of NAACL-HLT conference proceedings", "weight": 0.8}}], "semantic_groups": []}, "4": {"entities": [{"data": {"id": "COMPREHENSIVENESS", "label": "COMPREHENSIVENESS", "parent": "comm-4", "type": "CONCEPT", "description": "Measure used in News and Podcast datasets", "community": 4, "pagerank": 0.003129, "degree_centrality": 0.0043, "betweenness": 0.0002, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#911eb4", "size": 30, "chunk_count": 2}}, {"data": {"id": "VECTOR RAG _SS_", "label": "VECTOR RAG (SS)", "parent": "comm-4", "type": "PRODUCT", "description": "Competitor system for source text summarization", "community": 4, "pagerank": 0.004351, "degree_centrality": 0.0043, "betweenness": 0.0004, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#911eb4", "size": 36, "chunk_count": 1}}, {"data": {"id": "TS", "label": "TS", "parent": "comm-4", "type": "PRODUCT", "description": "A text summarization method that applies our map-reduce approach directly to source texts | Global text summarization without a graph index | Condition identifier in bolded values | Condition identifier in the data | A technical specification event in a sequence of events | Time series data point locations | Opening prices for multiple stocks", "community": 4, "pagerank": 0.008596, "degree_centrality": 0.0151, "betweenness": 0.0007, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#911eb4", "size": 53, "chunk_count": 7}}, {"data": {"id": "C2", "label": "C2", "parent": "sg-35", "type": "DATE", "description": "Condition identifier in bolded values | A concept identifier used in the text | A product identifier in a sequence of identifiers | Stock code or identifier", "community": 4, "pagerank": 0.001827, "degree_centrality": 0.0108, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#911eb4", "size": 25, "chunk_count": 4}}, {"data": {"id": "C3", "label": "C3", "parent": "sg-34", "type": "EVENT", "description": "Community summary level for low-level community summaries | Condition identifier in bolded values | A concept identifier used in the text | A product identifier in a sequence of identifiers | Stock code or identifier", "community": 4, "pagerank": 0.002021, "degree_centrality": 0.0108, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#911eb4", "size": 26, "chunk_count": 5}}, {"data": {"id": "SS", "label": "SS", "parent": "comm-4", "type": "PRODUCT", "description": "Vector RAG 'semantic search' approach | Condition identifier in bolded values | Participant in claim-based metrics who lost to C0 | Abbreviation for 'Standard Setting' condition | A standard specification event in a sequence of events | Secondary time series data point location | Closing prices for multiple stocks", "community": 4, "pagerank": 0.012481, "degree_centrality": 0.0129, "betweenness": 0.0001, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#911eb4", "size": 69, "chunk_count": 7}}, {"data": {"id": "DIRECTNESS", "label": "DIRECTNESS", "parent": "comm-4", "type": "EVENT", "description": "Control criterion used to evaluate the conciseness of an answer | Term used to describe a concept related to directness | A concept used in comparisons", "community": 4, "pagerank": 0.001691, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#911eb4", "size": 25, "chunk_count": 3}}, {"data": {"id": "P-VALUE", "label": "P-VALUE", "parent": "comm-4", "type": "MONEY", "description": "", "community": 4, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#911eb4", "size": 25, "chunk_count": 1}}, {"data": {"id": "C1", "label": "C1", "parent": "sg-35", "type": "DATE", "description": "Condition identifier in bolded values | A concept identifier used in the text | A product identifier in a sequence of identifiers | Stock code or identifier", "community": 4, "pagerank": 0.001767, "degree_centrality": 0.0129, "betweenness": 0.0014, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#911eb4", "size": 25, "chunk_count": 4}}, {"data": {"id": "C0", "label": "C0", "parent": "sg-34", "type": "EVENT", "description": "Community summary level for root-level community summaries | Condition identifier in bolded values | Participant in claim-based metrics who won over SS | Condition identifier in the data | A concept identifier used in the text | A product identifier in a sequence of identifiers | Stock code or identifier", "community": 4, "pagerank": 0.001691, "degree_centrality": 0.0108, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#911eb4", "size": 25, "chunk_count": 7}}], "edges": [{"data": {"id": "DIRECTNESS-->TS", "source": "DIRECTNESS", "target": "TS", "description": "Directness has a correlation with TS (C0)", "weight": 0.9}}, {"data": {"id": "DIRECTNESS-->SS", "source": "DIRECTNESS", "target": "SS", "description": "Directness has a correlation with SS (C1)", "weight": 0.8}}, {"data": {"id": "TS-->SS", "source": "TS", "target": "SS", "description": "Time Series data is compared with Stock Returns", "weight": 0.9}}, {"data": {"id": "C3-->TS", "source": "C3", "target": "TS", "description": "C3 and TS have a strength of -1.27 indicating they are very strong", "weight": 0.9}}, {"data": {"id": "C3-->SS", "source": "C3", "target": "SS", "description": "Correlation between C3 and SS is observed", "weight": 0.5}}, {"data": {"id": "C0-->C1", "source": "C0", "target": "C1", "description": "C0 and C1 have a strength of -1.23 indicating they are closely related", "weight": 0.1}}, {"data": {"id": "C0-->C2", "source": "C0", "target": "C2", "description": "C0 and C2 have a strength of -0.55 indicating they are moderately related", "weight": 0.1}}, {"data": {"id": "C0-->C3", "source": "C0", "target": "C3", "description": "C0 and C3 have a strength of -0.57 indicating they are moderately related", "weight": 0.1}}, {"data": {"id": "C0-->TS", "source": "C0", "target": "TS", "description": "C0 and TS have a strength of -4.1 indicating they are strongly related", "weight": 0.8}}, {"data": {"id": "C0-->SS", "source": "C0", "target": "SS", "description": "Correlation between C0 and SS is observed", "weight": 0.8}}, {"data": {"id": "C1-->TS", "source": "C1", "target": "TS", "description": "C1 and TS have a strength of -3.76 indicating they are very strong", "weight": 0.9}}, {"data": {"id": "C1-->SS", "source": "C1", "target": "SS", "description": "Correlation between C1 and SS is observed", "weight": 0.7}}, {"data": {"id": "C1-->C2", "source": "C1", "target": "C2", "description": "C1 and C2 have a strength of -1.5 indicating they are moderately related", "weight": 0.1}}, {"data": {"id": "C1-->C3", "source": "C1", "target": "C3", "description": "C1 and C3 have a strength of -0.84 indicating they are moderately related", "weight": 0.1}}, {"data": {"id": "C2-->C3", "source": "C2", "target": "C3", "description": "C2 and C3 have a strength of -0.22 indicating they are moderately related", "weight": 0.1}}, {"data": {"id": "C2-->TS", "source": "C2", "target": "TS", "description": "C2 and TS have a strength of -0.39 indicating they are weakly related", "weight": 0.1}}, {"data": {"id": "C2-->SS", "source": "C2", "target": "SS", "description": "Correlation between C2 and SS is observed", "weight": 0.6}}, {"data": {"id": "COMPREHENSIVENESS-->VECTOR RAG _SS_", "source": "COMPREHENSIVENESS", "target": "VECTOR RAG _SS_", "description": "Comprehensiveness is higher for global search conditions and source text summarization compared to vector RAG (SS)", "weight": 0.9}}, {"data": {"id": "VECTOR RAG _SS_-->TS", "source": "VECTOR RAG _SS_", "target": "TS", "description": "Vector RAG (SS) has lower comprehensiveness than source text summarization", "weight": 0.8}}, {"data": {"id": "P-VALUE-->COMPREHENSIVENESS", "source": "P-VALUE", "target": "COMPREHENSIVENESS", "description": "P-value and Comprehensiveness are the first two columns in the given text, likely representing statistical significance and comprehensiveness scores respectively.", "weight": 0.7}}], "semantic_groups": [{"data": {"id": "sg-34", "label": "C0", "parent": "comm-4", "type": "SEMANTIC_GROUP", "group_id": 34, "canonical": "C0", "member_count": 2, "color": "#bfef45"}}, {"data": {"id": "sg-35", "label": "C1", "parent": "comm-4", "type": "SEMANTIC_GROUP", "group_id": 35, "canonical": "C1", "member_count": 2, "color": "#bfef45"}}]}, "5": {"entities": [{"data": {"id": "GRAPSELOGIC", "label": "GRAPSELOGIC", "parent": "comm-5", "type": "PRODUCT", "description": "Library used for Leiden community detection", "community": 5, "pagerank": 0.001691, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#42d4f4", "size": 25, "chunk_count": 1}}, {"data": {"id": "CHUNG ET AL_", "label": "CHUNG ET AL.", "parent": "comm-5", "type": "CONCEPT", "description": "Authors of the paper referenced in parentheses", "community": 5, "pagerank": 0.002513, "degree_centrality": 0.0151, "betweenness": 0.0002, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#42d4f4", "size": 28, "chunk_count": 1}}, {"data": {"id": "APPENDIX F", "label": "APPENDIX F", "parent": "comm-5", "type": "LOCATION", "description": "Section of the text providing prompts for head-to-head measures | Section where prompts for evaluating LLM responses against criteria are located", "community": 5, "pagerank": 0.002047, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#42d4f4", "size": 26, "chunk_count": 2}}, {"data": {"id": "EXPERIMENT 2", "label": "EXPERIMENT 2", "parent": "comm-5", "type": "EVENT", "description": "Experiment used to implement claim-based measures of qualities | Experiment name mentioned in text", "community": 5, "pagerank": 0.002047, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#42d4f4", "size": 26, "chunk_count": 2}}, {"data": {"id": "APPENDIX E", "label": "APPENDIX E", "parent": "comm-5", "type": "LOCATION", "description": "Section where prompts for graph index and global answers are located", "community": 5, "pagerank": 0.002663, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#42d4f4", "size": 29, "chunk_count": 1}}, {"data": {"id": "APPENDIX G", "label": "APPENDIX G", "parent": "comm-5", "type": "LOCATION", "description": "Section where full statistical analysis of results is located", "community": 5, "pagerank": 0.002047, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#42d4f4", "size": 26, "chunk_count": 1}}, {"data": {"id": "NI ET AL_", "label": "NI ET AL.", "parent": "comm-5", "type": "CONCEPT", "description": "Authors of the paper referenced in parentheses", "community": 5, "pagerank": 0.001996, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#42d4f4", "size": 26, "chunk_count": 1}}, {"data": {"id": "EXPERIMENT 1", "label": "EXPERIMENT 1", "parent": "comm-5", "type": "EVENT", "description": "Experiment used to validate comprehensiveness and diversity results | Previous experiment results | Experiment conducted in pairwise comparisons", "community": 5, "pagerank": 0.002098, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#42d4f4", "size": 26, "chunk_count": 3}}], "edges": [{"data": {"id": "GRAPSELOGIC-->CHUNG ET AL_", "source": "GRAPSELOGIC", "target": "CHUNG ET AL_", "description": "Graspologic library is used in Chung et al. paper", "weight": 0.8}}, {"data": {"id": "GRAPSELOGIC-->APPENDIX E", "source": "GRAPSELOGIC", "target": "APPENDIX E", "description": "Graspologic library is related to Appendix E content", "weight": 0.6}}, {"data": {"id": "CHUNG ET AL_-->APPENDIX E", "source": "CHUNG ET AL_", "target": "APPENDIX E", "description": "Chung et al. discusses Appendix E content", "weight": 0.7}}, {"data": {"id": "CHUNG ET AL_-->APPENDIX F", "source": "CHUNG ET AL_", "target": "APPENDIX F", "description": "Chung et al. discusses Appendix F content", "weight": 0.7}}, {"data": {"id": "CHUNG ET AL_-->APPENDIX G", "source": "CHUNG ET AL_", "target": "APPENDIX G", "description": "Chung et al. discusses Appendix G content", "weight": 0.7}}, {"data": {"id": "CHUNG ET AL_-->EXPERIMENT 1", "source": "CHUNG ET AL_", "target": "EXPERIMENT 1", "description": "Chung et al. discusses Experiment 1 results", "weight": 0.8}}, {"data": {"id": "CHUNG ET AL_-->EXPERIMENT 2", "source": "CHUNG ET AL_", "target": "EXPERIMENT 2", "description": "Chung et al. discusses Experiment 2 validation methods", "weight": 0.7}}, {"data": {"id": "CHUNG ET AL_-->NI ET AL_", "source": "CHUNG ET AL_", "target": "NI ET AL_", "description": "Chung et al. references Ni et al. for claim definition", "weight": 0.6}}], "semantic_groups": []}, "6": {"entities": [{"data": {"id": "ETZIONI", "label": "ETZIONI", "parent": "comm-6", "type": "PERSON", "description": "Author of a related work on knowledge graph extraction", "community": 6, "pagerank": 0.003468, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f032e6", "size": 32, "chunk_count": 1}}, {"data": {"id": "SCIENTIFIC REPORTS", "label": "SCIENTIFIC REPORTS", "parent": "comm-6", "type": "JOURNAL", "description": "Journal where the article 'Enhancing knowledge graph construction using large language models' was published", "community": 6, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f032e6", "size": 25, "chunk_count": 1}}, {"data": {"id": "ELMAGRAMARD", "label": "ELMAGRAMARD", "parent": "sg-38", "type": "PERSON", "description": "Authors of the paper 'Duplicate record detection: A survey'", "community": 6, "pagerank": 0.001691, "degree_centrality": 0.0065, "betweenness": 0.0001, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f032e6", "size": 25, "chunk_count": 1}}, {"data": {"id": "IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING", "label": "IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING", "parent": "sg-38", "type": "JOURNAL", "description": "Publication where the paper 'Duplicate record detection: A survey' was published", "community": 6, "pagerank": 0.00225, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f032e6", "size": 27, "chunk_count": 1}}, {"data": {"id": "ARXIV", "label": "ARXIV", "parent": "comm-6", "type": "ORGANIZATION", "description": "Preprint server where the papers are uploaded | Preprint server where the paper 'Ragas: Automated evaluation of retrieval augmented generation' is hosted | Preprint repository for academic papers | preprint repository | Preprint server where articles were submitted for publication | Preprint repository where the paper was uploaded", "community": 6, "pagerank": 0.003608, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f032e6", "size": 32, "chunk_count": 8}}, {"data": {"id": "KNOWITALL", "label": "KNOWITALL", "parent": "comm-6", "type": "PROJECT", "description": "Project name mentioned in the author's affiliation", "community": 6, "pagerank": 0.00209, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f032e6", "size": 26, "chunk_count": 1}}], "edges": [{"data": {"id": "ELMAGRAMARD-->IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING", "source": "ELMAGRAMARD", "target": "IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING", "description": "Elmagaramid, A. K., Ipeirotis, P. G., and Verykios, V. S. published in IEEE Transactions on Knowledge and Data Engineering", "weight": 0.7}}, {"data": {"id": "ELMAGRAMARD-->ARXIV", "source": "ELMAGRAMARD", "target": "ARXIV", "description": "Elmagaramid, A. K., Ipeirotis, P. G., and Verykios, V. S. published in Arxiv", "weight": 0.6}}, {"data": {"id": "ELMAGRAMARD-->KNOWITALL", "source": "ELMAGRAMARD", "target": "KNOWITALL", "description": "Elmagaramid, A. K., Ipeirotis, P. G., and Verykios, V. S. are related to Knowitall", "weight": 0.5}}, {"data": {"id": "KNOWITALL-->ETZIONI", "source": "KNOWITALL", "target": "ETZIONI", "description": "Knowitall is a dataset used by Etzioni, O., Cafarella, M., Downey, D., Kok, S., Popescu, A.-M., Shaked, T., Soderland, S., Weld, D. S., and Yates, A.", "weight": 0.5}}, {"data": {"id": "SCIENTIFIC REPORTS-->ARXIV", "source": "SCIENTIFIC REPORTS", "target": "ARXIV", "description": "Scientific Reports references ArXiv for the publication of Wang, J., Liang, Y., Meng, F., Sun, Z., Shi, H., Li, Z., Xu, J., Qu, J., and Zhou, J. (2023a) paper", "weight": 0.7}}], "semantic_groups": [{"data": {"id": "sg-38", "label": "IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING", "parent": "comm-6", "type": "SEMANTIC_GROUP", "group_id": 38, "canonical": "IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING", "member_count": 2, "color": "#bfef45"}}]}, "7": {"entities": [{"data": {"id": "PRIOR QFS METHODS", "label": "PRIOR QFS METHODS", "parent": "comm-7", "type": "ORGANIZATION", "description": "Previous approaches to query-focused summarization", "community": 7, "pagerank": 0.002482, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#bfef45", "size": 28, "chunk_count": 1}}, {"data": {"id": "RETRIEVAL-AUGMENTED GENERATION", "label": "RETRIEVAL-AUGMENTED GENERATION", "parent": "comm-7", "type": "CONCEPT", "description": "A technique used in large language models", "community": 7, "pagerank": 0.001691, "degree_centrality": 0.0065, "betweenness": 0.0001, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#bfef45", "size": 25, "chunk_count": 1}}, {"data": {"id": "LARGE LANGUAGE MODELS", "label": "LARGE LANGUAGE MODELS", "parent": "comm-7", "type": "ORGANIZATION", "description": "Type of artificial intelligence model", "community": 7, "pagerank": 0.00217, "degree_centrality": 0.0065, "betweenness": 0.0001, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#bfef45", "size": 26, "chunk_count": 1}}, {"data": {"id": "EXTERNAL KNOWLEDGE SOURCE", "label": "EXTERNAL KNOWLEDGE SOURCE", "parent": "comm-7", "type": "LOCATION", "description": "Source of information for retrieval-augmented generation", "community": 7, "pagerank": 0.00223, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#bfef45", "size": 27, "chunk_count": 1}}, {"data": {"id": "QUERY-FOCUSED SUMMARIZATION _QFS_", "label": "QUERY-FOCUSED SUMMARIZATION (QFS)", "parent": "comm-7", "type": "CONCEPT", "description": "Type of summarization task", "community": 7, "pagerank": 0.00211, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#bfef45", "size": 26, "chunk_count": 1}}, {"data": {"id": "PRIVATE DOCUMENT COLLECTIONS", "label": "PRIVATE DOCUMENT COLLECTIONS", "parent": "comm-7", "type": "LOCATION", "description": "Collections of documents that are private or unseen by the model", "community": 7, "pagerank": 0.002745, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#bfef45", "size": 29, "chunk_count": 1}}], "edges": [{"data": {"id": "RETRIEVAL-AUGMENTED GENERATION-->LARGE LANGUAGE MODELS", "source": "RETRIEVAL-AUGMENTED GENERATION", "target": "LARGE LANGUAGE MODELS", "description": "Retrieval-augmented generation (RAG) is used by large language models (LLMs)", "weight": 0.8}}, {"data": {"id": "RETRIEVAL-AUGMENTED GENERATION-->EXTERNAL KNOWLEDGE SOURCE", "source": "RETRIEVAL-AUGMENTED GENERATION", "target": "EXTERNAL KNOWLEDGE SOURCE", "description": "Retrieval-augmented generation (RAG) retrieves relevant information from an external knowledge source", "weight": 0.9}}, {"data": {"id": "RETRIEVAL-AUGMENTED GENERATION-->QUERY-FOCUSED SUMMARIZATION _QFS_", "source": "RETRIEVAL-AUGMENTED GENERATION", "target": "QUERY-FOCUSED SUMMARIZATION _QFS_", "description": "RAG is used for query-focused summarization tasks", "weight": 0.7}}, {"data": {"id": "LARGE LANGUAGE MODELS-->PRIVATE DOCUMENT COLLECTIONS", "source": "LARGE LANGUAGE MODELS", "target": "PRIVATE DOCUMENT COLLECTIONS", "description": "Large language models can answer questions over private document collections", "weight": 0.8}}, {"data": {"id": "LARGE LANGUAGE MODELS-->PRIOR QFS METHODS", "source": "LARGE LANGUAGE MODELS", "target": "PRIOR QFS METHODS", "description": "Large language models use prior QFS methods to summarize text corpora", "weight": 0.6}}], "semantic_groups": []}, "8": {"entities": [{"data": {"id": "COMUNITY", "label": "COMUNITY", "parent": "comm-8", "type": "CONCEPT", "description": "Community being reported on", "community": 8, "pagerank": 0.001691, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#fabed4", "size": 25, "chunk_count": 1}}, {"data": {"id": "EXAMPLE CORP", "label": "EXAMPLE CORP", "parent": "sg-14", "type": "ORGANIZATION", "description": "Technology company acquiring StartupXYZ", "community": 8, "pagerank": 0.004466, "degree_centrality": 0.0086, "betweenness": 0.0007, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#fabed4", "size": 36, "chunk_count": 6}}, {"data": {"id": "STARTUPXYZ", "label": "STARTUPXYZ", "parent": "sg-14", "type": "ORGANIZATION", "description": "Company being acquired by Example Corp", "community": 8, "pagerank": 0.00359, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#fabed4", "size": 32, "chunk_count": 1}}, {"data": {"id": "JOHN SMITH", "label": "JOHN SMITH", "parent": "comm-8", "type": "PERSON", "description": "Individual whose contributions are listed in the overview of public figures | CEO of Example Corp who announced the merger", "community": 8, "pagerank": 0.002362, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#fabed4", "size": 27, "chunk_count": 2}}], "edges": [{"data": {"id": "EXAMPLE CORP-->STARTUPXYZ", "source": "EXAMPLE CORP", "target": "STARTUPXYZ", "description": "Example Corp is acquiring StartupXYZ", "weight": 0.8}}, {"data": {"id": "JOHN SMITH-->EXAMPLE CORP", "source": "JOHN SMITH", "target": "EXAMPLE CORP", "description": "John Smith is associated with Example Corp", "weight": 0.7}}, {"data": {"id": "COMUNITY-->JOHN SMITH", "source": "COMUNITY", "target": "JOHN SMITH", "description": "John Smith is a member of the community", "weight": 0.7}}, {"data": {"id": "COMUNITY-->EXAMPLE CORP", "source": "COMUNITY", "target": "EXAMPLE CORP", "description": "Example Corp is part of the community", "weight": 0.8}}], "semantic_groups": [{"data": {"id": "sg-14", "label": "QUANTUM SYSTEMS", "parent": "comm-8", "type": "SEMANTIC_GROUP", "group_id": 14, "canonical": "QUANTUM SYSTEMS", "member_count": 2, "color": "#bfef45"}}]}, "9": {"entities": [{"data": {"id": "LAW", "label": "LAW", "parent": "sg-19", "type": "CONCEPT", "description": "Domain for specialized knowledge in law", "community": 9, "pagerank": 0.00217, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#469990", "size": 26, "chunk_count": 1}}, {"data": {"id": "MEDICINE", "label": "MEDICINE", "parent": "sg-19", "type": "CONCEPT", "description": "Domain for specialized knowledge in medicine", "community": 9, "pagerank": 0.00217, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#469990", "size": 26, "chunk_count": 1}}, {"data": {"id": "SCIENCE", "label": "SCIENCE", "parent": "sg-19", "type": "CONCEPT", "description": "Domain for specialized knowledge in science", "community": 9, "pagerank": 0.00217, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#469990", "size": 26, "chunk_count": 1}}, {"data": {"id": "BROWN", "label": "BROWN", "parent": "comm-9", "type": "PERSON", "description": "Author of the paper 'In-context learning'", "community": 9, "pagerank": 0.001691, "degree_centrality": 0.0065, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#469990", "size": 25, "chunk_count": 1}}], "edges": [{"data": {"id": "BROWN-->SCIENCE", "source": "BROWN", "target": "SCIENCE", "description": "Brown is related to Science", "weight": 0.4}}, {"data": {"id": "BROWN-->MEDICINE", "source": "BROWN", "target": "MEDICINE", "description": "Brown is related to Medicine", "weight": 0.4}}, {"data": {"id": "BROWN-->LAW", "source": "BROWN", "target": "LAW", "description": "Brown is related to Law", "weight": 0.4}}], "semantic_groups": [{"data": {"id": "sg-19", "label": "MEDICINE", "parent": "comm-9", "type": "SEMANTIC_GROUP", "group_id": 19, "canonical": "MEDICINE", "member_count": 3, "color": "#bfef45"}}]}, "10": {"entities": [{"data": {"id": "CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE", "label": "CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE", "parent": "comm-10", "type": "ORGANIZATION", "description": "Conference where the papers were presented", "community": 10, "pagerank": 0.00539, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#dcbeff", "size": 40, "chunk_count": 1}}, {"data": {"id": "PETRONI", "label": "PETRONI", "parent": "sg-4", "type": "PERSON", "description": "Author of the paper 'Retrieval-augmented generation for knowledge-intensive nlp'", "community": 10, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#dcbeff", "size": 25, "chunk_count": 1}}, {"data": {"id": "GOALY", "label": "GOALY", "parent": "sg-4", "type": "PERSON", "description": "Author of the paper 'Retrieval-augmented generation for knowledge-intensive nlp'", "community": 10, "pagerank": 0.004351, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#dcbeff", "size": 36, "chunk_count": 1}}, {"data": {"id": "KARPUKHIN", "label": "KARPUKHIN", "parent": "sg-4", "type": "PERSON", "description": "Author of the paper 'Retrieval-augmented generation for knowledge-intensive nlp'", "community": 10, "pagerank": 0.003129, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#dcbeff", "size": 30, "chunk_count": 1}}], "edges": [{"data": {"id": "PETRONI-->KARPUKHIN", "source": "PETRONI", "target": "KARPUKHIN", "description": "Petroni is the fourth author and Karpukhin is the third author in the same paper", "weight": 0.6}}, {"data": {"id": "KARPUKHIN-->GOALY", "source": "KARPUKHIN", "target": "GOALY", "description": "Karpukhin is cited by Goaly in the text", "weight": 0.5}}, {"data": {"id": "GOALY-->CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE", "source": "GOALY", "target": "CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE", "description": "Goal is a conference and it's mentioned that papers were presented at this conference", "weight": 0.4}}], "semantic_groups": [{"data": {"id": "sg-4", "label": "W.-T.", "parent": "comm-10", "type": "SEMANTIC_GROUP", "group_id": 4, "canonical": "W.-T.", "member_count": 3, "color": "#bfef45"}}]}, "11": {"entities": [{"data": {"id": "VERDANT OASIS PLAZA", "label": "VERDANT OASIS PLAZA", "parent": "sg-44", "type": "LOCATION", "description": "Location of the Unity March | Central location for Unity March | Central location in the community serving as the site for the Unity March | Location where Harmony Assembly organizes a march", "community": 11, "pagerank": 0.00407, "degree_centrality": 0.0086, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#9A6324", "size": 34, "chunk_count": 4}}, {"data": {"id": "UNITY MARCH", "label": "UNITY MARCH", "parent": "comm-11", "type": "EVENT", "description": "March taking place at Verdant Oasis Plaza | Community event associated with the plaza and other entities | Main event taking place at Verdant Oasis Plaza", "community": 11, "pagerank": 0.003075, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#9A6324", "size": 30, "chunk_count": 2}}, {"data": {"id": "HARMONY ASSEMBLY", "label": "HARMONY ASSEMBLY", "parent": "sg-44", "type": "ORGANIZATION", "description": "Organization holding a march at Verdant Oasis Plaza | Organization related to the Unity March | Community organization that organizes events at Verdant Oasis Plaza", "community": 11, "pagerank": 0.002799, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#9A6324", "size": 29, "chunk_count": 3}}, {"data": {"id": "TRIBUNE SPOTLIGHT", "label": "TRIBUNE SPOTLIGHT", "parent": "comm-11", "type": "ORGANIZATION", "description": "Organization associated with the Unity March", "community": 11, "pagerank": 0.00266, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#9A6324", "size": 29, "chunk_count": 1}}], "edges": [{"data": {"id": "VERDANT OASIS PLAZA-->UNITY MARCH", "source": "VERDANT OASIS PLAZA", "target": "UNITY MARCH", "description": "Unity March is held at Verdant Oasis Plaza", "weight": 1.0}}, {"data": {"id": "VERDANT OASIS PLAZA-->HARMONY ASSEMBLY", "source": "VERDANT OASIS PLAZA", "target": "HARMONY ASSEMBLY", "description": "Verdant Oasis Plaza has a relationship with Harmony Assembly", "weight": 0.8}}, {"data": {"id": "VERDANT OASIS PLAZA-->TRIBUNE SPOTLIGHT", "source": "VERDANT OASIS PLAZA", "target": "TRIBUNE SPOTLIGHT", "description": "Verdant Oasis Plaza has a relationship with Tribune Spotlight", "weight": 0.7}}, {"data": {"id": "HARMONY ASSEMBLY-->VERDANT OASIS PLAZA", "source": "HARMONY ASSEMBLY", "target": "VERDANT OASIS PLAZA", "description": "Harmony Assembly organizes a march at Verdant Oasis Plaza", "weight": 0.8}}], "semantic_groups": [{"data": {"id": "sg-44", "label": "VERDANT OASIS PLAZA", "parent": "comm-11", "type": "SEMANTIC_GROUP", "group_id": 44, "canonical": "VERDANT OASIS PLAZA", "member_count": 2, "color": "#bfef45"}}]}, "12": {"entities": [{"data": {"id": "MICROSOFT RESEARCH", "label": "MICROSOFT RESEARCH", "parent": "sg-12", "type": "ORGANIZATION", "description": "Institution where some authors are affiliated", "community": 12, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#fffac8", "size": 25, "chunk_count": 1}}, {"data": {"id": "MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES", "label": "MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES", "parent": "sg-12", "type": "ORGANIZATION", "description": "Institution where some authors are affiliated", "community": 12, "pagerank": 0.003129, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#fffac8", "size": 30, "chunk_count": 1}}, {"data": {"id": "MICROSOFT OFFICE OF THE CTO", "label": "MICROSOFT OFFICE OF THE CTO", "parent": "sg-12", "type": "ORGANIZATION", "description": "Institution where some authors are affiliated", "community": 12, "pagerank": 0.004351, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#fffac8", "size": 36, "chunk_count": 1}}], "edges": [{"data": {"id": "MICROSOFT RESEARCH-->MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES", "source": "MICROSOFT RESEARCH", "target": "MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES", "description": "Microsoft Research is a parent entity of Microsoft Strategic Missions and Technologies", "weight": 0.8}}, {"data": {"id": "MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES-->MICROSOFT OFFICE OF THE CTO", "source": "MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES", "target": "MICROSOFT OFFICE OF THE CTO", "description": "Microsoft Strategic Missions and Technologies is a sub-entity of Microsoft Office of the CTO", "weight": 0.7}}], "semantic_groups": [{"data": {"id": "sg-12", "label": "KNOWITALL", "parent": "comm-12", "type": "SEMANTIC_GROUP", "group_id": 12, "canonical": "KNOWITALL", "member_count": 3, "color": "#bfef45"}}]}, "13": {"entities": [{"data": {"id": "HUANG", "label": "HUANG", "parent": "sg-3", "type": "PERSON", "description": "Author of the paper 'Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models'", "community": 13, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#800000", "size": 25, "chunk_count": 1}}, {"data": {"id": "LASKAR", "label": "LASKAR", "parent": "sg-3", "type": "PERSON", "description": "Authors of a paper on vector RAG approach | Author of the paper 'Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models'", "community": 13, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#800000", "size": 25, "chunk_count": 2}}, {"data": {"id": "HOQUE", "label": "HOQUE", "parent": "sg-3", "type": "PERSON", "description": "Author of the paper 'Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models'", "community": 13, "pagerank": 0.004566, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#800000", "size": 36, "chunk_count": 1}}], "edges": [{"data": {"id": "LASKAR-->HOQUE", "source": "LASKAR", "target": "HOQUE", "description": "Laskar is the first author and Hoque is the second author", "weight": 0.7}}, {"data": {"id": "HUANG-->HOQUE", "source": "HUANG", "target": "HOQUE", "description": "Huang is the third author and Hoque is the second author", "weight": 0.7}}], "semantic_groups": [{"data": {"id": "sg-3", "label": "BAUMEL", "parent": "comm-13", "type": "SEMANTIC_GROUP", "group_id": 3, "canonical": "BAUMEL", "member_count": 3, "color": "#bfef45"}}]}, "14": {"entities": [{"data": {"id": "TRAAG", "label": "TRAAG", "parent": "comm-14", "type": "PERSON", "description": " | Author of a paper introducing the Leiden community detection algorithm", "community": 14, "pagerank": 0.004566, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#aaffc3", "size": 36, "chunk_count": 2}}, {"data": {"id": "FORTUNATO", "label": "FORTUNATO", "parent": "comm-14", "type": "CONCEPT", "description": "Author of a survey on community detection algorithms", "community": 14, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#aaffc3", "size": 25, "chunk_count": 1}}, {"data": {"id": "JIN", "label": "JIN", "parent": "comm-14", "type": "CONCEPT", "description": "Author of a survey on community detection algorithms | First author of the survey on community detection approaches", "community": 14, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#aaffc3", "size": 25, "chunk_count": 2}}], "edges": [{"data": {"id": "FORTUNATO-->TRAAG", "source": "FORTUNATO", "target": "TRAAG", "description": "Fortunato's work is cited by Traag's work", "weight": 0.7}}, {"data": {"id": "JIN-->TRAAG", "source": "JIN", "target": "TRAAG", "description": "Jin et al. (2021) is cited by Traag et al. (2019)", "weight": 0.8}}], "semantic_groups": []}, "15": {"entities": [{"data": {"id": "KOSINKSI", "label": "KOSINKSI", "parent": "comm-15", "type": "PERSON", "description": "Author of a paper referenced in the text", "community": 15, "pagerank": 0.001691, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 25, "chunk_count": 1}}, {"data": {"id": "SHIN ET AL_", "label": "SHIN ET AL.", "parent": "comm-15", "type": "PERSON", "description": "Authors of a paper referenced in the text", "community": 15, "pagerank": 0.00241, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 27, "chunk_count": 1}}, {"data": {"id": "SALMINEN ET AL_", "label": "SALMINEN ET AL.", "parent": "comm-15", "type": "PERSON", "description": "Authors of a paper referenced in the text", "community": 15, "pagerank": 0.00241, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 27, "chunk_count": 1}}], "edges": [{"data": {"id": "KOSINKSI-->SALMINEN ET AL_", "source": "KOSINKSI", "target": "SALMINEN ET AL_", "description": "Kosinski and Salminen et al. are co-authored papers", "weight": 0.7}}, {"data": {"id": "KOSINKSI-->SHIN ET AL_", "source": "KOSINKSI", "target": "SHIN ET AL_", "description": "Kosinski and Shin et al. are co-authored papers", "weight": 0.7}}], "semantic_groups": []}, "16": {"entities": [{"data": {"id": "RAG GENERATED ANSWERS", "label": "RAG GENERATED ANSWERS", "parent": "comm-16", "type": "PRODUCT", "description": "Generated answers evaluated using GraphRAG approach", "community": 16, "pagerank": 0.004351, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 36, "chunk_count": 1}}, {"data": {"id": "VERIFIABLE FACTS", "label": "VERIFIABLE FACTS", "parent": "comm-16", "type": "MONEY", "description": "Facts extracted from LLM statements for validation", "community": 16, "pagerank": 0.003129, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 30, "chunk_count": 1}}, {"data": {"id": "GLOBAL", "label": "GLOBAL", "parent": "comm-16", "type": "CONCEPT", "description": "Concept used in evaluating RAG-generated answers | Refers to the overall structure and semantics of a dataset", "community": 16, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 25, "chunk_count": 2}}], "edges": [{"data": {"id": "GLOBAL-->VERIFIABLE FACTS", "source": "GLOBAL", "target": "VERIFIABLE FACTS", "description": "Global sensemaking questions require validation using verifiable facts", "weight": 0.7}}, {"data": {"id": "VERIFIABLE FACTS-->RAG GENERATED ANSWERS", "source": "VERIFIABLE FACTS", "target": "RAG GENERATED ANSWERS", "description": "Verifiable facts are used to validate RAG-generated answers", "weight": 0.8}}], "semantic_groups": []}, "17": {"entities": [{"data": {"id": "NEOCHIP", "label": "NEOCHIP", "parent": "comm-17", "type": "ORGANIZATION", "description": "NeoChip is a publicly traded company specializing in low-power processors for wearables and IoT devices. | Technology company acquired by Quantum Systems | Company that was acquired by Quantum Systems", "community": 17, "pagerank": 0.001691, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#4363d8", "size": 25, "chunk_count": 3}}, {"data": {"id": "QUANTUM SYSTEMS", "label": "QUANTUM SYSTEMS", "parent": "comm-17", "type": "ORGANIZATION", "description": "Firm that previously owned NeoChip | Acquirer of NeoChip | Acquirer in the acquisition event", "community": 17, "pagerank": 0.002452, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#4363d8", "size": 28, "chunk_count": 3}}, {"data": {"id": "NEWTECH EXCHANGE", "label": "NEWTECH EXCHANGE", "parent": "comm-17", "type": "LOCATION", "description": "Exchange where NeoChip listed its shares", "community": 17, "pagerank": 0.002368, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#4363d8", "size": 27, "chunk_count": 1}}], "edges": [{"data": {"id": "NEOCHIP-->QUANTUM SYSTEMS", "source": "NEOCHIP", "target": "QUANTUM SYSTEMS", "description": "Quantum Systems acquired NeoChip in 2016 and held ownership until NeoChip went public.", "weight": 0.9}}, {"data": {"id": "NEOCHIP-->NEWTECH EXCHANGE", "source": "NEOCHIP", "target": "NEWTECH EXCHANGE", "description": "NeoChip debuted as a publicly listed company on the NewTech Exchange.", "weight": 0.8}}], "semantic_groups": []}, "18": {"entities": [{"data": {"id": "NEW YORK", "label": "NEW YORK", "parent": "sg-31", "type": "LOCATION", "description": "State where incentives for renewable energy adoption were implemented", "community": 18, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f58231", "size": 25, "chunk_count": 1}}, {"data": {"id": "NI ET AL", "label": "NI ET AL", "parent": "comm-18", "type": "CONCEPT", "description": "Authors Ni et al. who provided the definition of a factual claim", "community": 18, "pagerank": 0.004566, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f58231", "size": 36, "chunk_count": 1}}, {"data": {"id": "CALIFORNIA", "label": "CALIFORNIA", "parent": "sg-31", "type": "LOCATION", "description": "State where incentives for renewable energy adoption were implemented", "community": 18, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f58231", "size": 25, "chunk_count": 1}}], "edges": [{"data": {"id": "CALIFORNIA-->NI ET AL", "source": "CALIFORNIA", "target": "NI ET AL", "description": "California is an example used in the definition provided by Ni et al.", "weight": 0.7}}, {"data": {"id": "NEW YORK-->NI ET AL", "source": "NEW YORK", "target": "NI ET AL", "description": "New York is an example used in the definition provided by Ni et al.", "weight": 0.7}}], "semantic_groups": [{"data": {"id": "sg-31", "label": "CALIFORNIA", "parent": "comm-18", "type": "SEMANTIC_GROUP", "group_id": 31, "canonical": "CALIFORNIA", "member_count": 2, "color": "#bfef45"}}]}, "19": {"entities": [{"data": {"id": "A_JOSHI", "label": "A.JOSHI", "parent": "comm-19", "type": "PERSON", "description": "Author of the paper who is also a co-author with P. Ranade", "community": 19, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#911eb4", "size": 25, "chunk_count": 1}}, {"data": {"id": "P_P_RANADE", "label": "P.P.RANADE", "parent": "comm-19", "type": "PERSON", "description": "Author of the paper who is also a co-author with A. Joshi", "community": 19, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#911eb4", "size": 25, "chunk_count": 1}}, {"data": {"id": "ARXIV_202310_13848", "label": "ARXIV:202310.13848", "parent": "comm-19", "type": "MONEY", "description": "Preprint identifier for arXiv submission", "community": 19, "pagerank": 0.004566, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#911eb4", "size": 36, "chunk_count": 1}}], "edges": [{"data": {"id": "A_JOSHI-->ARXIV_202310_13848", "source": "A_JOSHI", "target": "ARXIV_202310_13848", "description": "A.Joshi is an author of the arXiv preprint", "weight": 0.9}}, {"data": {"id": "P_P_RANADE-->ARXIV_202310_13848", "source": "P_P_RANADE", "target": "ARXIV_202310_13848", "description": "P.P. Ranade is the author of the arXiv preprint", "weight": 0.9}}], "semantic_groups": []}, "20": {"entities": [{"data": {"id": "ENTITY EXTRACTION", "label": "ENTITY EXTRACTION", "parent": "comm-20", "type": "EVENT", "description": "Process of identifying entities in text", "community": 20, "pagerank": 0.001691, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#42d4f4", "size": 25, "chunk_count": 1}}, {"data": {"id": "DEFAULT GRAPH EXTRACTION PROMPT", "label": "DEFAULT GRAPH EXTRACTION PROMPT", "parent": "sg-43", "type": "CONCEPT", "description": "Prompt used in the initialization pipeline", "community": 20, "pagerank": 0.00241, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#42d4f4", "size": 27, "chunk_count": 1}}, {"data": {"id": "CLAIM EXTRACTION PROMPT", "label": "CLAIM EXTRACTION PROMPT", "parent": "sg-43", "type": "CONCEPT", "description": "Prompt used in the initialization pipeline", "community": 20, "pagerank": 0.00241, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#42d4f4", "size": 27, "chunk_count": 1}}], "edges": [{"data": {"id": "ENTITY EXTRACTION-->DEFAULT GRAPH EXTRACTION PROMPT", "source": "ENTITY EXTRACTION", "target": "DEFAULT GRAPH EXTRACTION PROMPT", "description": "Entity Extraction uses the Default Graph Extraction Prompt to identify entities and their relationships", "weight": 0.8}}, {"data": {"id": "ENTITY EXTRACTION-->CLAIM EXTRACTION PROMPT", "source": "ENTITY EXTRACTION", "target": "CLAIM EXTRACTION PROMPT", "description": "Entity Extraction uses the Claim Extraction Prompt to identify entities and their relationships", "weight": 0.8}}], "semantic_groups": [{"data": {"id": "sg-43", "label": "DEFAULT GRAPH EXTRACTION PROMPT", "parent": "comm-20", "type": "SEMANTIC_GROUP", "group_id": 43, "canonical": "DEFAULT GRAPH EXTRACTION PROMPT", "member_count": 2, "color": "#bfef45"}}]}, "21": {"entities": [{"data": {"id": "ENTREPRENEURS", "label": "ENTREPRENEURS", "parent": "comm-21", "type": "PERSON", "description": "Individuals who start, manage, and operate businesses", "community": 21, "pagerank": 0.004566, "degree_centrality": 0.0043, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f032e6", "size": 36, "chunk_count": 1}}, {"data": {"id": "PUBLIC FIGURES IN CONTROVERSY", "label": "PUBLIC FIGURES IN CONTROVERSY", "parent": "comm-21", "type": "PERSON", "description": "Individuals involved in public disputes or controversies", "community": 21, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f032e6", "size": 25, "chunk_count": 1}}, {"data": {"id": "INFLUENCERS", "label": "INFLUENCERS", "parent": "comm-21", "type": "PERSON", "description": "Individuals with significant social media following and influence", "community": 21, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f032e6", "size": 25, "chunk_count": 1}}], "edges": [{"data": {"id": "PUBLIC FIGURES IN CONTROVERSY-->ENTREPRENEURS", "source": "PUBLIC FIGURES IN CONTROVERSY", "target": "ENTREPRENEURS", "description": "Public Figures in Controversy frequently involve themselves or are associated with Entrepreneurs", "weight": 0.6}}, {"data": {"id": "INFLUENCERS-->ENTREPRENEURS", "source": "INFLUENCERS", "target": "ENTREPRENEURS", "description": "Influencers often engage with Entrepreneurs for collaborations or endorsements", "weight": 0.5}}], "semantic_groups": []}, "22": {"entities": [{"data": {"id": "YATES ET AL_", "label": "YATES ET AL.", "parent": "comm-22", "type": "PERSON", "description": "Authors of a study on knowledge graph extraction", "community": 22, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#bfef45", "size": 30, "chunk_count": 1}}, {"data": {"id": "MOONEY AND BUNESCU", "label": "MOONEY AND BUNESCU", "parent": "comm-22", "type": "PERSON", "description": "Authors of a study on knowledge graph extraction", "community": 22, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#bfef45", "size": 25, "chunk_count": 1}}], "edges": [{"data": {"id": "MOONEY AND BUNESCU-->YATES ET AL_", "source": "MOONEY AND BUNESCU", "target": "YATES ET AL_", "description": "Mooney and Bunescu is a reference to Yates et al. in the text", "weight": 0.4}}], "semantic_groups": []}, "23": {"entities": [{"data": {"id": "ZHENG", "label": "ZHENG", "parent": "comm-23", "type": "PERSON", "description": "Author of a paper on LLM-as-a-judge method", "community": 23, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#fabed4", "size": 25, "chunk_count": 1}}, {"data": {"id": "ES", "label": "ES", "parent": "comm-23", "type": "PERSON", "description": "Author of a paper on context relevance, faithfulness and answer relevance", "community": 23, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#fabed4", "size": 30, "chunk_count": 1}}], "edges": [{"data": {"id": "ZHENG-->ES", "source": "ZHENG", "target": "ES", "description": "ZHENG et al. 2024 collaborated with ES et al. 2023", "weight": 0.8}}], "semantic_groups": []}, "24": {"entities": [{"data": {"id": "PODCAST", "label": "PODCAST", "parent": "sg-33", "type": "PRODUCT", "description": "Type of media content", "community": 24, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#469990", "size": 25, "chunk_count": 1}}, {"data": {"id": "NEWS ARTICLES", "label": "NEWS ARTICLES", "parent": "sg-33", "type": "PRODUCT", "description": "Type of media content", "community": 24, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#469990", "size": 30, "chunk_count": 1}}], "edges": [{"data": {"id": "PODCAST-->NEWS ARTICLES", "source": "PODCAST", "target": "NEWS ARTICLES", "description": "Podcast transcripts have a higher success rate than News articles", "weight": 0.8}}], "semantic_groups": [{"data": {"id": "sg-33", "label": "PODCAST", "parent": "comm-24", "type": "SEMANTIC_GROUP", "group_id": 33, "canonical": "PODCAST", "member_count": 2, "color": "#bfef45"}}]}, "25": {"entities": [{"data": {"id": "GRAPH INDEX", "label": "GRAPH INDEX", "parent": "comm-25", "type": "PRODUCT", "description": "Graph-based index service | Graph index technology product", "community": 25, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#dcbeff", "size": 25, "chunk_count": 2}}, {"data": {"id": "RAG APPROACHES", "label": "RAG APPROACHES", "parent": "comm-25", "type": "EVENT", "description": "Graph Retrieval Augmented (RAG) approaches", "community": 25, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#dcbeff", "size": 30, "chunk_count": 1}}], "edges": [{"data": {"id": "GRAPH INDEX-->RAG APPROACHES", "source": "GRAPH INDEX", "target": "RAG APPROACHES", "description": "Graph Index is a component of RAG Approaches", "weight": 0.8}}], "semantic_groups": []}, "26": {"entities": [{"data": {"id": "MAP-REDUCE SOURCE TEXT SUMMARIZATION", "label": "MAP-REDUCE SOURCE TEXT SUMMARIZATION", "parent": "comm-26", "type": "PRODUCT", "description": "Global but graph-free source text summarization method using map-reduce approach", "community": 26, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#9A6324", "size": 30, "chunk_count": 1}}, {"data": {"id": "VECTOR RAG BASELINE", "label": "VECTOR RAG BASELINE", "parent": "comm-26", "type": "PRODUCT", "description": "Baseline for vector-based RAG approach", "community": 26, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#9A6324", "size": 25, "chunk_count": 1}}], "edges": [{"data": {"id": "VECTOR RAG BASELINE-->MAP-REDUCE SOURCE TEXT SUMMARIZATION", "source": "VECTOR RAG BASELINE", "target": "MAP-REDUCE SOURCE TEXT SUMMARIZATION", "description": "Vector RAG baseline is compared to map-reduce source text summarization approach", "weight": 0.7}}], "semantic_groups": []}, "27": {"entities": [{"data": {"id": "ALONSO GUEVARA", "label": "ALONSO GUEVARA", "parent": "sg-2", "type": "PERSON", "description": "Contributor who worked on the project", "community": 27, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#fffac8", "size": 25, "chunk_count": 1}}, {"data": {"id": "FERN´ANDEZ", "label": "FERN´ANDEZ", "parent": "sg-2", "type": "PERSON", "description": "Contributor who worked on the project", "community": 27, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#fffac8", "size": 30, "chunk_count": 1}}], "edges": [{"data": {"id": "ALONSO GUEVARA-->FERN´ANDEZ", "source": "ALONSO GUEVARA", "target": "FERN´ANDEZ", "description": "Alonso Guevara and Fernández are co-authors", "weight": 0.8}}], "semantic_groups": [{"data": {"id": "sg-2", "label": "ALONSO GUEVARA", "parent": "comm-27", "type": "SEMANTIC_GROUP", "group_id": 2, "canonical": "ALONSO GUEVARA", "member_count": 2, "color": "#bfef45"}}]}, "28": {"entities": [{"data": {"id": "ARXIV_20231210997", "label": "ARXIV:20231210997", "parent": "comm-28", "type": "DATE", "description": "Publication date of a preprint paper", "community": 28, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#800000", "size": 25, "chunk_count": 1}}, {"data": {"id": "A SURVEY", "label": "A SURVEY", "parent": "comm-28", "type": "CONCEPT", "description": "Topic of a survey paper", "community": 28, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#800000", "size": 30, "chunk_count": 1}}], "edges": [{"data": {"id": "ARXIV_20231210997-->A SURVEY", "source": "ARXIV_20231210997", "target": "A SURVEY", "description": "arXiv preprint corresponds to a survey article", "weight": 0.8}}], "semantic_groups": []}, "29": {"entities": [{"data": {"id": "CIKM", "label": "CIKM", "parent": "comm-29", "type": "EVENT", "description": "Conference on Information and Knowledge Management", "community": 29, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#aaffc3", "size": 30, "chunk_count": 1}}, {"data": {"id": "IEEE", "label": "IEEE", "parent": "comm-29", "type": "ORGANIZATION", "description": "Institute of Electrical and Electronics Engineers | Organization that publishes intelligent systems", "community": 29, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#aaffc3", "size": 25, "chunk_count": 2}}], "edges": [{"data": {"id": "IEEE-->CIKM", "source": "IEEE", "target": "CIKM", "description": "CIKM is a conference published by IEEE", "weight": 0.8}}], "semantic_groups": []}, "30": {"entities": [{"data": {"id": "LEWIS", "label": "LEWIS", "parent": "sg-4", "type": "PERSON", "description": "Author of the paper 'Retrieval-augmented generation for knowledge-intensive nlp'", "community": 30, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 25, "chunk_count": 1}}, {"data": {"id": "PEREZ", "label": "PEREZ", "parent": "sg-4", "type": "PERSON", "description": "Author of the paper 'Retrieval-augmented generation for knowledge-intensive nlp'", "community": 30, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#e6194b", "size": 30, "chunk_count": 1}}], "edges": [{"data": {"id": "LEWIS-->PEREZ", "source": "LEWIS", "target": "PEREZ", "description": "Lewis is the first author of one paper and Perez is the first author of another paper", "weight": 0.6}}], "semantic_groups": [{"data": {"id": "sg-4", "label": "W.-T.", "parent": "comm-30", "type": "SEMANTIC_GROUP", "group_id": 4, "canonical": "W.-T.", "member_count": 2, "color": "#bfef45"}}]}, "31": {"entities": [{"data": {"id": "PADMAKUMAR", "label": "PADMAKUMAR", "parent": "sg-41", "type": "PERSON", "description": "Author of the paper 'Does writing with language models reduce content diversity'?", "community": 31, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 25, "chunk_count": 1}}, {"data": {"id": "HE HONG", "label": "HE HONG", "parent": "sg-41", "type": "PERSON", "description": "Author of the paper 'Does writing with language models reduce content diversity'?", "community": 31, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#3cb44b", "size": 30, "chunk_count": 1}}], "edges": [{"data": {"id": "PADMAKUMAR-->HE HONG", "source": "PADMAKUMAR", "target": "HE HONG", "description": "Padmakumar and He Hong are co-authors of a paper presented at ICLR in 2024", "weight": 0.7}}], "semantic_groups": [{"data": {"id": "sg-41", "label": "PADMAKUMAR", "parent": "comm-31", "type": "SEMANTIC_GROUP", "group_id": 41, "canonical": "PADMAKUMAR", "member_count": 2, "color": "#bfef45"}}]}, "32": {"entities": [{"data": {"id": "COMPUTATIONAL LINGUISTICS", "label": "COMPUTATIONAL LINGUISTICS", "parent": "comm-32", "type": "CONCEPT", "description": "Journal article title", "community": 32, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#4363d8", "size": 25, "chunk_count": 1}}, {"data": {"id": "ARXIV PREPRINT", "label": "ARXIV PREPRINT", "parent": "comm-32", "type": "CONCEPT", "description": "Preprint identifier for arXiv submission", "community": 32, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#4363d8", "size": 30, "chunk_count": 1}}], "edges": [{"data": {"id": "COMPUTATIONAL LINGUISTICS-->ARXIV PREPRINT", "source": "COMPUTATIONAL LINGUISTICS", "target": "ARXIV PREPRINT", "description": "Computational Linguistics references an arXiv preprint", "weight": 0.7}}], "semantic_groups": []}, "33": {"entities": [{"data": {"id": "TURBO", "label": "TURBO", "parent": "comm-33", "type": "PRODUCT", "description": "Model name or product", "community": 33, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f58231", "size": 30, "chunk_count": 1}}, {"data": {"id": "YANG ET AL", "label": "YANG ET AL", "parent": "comm-33", "type": "CONCEPT", "description": "Authors of the paper mentioned in the text", "community": 33, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f58231", "size": 25, "chunk_count": 1}}], "edges": [{"data": {"id": "YANG ET AL-->TURBO", "source": "YANG ET AL", "target": "TURBO", "description": "Yang et al. (2018) discusses Turbo", "weight": 0.7}}], "semantic_groups": []}, "34": {"entities": [{"data": {"id": "TRAAG ET AL_", "label": "TRAAG ET AL.", "parent": "comm-34", "type": "PERSON", "description": "Authors who used Leiden algorithm | Authors of the algorithm", "community": 34, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#911eb4", "size": 30, "chunk_count": 2}}, {"data": {"id": "LEEDEN ALGORITHM", "label": "LEEDEN ALGORITHM", "parent": "comm-34", "type": "EVENT", "description": "Algorithm used for community detection", "community": 34, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#911eb4", "size": 25, "chunk_count": 1}}], "edges": [{"data": {"id": "LEEDEN ALGORITHM-->TRAAG ET AL_", "source": "LEEDEN ALGORITHM", "target": "TRAAG ET AL_", "description": "Leiden algorithm is based on Traag et al. work", "weight": 0.8}}], "semantic_groups": []}, "35": {"entities": [{"data": {"id": "MULTIHOPE-RAG", "label": "MULTIHOPE-RAG", "parent": "comm-35", "type": "PRODUCT", "description": "Dataset used for community detection", "community": 35, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#42d4f4", "size": 25, "chunk_count": 1}}, {"data": {"id": "TANG AND YANG", "label": "TANG AND YANG", "parent": "comm-35", "type": "ORGANIZATION", "description": "Authors of the paper providing information about the benchmark dataset | Authors of the dataset", "community": 35, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#42d4f4", "size": 30, "chunk_count": 2}}], "edges": [{"data": {"id": "MULTIHOPE-RAG-->TANG AND YANG", "source": "MULTIHOPE-RAG", "target": "TANG AND YANG", "description": "MultiHop-RAG is based on Tang and Yang's research", "weight": 0.8}}], "semantic_groups": []}, "36": {"entities": [{"data": {"id": "ACTORS", "label": "ACTORS", "parent": "comm-36", "type": "PERSON", "description": "Individuals who act in movies or plays", "community": 36, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f032e6", "size": 25, "chunk_count": 1}}, {"data": {"id": "DIRECTORS", "label": "DIRECTORS", "parent": "comm-36", "type": "PERSON", "description": "Individuals who direct films or productions", "community": 36, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#f032e6", "size": 30, "chunk_count": 1}}], "edges": [{"data": {"id": "ACTORS-->DIRECTORS", "source": "ACTORS", "target": "DIRECTORS", "description": "Actors often collaborate with Directors in the industry", "weight": 0.7}}], "semantic_groups": []}, "37": {"entities": [{"data": {"id": "MUSICIANS", "label": "MUSICIANS", "parent": "comm-37", "type": "PERSON", "description": "Individuals who compose, perform, and/or produce music", "community": 37, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#bfef45", "size": 25, "chunk_count": 1}}, {"data": {"id": "EXECUTIVES", "label": "EXECUTIVES", "parent": "comm-37", "type": "PERSON", "description": "Individuals holding executive positions within organizations", "community": 37, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#bfef45", "size": 30, "chunk_count": 1}}], "edges": [{"data": {"id": "MUSICIANS-->EXECUTIVES", "source": "MUSICIANS", "target": "EXECUTIVES", "description": "Musicians often work closely with Executives within the industry", "weight": 0.7}}], "semantic_groups": []}, "38": {"entities": [{"data": {"id": "COACHES", "label": "COACHES", "parent": "comm-38", "type": "PERSON", "description": "Individuals who provide coaching for athletes or teams", "community": 38, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#fabed4", "size": 30, "chunk_count": 1}}, {"data": {"id": "ATHLETES", "label": "ATHLETES", "parent": "comm-38", "type": "PERSON", "description": "Individuals who participate in sports competitions or games", "community": 38, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#fabed4", "size": 25, "chunk_count": 1}}], "edges": [{"data": {"id": "ATHLETES-->COACHES", "source": "ATHLETES", "target": "COACHES", "description": "Athletes frequently have coaches to assist them in their careers", "weight": 0.6}}], "semantic_groups": []}, "39": {"entities": [{"data": {"id": "JEROME POWELL", "label": "JEROME POWELL", "parent": "comm-39", "type": "PERSON", "description": "Jerome Powell is the chair of the Federal Reserve | Chair of the Federal Reserve who will answer questions at a press conference", "community": 39, "pagerank": 0.003129, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#469990", "size": 30, "chunk_count": 2}}, {"data": {"id": "FEDERAL OPEN MARKET COMMITTEE", "label": "FEDERAL OPEN MARKET COMMITTEE", "parent": "comm-39", "type": "ORGANIZATION", "description": "Committee that makes key decisions about interest rates and the growth of the United States money supply", "community": 39, "pagerank": 0.001691, "degree_centrality": 0.0022, "betweenness": 0.0, "num_sources": 1, "source_refs": "[\"arxiv:2404.16130\"]", "color": "#469990", "size": 25, "chunk_count": 1}}], "edges": [{"data": {"id": "FEDERAL OPEN MARKET COMMITTEE-->JEROME POWELL", "source": "FEDERAL OPEN MARKET COMMITTEE", "target": "JEROME POWELL", "description": "Jerome Powell is the Chair of the Federal Reserve Committee", "weight": 0.9}}], "semantic_groups": []}}, "chunkTexts": ["of comprehensiveness) per condition. For both the News and Podcast datasets, all global search\nconditions (C0-C3) and source text summarization (TS) had greater comprehensiveness than vector\nRAG (SS). The differences were statistically significant (p<.05) in all cases. These findings align\nwith the LLM-based win rates from Experiment 1.\nTable 4 contains the results for the average number of clusters, the claim-based measure of diver-\nsity. For the Podcast dataset, all global search conditions had significantly greater diversity than SS", "p-value\nComprehensiveness\nC0\nTS\n50.24\n49.76\n-0.06\n1\n55.52\n44.48\n-2.03\n0.17\nC1\nTS\n51.92\n48.08\n-1.56\n0.633\n58.8\n41.2\n-3.62\n0.002\nC2\nTS\n57.28\n42.72\n-4.1\n<0.001\n62.08\n37.92\n-5.07\n<0.001\nC3\nTS\n56.48\n43.52\n-3.42\n0.006\n63.6\n36.4\n-5.63\n<0.001\nC0\nSS\n71.92\n28.08\n-6.2\n<0.001\n71.76\n28.24\n-6.3\n<0.001\nC1\nSS\n75.44\n24.56\n-7.45\n<0.001\n74.72\n25.28\n-7.78\n<0.001\nC2\nSS\n77.76\n22.24\n-8.17\n<0.001\n79.2\n20.8\n-8.34\n<0.001\nC3\nSS\n78.96\n21.04\n-8.12\n<0.001\n79.44\n20.56\n-8.44\n<0.001\nTS\nSS\n83.12\n16.88\n-8.85\n<0.001\n79.6\n20.4\n-8.27\n<0.001\nC0\nC1\n53.2\n46.8\n-1.96\n0.389\n51.92\n48.08\n-0.45\n0.777\nC0\nC2\n50.24\n49.76\n-0.23\n1\n53.68\n46.32", "the annotation of factual claim detection with reliable LLM annotators. In Ku, L.-W., Martins, A.,\nand Srikumar, V., editors, Proceedings of the 62nd Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages 1890–1912, Bangkok, Thailand. Association\nfor Computational Linguistics.\nOpenAI (2023). Chatgpt: Gpt-4 language model.\nPadmakumar, V. and He, H. (2024). Does writing with language models reduce content diversity?\nICLR.\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Pret-", "J. D., editors, Proceedings of Human Language Technologies: The Annual Conference of the\nNorth American Chapter of the Association for Computational Linguistics (NAACL-HLT), pages\n25–26, Rochester, New York, USA. Association for Computational Linguistics.\nYuan, X., Li, J., Wang, D., Chen, Y., Mao, X., Huang, L., Xue, H., Wang, W., Ren, K., and Wang,\nJ. (2024). S-eval: Automatic and adaptive test generation for benchmarking safety evaluation of\nlarge language models. arXiv preprint arXiv:2405.14191.\nZhang, J. (2023). Graph-toolformer: To empower llms with graph reasoning ability via prompt", "within the community. Otherwise, rank sub-communities in decreasing order of element\nsummary tokens and iteratively substitute sub-community summaries (shorter) for their\nassociated element summaries (longer) until they fit within the context window.\n3.1.6\nCommunity Summaries →Community Answers →Global Answer\nGiven a user query, the community summaries generated in the previous step can be used to generate\na final answer in a multi-stage process. The hierarchical nature of the community structure also", "2016; Mooney and Bunescu, 2005; Yates et al., 2007). GraphRAG falls into a more recent body of\nresearch that use of LLMs for knowledge graph extraction (Ban et al., 2023; Melnyk et al., 2022;\nOpenAI, 2023; Tan et al., 2017; Trajanoska et al., 2023; Yao et al., 2023; Yates et al., 2007; Zhang\net al., 2024a). It also adds to a growing body of RAG approaches that use a knowledge graph as\nan index (Gao et al., 2023). Some techniques use subgraphs, elements of the graph, or properties\nof the graph structure directly in the prompt (Baek et al., 2023; He et al., 2024; Zhang, 2023)", "4.1.3\nConfiguration\nWe used a fixed context window size of 8k tokens for generating community summaries, community\nanswers, and global answers (explained in Appendix C). Graph indexing with a 600 token window\n(explained in Section A.2) took 281 minutes for the Podcast dataset, running on a virtual machine\n(16GB RAM, Intel(R) Xeon(R) Platinum 8171M CPU @ 2.60GHz) and using a public OpenAI\nendpoint for gpt-4-turbo (2M TPM, 10k RPM).\nWe implemented Leiden community detection using the graspologic library (Chung et al., 2019).", "same dataset, summaries of root-level communities in the entity-based graph index provide a data\nindex that is both superior to vector RAG and achieves competitive performance to other global\nmethods at a fraction of the token cost.\nAcknowledgements\nWe would also like to thank the following people who contributed to the work: Alonso Guevara\nFern´andez, Amber Hoak, Andr´es Morales Esquivel, Ben Cutler, Billie Rinaldi, Chris Sanchez,\nChris Trevino, Christine Caggiano, David Tittsworth, Dayenne de Souza, Douglas Orbaker, Ed", "sign criteria for evaluating RAG-generated answers to global sensemaking questions and evaluate\nour results using the comparative approach. We also validate results using statistics derived from\nLLM-extracted statements of verifiable facts, or “claims.”\n3\nMethods\n3.1\nGraphRAG Workflow\nFigure 1 illustrates the high-level data flow of the GraphRAG approach and pipeline. In this section,\nwe describe the key design parameters, techniques, and implementation details for each step.\n3.1.1\nSource Documents →Text Chunks", "Wang et al., 2024). In particular, GraphRAG is similar to other approaches that use hierarchical\nindexing to create summaries (similar to Kim et al. 2023; Sarthi et al. 2024). GraphRAG contrasts\nwith these approaches by generating a graph index from the source data, then applying graph-based\ncommunity detection to create a thematic partitioning of the data.\n2.2\nUsing Knowledge Graphs with LLMs and RAG\nApproaches to knowledge graph extraction from natural language text corpora include rule-\nmatching, statistical pattern recognition, clustering, and embeddings (Etzioni et al., 2004; Kim et al.,", "A\nEntity and Relationship Extraction Approach\nThe following prompts, designed for GPT-4, are used in the default GraphRAG initialization\npipeline:\n• Default Graph Extraction Prompt\n• Claim Extraction Prompt\nA.1\nEntity Extraction\nWe do this using a multipart LLM prompt that first identifies all entities in the text, including their\nname, type, and description, before identifying all relationships between clearly related entities,\nincluding the source and target entities and a description of their relationship. Both kinds of element\ninstance are output in a single list of delimited tuples.\nA.2", "We implemented Leiden community detection using the graspologic library (Chung et al., 2019).\nThe prompts used to generate the graph index and global answers can be found in Appendix E,\nwhile the prompts used to evaluate LLM responses against our criteria can be found in Appendix F.\nA full statistical analysis of the results presented in the next section can be found in Appendix G.\n4.2\nExperiment 2\nTo validate the comprehensiveness and diversity results from Experiment 1, we implemented claim-\nbased measures of these qualities. We use the definition of a factual claim from Ni et al. (2024),", "utility as part of a graph-based index used for answering global queries.\nGraphRAG generates community summaries by adding various element summaries (for nodes,\nedges, and related claims) to a community summary template. Community summaries from lower-\nlevel communities are used to generate summaries for higher-level communities as follows:\n• Leaf-level communities. The element summaries of a leaf-level community are prioritized\nand then iteratively added to the LLM context window until the token limit is reached.", "19.70\n17.39\n0.7\n20.41\n20.04\n19.79\n19.22\n18.08\n16.28\n0.8\n19.26\n18.77\n18.46\n17.89\n16.66\n15.07\n6.2\nFuture work\nThe graph index, rich text annotations, and hierarchical community structure supporting the current\nGraphRAG approach offer many possibilities for refinement and adaptation. This includes RAG\napproaches that operate in a more local manner, via embedding-based matching of user queries and\ngraph annotations. In particular, we see potential in hybrid RAG schemes that combine embedding-\nbased matching with just-in-time community report generation before employing our map-reduce", "across these sectors. The following summary highlights key individuals who are repeatedly\nmentioned in various entertainment articles, reflecting their impact and presence within the industry.\nActors and Directors [...] Public Figures in Controversy [...] Musicians and Executives [...]\nAthletes and Coaches [...] Influencers and Entrepreneurs [...]\nThe repeated mention of these figures in entertainment articles signifies their ongoing relevance and\nthe public’s interest in their work. Their influence spans across various aspects of entertainment, from", "Computational Linguistics, 11:1316–1331.\nRanade, P. and Joshi, A. (2023). Fabula: Intelligence report generation using retrieval-augmented\nnarrative construction. arXiv preprint arXiv:2310.13848.\nSalminen, J., Liu, C., Pian, W., Chi, J., H¨ayh¨anen, E., and Jansen, B. J. (2024). Deus ex machina\nand personas from large language models: Investigating the composition of ai-generated persona\ndescriptions. In Proceedings of the CHI Conference on Human Factors in Computing Systems,\npages 1–20.\nSarthi, P., Abdullah, S., Tuli, A., Khanna, S., Goldie, A., and Manning, C. D. (2024). Raptor:", "---Example---\nInput:\nEntities\nid,entity,description\n5,VERDANT OASIS PLAZA,Verdant Oasis Plaza is the location of the Unity March\n6,HARMONY ASSEMBLY,Harmony Assembly is an organization that is holding a march at Verdant Oasis Plaza\nRelationships\nid,source,target,description\n37,VERDANT OASIS PLAZA,UNITY MARCH,Verdant Oasis Plaza is the location of the Unity March\n38,VERDANT OASIS PLAZA,HARMONY ASSEMBLY,Harmony Assembly is holding a march at Verdant Oasis Plaza\n39,VERDANT OASIS PLAZA,UNITY MARCH,The Unity March is taking place at Verdant Oasis Plaza", "{{\n\"title\":\n\"Verdant Oasis Plaza and Unity March\",\n\"summary\":\n\"The community revolves around the Verdant Oasis Plaza, which is the location of the Unity\nMarch.\nThe plaza has relationships with the Harmony Assembly, Unity March, and Tribune Spotlight, all of\nwhich are associated with the march event.\",\n\"rating\":\n5.0,\n\"rating explanation\":\n\"The impact severity rating is moderate due to the potential for unrest or conflict\nduring the Unity March.\",\n\"findings\":\n[\n{{\n\"summary\":\n\"Verdant Oasis Plaza as the central location\",\n\"explanation\":", "\"findings\":\n[\n{{\n\"summary\":\n\"Verdant Oasis Plaza as the central location\",\n\"explanation\":\n\"Verdant Oasis Plaza is the central entity in this community, serving as the location for\nthe Unity March.\nThis plaza is the common link between all other entities, suggesting its significance\nin the community.\nThe plaza’s association with the march could potentially lead to issues such as\npublic disorder or conflict, depending on the nature of the march and the reactions it provokes.\n[Data:\nEntities (5), Relationships (37, 38, 39, 40, 41,+more)]\"\n}},\n{{\n\"summary\":", "[Data:\nEntities (5), Relationships (37, 38, 39, 40, 41,+more)]\"\n}},\n{{\n\"summary\":\n\"Harmony Assembly’s role in the community\",\n\"explanation\":\n\"Harmony Assembly is another key entity in this community, being the organizer of the\nmarch at Verdant Oasis Plaza.\nThe nature of Harmony Assembly and its march could be a potential source of\nthreat, depending on their objectives and the reactions they provoke.\nThe relationship between Harmony\nAssembly and the plaza is crucial in understanding the dynamics of this community.\n[Data:\nEntities(6),\nRelationships (38, 43)]\"\n}},\n{{\n\"summary\":", "generated texts such as “fluency” (Wang et al., 2023a) Some of these criteria are generic to vector\nRAG systems and not relevant to global sensemaking, such as “context relevance”, “faithfulness”,\nand “answer relevance” (RAGAS, Es et al. 2023). Lacking a gold standard for evaluation, one can\nquantify relative performance for a given criterion by prompting the LLM to compare generations\nfrom two different competing models (LLM-as-a-judge, (Zheng et al., 2024)). In this work, we de-\nsign criteria for evaluating RAG-generated answers to global sensemaking questions and evaluate", "based measures of these qualities. We use the definition of a factual claim from Ni et al. (2024),\nwhich is “a statement that explicitly presents some verifiable facts.” For example, the sentence\n“California and New York implemented incentives for renewable energy adoption, highlighting the\nbroader importance of sustainability in policy decisions” contains two factual claims: (1) California\nimplemented incentives for renewable energy adoption, and (2) New York implemented incentives\nfor renewable energy adoption.", "Laskar, M. T. R., Hoque, E., and Huang, J. (2020). Query focused abstractive summarization via\nincorporating query relevance and transfer learning with transformer models. In Advances in\nArtificial Intelligence: 33rd Canadian Conference on Artificial Intelligence, Canadian AI 2020,\nOttawa, ON, Canada, May 13–15, 2020, Proceedings 33, pages 342–348. Springer.\nLewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., K¨uttler, H., Lewis, M., Yih,\nW.-t., Rockt¨aschel, T., et al. (2020). Retrieval-augmented generation for knowledge-intensive nlp", "Abstract\nThe use of retrieval-augmented generation (RAG) to retrieve relevant informa-\ntion from an external knowledge source enables large language models (LLMs)\nto answer questions over private and/or previously unseen document collections.\nHowever, RAG fails on global questions directed at an entire text corpus, such\nas “What are the main themes in the dataset?”, since this is inherently a query-\nfocused summarization (QFS) task, rather than an explicit retrieval task. Prior\nQFS methods, meanwhile, do not scale to the quantities of text indexed by typ-", "ships. GraphRAG contrasts with these approaches by focusing on a previously unexplored quality of\ngraphs in this context: their inherent modularity (Newman, 2006) and the ability to partition graphs\ninto nested modular communities of closely related nodes (e.g., Louvain, Blondel et al. 2008; Lei-\nden, Traag et al. 2019). Specifically, GraphRAG recursively creates increasingly global summaries\nby using the LLM to create summaries spanning this community hierarchy.\n2.3\nAdaptive benchmarking for RAG Evaluation", "tion with llm based on knowledge graphs. https://www.nebula-graph.io/posts/graph-RAG.\nNeo4J (2024). Get started with graphrag: Neo4j’s ecosystem tools. https://neo4j.com/developer-\nblog/graphrag-ecosystem-tools/.\nNewman, M. E. (2006). Modularity and community structure in networks. Proceedings of the\nnational academy of sciences, 103(23):8577–8582.\nNi, J., Shi, M., Stammbach, D., Sachan, M., Ash, E., and Leippold, M. (2024). AFaCTA: Assisting\nthe annotation of factual claim detection with reliable LLM annotators. In Ku, L.-W., Martins, A.,", "---Goal---\nWrite a comprehensive report of a community, given a list of entities that belong to the community as well\nas their relationships and optional associated claims.\nThe report will be used to inform decision-makers\nabout information associated with the community and their potential impact.\nThe content of this report\nincludes an overview of the community’s key entities, their legal compliance, technical capabilities,\nreputation, and noteworthy claims.\n---Report Structure---\nThe report should include the following sections:", "ET, followed by a press conference where Fed Chair\nJerome Powell will take questions.\nInvestors expect the Federal Open Market Committee to hold its\nbenchmark interest rate steady in a range of 5.25%-5.5%.\nOutput:\n(\"entity\"{tuple delimiter}FED{tuple delimiter}ORGANIZATION{tuple delimiter}The Fed is the Federal Reserve,\nwhich is setting interest rates on Tuesday and Wednesday)\n{record delimiter}\n(\"entity\"{tuple delimiter}JEROME POWELL{tuple delimiter}PERSON{tuple delimiter}Jerome Powell is the chair\nof the Federal Reserve)\n{record delimiter}", "of the Federal Reserve)\n{record delimiter}\n(\"entity\"{tuple delimiter}FEDERAL OPEN MARKET COMMITTEE{tuple delimiter}ORGANIZATION{tuple delimiter}The\nFederal Reserve committee makes key decisions about interest rates and the growth of the United States\nmoney supply)\n{record delimiter}\n(\"relationship\"{tuple delimiter}JEROME POWELL{tuple delimiter}FED{tuple delimiter}Jerome Powell is the\nChair of the Federal Reserve and will answer questions at a press conference{tuple delimiter}9)\n{completion delimiter}\n...More examples...\n---Real Data---\nEntity types:\n{entity types}\nInput:\n{input text}\nOutput:", "NeoChip’s (NC) shares surged in their first week of trading on the NewTech Ex-\nchange. However, market analysts caution that the chipmaker’s public debut may\nnot reflect trends for other technology IPOs. NeoChip, previously a private entity,\nwas acquired by Quantum Systems in 2016. The innovative semiconductor firm\nspecializes in low-power processors for wearables and IoT devices.\nThe LLM is prompted such that it extracts the following:\n• The entity NeoChip, with description “NeoChip is a publicly traded company specializing\nin low-power processors for wearables and IoT devices.”", "in low-power processors for wearables and IoT devices.”\n• The entity Quantum Systems, with description “Quantum Systems is a firm that previ-\nously owned NeoChip.”\n• A relationship between NeoChip and Quantum Systems, with description “Quantum Sys-\ntems owned NeoChip from 2016 until NeoChip became publicly traded.”\nThese prompts can be tailored to the domain of the document corpus by choosing domain appropriate\nfew-shot exemplars for in-context learning (Brown et al., 2020). For example, while our default", "factual statements about entities, such as dates, events, and interactions with other entities. As\nwith entities and relationships, in-context learning exemplars can provide domain-specific guidance.\nClaim descriptions extracted from the example tetx chunk are as follows:\n• NeoChip’s shares surged during their first week of trading on the NewTech Exchange.\n• NeoChip debuted as a publicly listed company on the NewTech Exchange.\n• Quantum Systems acquired NeoChip in 2016 and held ownership until NeoChip went pub-\nlic.", "Source Documents\nText Chunks\ntext extraction\nand chunking\nEntities & Relationships\ndomain-tailored\nsummarization\nKnowledge Graph\ndomain-tailored\nsummarization\nGraph Communities\ncommunity\ndetection\nCommunity Summaries\ndomain-tailored\nsummarization\nCommunity Answers\nquery-focused\nsummarization\nGlobal Answer\nquery-focused\nsummarization\nIndexing Time\nQuery Time\nPipeline Stage\nFigure 1: Graph RAG pipeline using an LLM-derived graph index of source document text. This\ngraph index spans nodes (e.g., entities), edges (e.g., relationships), and covariates (e.g., claims)", "From Local to Global: A GraphRAG Approach to\nQuery-Focused Summarization\nDarren Edge1†\nHa Trinh1†\nNewman Cheng2\nJoshua Bradley2\nAlex Chao3\nApurva Mody3\nSteven Truitt2\nDasha Metropolitansky1\nRobert Osazuwa Ness1\nJonathan Larson1\n1Microsoft Research\n2Microsoft Strategic Missions and Technologies\n3Microsoft Office of the CTO\n{daedge,trinhha,newmancheng,joshbradley,achao,moapurva,\nsteventruitt,dasham,robertness,jolarso}@microsoft.com\n†These authors contributed equally to this work\nAbstract\nThe use of retrieval-augmented generation (RAG) to retrieve relevant informa-", "generates a response based on both the query and the retrieved records (Baumel et al., 2018; Dang,\n2006; Laskar et al., 2020; Yao et al., 2017). This conventional approach, which we collectively call\nvector RAG, works well for queries that can be answered with information localized within a small\nset of records. However, vector RAG approaches do not support sensemaking queries, meaning\nqueries that require global understanding of the entire dataset, such as ”What are the key trends in\nhow scientific discoveries are influenced by interdisciplinary research over the past decade?”", "since duplicates are typically clustered together for summarization in subsequent steps.\n3.1.4\nKnowledge Graph →Graph Communities\nGiven the graph index created in the previous step, a variety of community detection algorithms\nmay be used to partition the graph into communities of strongly connected nodes (e.g., see the\nsurveys by Fortunato (2010) and Jin et al. (2021)). In our pipeline, we use Leiden community\ndetection (Traag et al., 2019) in a hierarchical manner, recursively detecting sub-communities within", "chunks, with 100-token overlaps between chunks (∼1.7 million tokens).\n4.1.2\nConditions\nWe compared six conditions including GraphRAG at four different graph community levels (C0,\nC1, C2, C3), a text summarization method that applies our map-reduce approach directly to source\ntexts (TS), and a vector RAG “semantic search” approach (SS):\n• CO. Uses root-level community summaries (fewest in number) to answer user queries.\n• C1. Uses high-level community summaries to answer queries. These are sub-communities\nof C0, if present, otherwise C0 communities projected downwards.", "The overall winner per dataset and metric is shown in bold. Self-win rates were not computed but\nare shown as the expected 50% for reference. All Graph RAG conditions outperformed na¨ıve RAG\non comprehensiveness and diversity. Conditions C1-C3 also showed slight improvements in answer\ncomprehensiveness and diversity over TS (global text summarization without a graph index).\nTable 2: Number of context units (community summaries for C0-C3 and text chunks for TS), corre-\nsponding token counts, and percentage of the maximum token count. Map-reduce summarization of", "Table 3: Average number of extracted claims, reported by condition and dataset type. Bolded values\nrepresent the highest score in each column.\nCondition\nAverage Number of Claims\nNews Articles\nPodcast Transcripts\nC0\n34.18\n32.21\nC1\n32.50\n32.20\nC2\n31.62\n32.46\nC3\n33.14\n32.28\nTS\n32.89\n31.39\nSS\n25.23\n26.50\n5.2\nExperiment 2\nTable 3 shows the results for the average number of extracted claims (i.e., the claim-based measure\nof comprehensiveness) per condition. For both the News and Podcast datasets, all global search", "dicated that the data did not follow a normal distribution. Thus, non-parametric tests (Wilcoxon\nsigned-rank tests) were employed to assess the performance differences between pairs of condi-\ntions, with Holm-Bonferroni correction applied to account for multiple pairwise comparisons. The\ncorrected p-values that indicated statistically significant differences are highlighted in bold.\nPodcast Transcripts\nNews Articles\nCondition 1\nCondition 2\nMean 1\nMean 2\nZ-value\np-value\nMean 1\nMean 2\nZ-value\np-value\nComprehensiveness\nC0\nTS\n50.24\n49.76\n-0.06\n1\n55.52\n44.48\n-2.03\n0.17\nC1\nTS\n51.92\n48.08\n-1.56", "-3.47\n0.004\nC1\nC3\n45.44\n54.56\n-2.98\n0.026\n49.52\n50.48\n-0.01\n1\nC2\nC3\n48.48\n51.52\n-0.96\n1\n50.96\n49.04\n-0.39\n1\nEmpowerment\nC0\nTS\n40.96\n59.04\n-4.3\n<0.001\n42.24\n57.76\n-3.32\n0.012\nC1\nTS\n45.2\n54.8\n-3.76\n0.002\n50\n50\n-0.12\n1\nC2\nTS\n47.68\n52.32\n-2.2\n0.281\n49.52\n50.48\n-0.22\n1\nC3\nTS\n48.72\n51.28\n-1.27\n1\n51.68\n48.32\n-1.2\n1\nC0\nSS\n42.96\n57.04\n-3.71\n0.003\n42.72\n57.28\n-3.12\n0.022\nC1\nSS\n47.68\n52.32\n-1.5\n0.936\n51.36\n48.64\n-0.84\n1\nC2\nSS\n50.72\n49.28\n-0.55\n1\n49.84\n50.16\n-0.2\n1\nC3\nSS\n48.96\n51.04\n-0.57\n1\n49.52\n50.48\n-0.08\n1\nTS\nSS\n57.52\n42.48\n-4.1\n<0.001\n52.88\n47.12\n-1.1\n1\nC0\nC1\n48.72\n51.28\n-1.23\n1\n42.4\n57.6\n-3.9\n0.001", "1\nTS\nSS\n57.52\n42.48\n-4.1\n<0.001\n52.88\n47.12\n-1.1\n1\nC0\nC1\n48.72\n51.28\n-1.23\n1\n42.4\n57.6\n-3.9\n0.001\nC0\nC2\n46.64\n53.36\n-2.54\n0.12\n44.8\n55.2\n-2.16\n0.336\nC1\nC2\n49.28\n50.72\n-1.73\n0.682\n52\n48\n-1.45\n1\nC0\nC3\n47.6\n52.4\n-1.78\n0.682\n44.32\n55.68\n-3.45\n0.008\nC1\nC3\n50\n50\n0\n1\n51.44\n48.56\n-1.02\n1\nC2\nC3\n50.72\n49.28\n-0.86\n1\n50.4\n49.6\n-0.22\n1\nDirectness\nC0\nTS\n44.96\n55.04\n-4.09\n<0.001\n45.2\n54.8\n-3.68\n0.003\nC1\nTS\n47.92\n52.08\n-2.41\n0.126\n46.64\n53.36\n-2.91\n0.04\nC2\nTS\n48.8\n51.2\n-2.23\n0.179\n48.32\n51.68\n-2.12\n0.179\nC3\nTS\n48.08\n51.92\n-2.23\n0.179\n48.32\n51.68\n-2.56\n0.074\nC0\nSS\n35.12\n64.88\n-6.17\n<0.001\n41.44\n58.56\n-4.82", "TS\n48.08\n51.92\n-2.23\n0.179\n48.32\n51.68\n-2.56\n0.074\nC0\nSS\n35.12\n64.88\n-6.17\n<0.001\n41.44\n58.56\n-4.82\n<0.001\nC1\nSS\n40.32\n59.68\n-4.83\n<0.001\n45.2\n54.8\n-3.19\n0.017\nC2\nSS\n40.4\n59.6\n-4.67\n<0.001\n44.88\n55.12\n-3.65\n0.003\nC3\nSS\n40.48\n59.52\n-4.69\n<0.001\n45.6\n54.4\n-2.86\n0.043\nTS\nSS\n43.6\n56.4\n-3.96\n<0.001\n46\n54\n-2.68\n0.066\nC0\nC1\n46.96\n53.04\n-2.87\n0.037\n47.6\n52.4\n-2.17\n0.179\nC0\nC2\n48.4\n51.6\n-2.06\n0.197\n48.48\n51.52\n-1.61\n0.321\nC1\nC2\n49.84\n50.16\n-1\n0.952\n49.28\n50.72\n-1.6\n0.321\nC0\nC3\n48.4\n51.6\n-1.8\n0.29\n47.2\n52.8\n-2.62\n0.071\nC1\nC3\n49.76\n50.24\n0\n1\n48.8\n51.2\n-1.29\n0.321\nC2\nC3\n50\n50\n0\n1\n48.8\n51.2\n-1.84\n0.262\n26", "83% (p<.001) for Podcast transcripts and 72-80% (p<.001) for News articles, while diversity win\nrates ranged from 75-82% (p<.001) and 62-71% (p<.01) respectively. Our use of directness as a\nvalidity test confirmed that vector RAG produces the most direct responses across all comparisons.\nEmpowerment. Empowerment comparisons showed mixed results for both global approaches ver-\nsus vector RAG (SS) and GraphRAG approaches versus source text summarization (TS). Using an\nLLM to analyze LLM reasoning for this measure indicated that the ability to provide specific exam-\n9", "well-connected communities. Scientific Reports, 9(1).\nTrajanoska, M., Stojanov, R., and Trajanov, D. (2023). Enhancing knowledge graph construction\nusing large language models. ArXiv, abs/2305.04676.\nTrivedi, H., Balasubramanian, N., Khot, T., and Sabharwal, A. (2022).\nInterleaving retrieval\nwith chain-of-thought reasoning for knowledge-intensive multi-step questions. arXiv preprint\narXiv:2212.10509.\nWang, J., Liang, Y., Meng, F., Sun, Z., Shi, H., Li, Z., Xu, J., Qu, J., and Zhou, J. (2023a). Is chatgpt\na good nlg evaluator? a preliminary study. arXiv preprint arXiv:2303.04048.", "that have been detected, extracted, and summarized by LLM prompts tailored to the domain of the\ndataset. Community detection (e.g., Leiden, Traag et al., 2019) is used to partition the graph index\ninto groups of elements (nodes, edges, covariates) that the LLM can summarize in parallel at both\nindexing time and query time. The “global answer” to a given query is produced using a final round\nof query-focused summarization over all community summaries reporting relevance to that query.\ngenerated texts such as “fluency” (Wang et al., 2023a) Some of these criteria are generic to vector", "(a) Root communities at level 0\n(b) Sub-communities at level 1\nFigure 4: Graph communities detected using the Leiden algorithm (Traag et al., 2019) over the\nMultiHop-RAG (Tang and Yang, 2024) dataset as indexed. Circles represent entity nodes with size\nproportional to their degree. Node layout was performed via OpenORD (Martin et al., 2011) and\nForce Atlas 2 (Jacomy et al., 2014). Node colors represent entity communities, shown at two levels\nof hierarchical clustering: (a) Level 0, corresponding to the hierarchical partition with maximum", "and incremental approaches. In Proceedings of the 25th ACM International on Conference on\nInformation and Knowledge Management, CIKM ’16, page 2257–2262, New York, NY, USA.\nAssociation for Computing Machinery.\nKim, G., Kim, S., Jeon, B., Park, J., and Kang, J. (2023). Tree of clarifications: Answering ambigu-\nous questions with retrieval-augmented large language models. arXiv preprint arXiv:2310.14696.\nKlein, G., Moon, B., and Hoffman, R. R. (2006). Making sense of sensemaking 1: Alternative\nperspectives. IEEE intelligent systems, 21(4):70–73.", "-2.39\n0.1\n60.16\n39.84\n-4.07\n<0.001\nC0\nSS\n76.56\n23.44\n-7.12\n<0.001\n62.08\n37.92\n-3.57\n0.003\nC1\nSS\n75.44\n24.56\n-7.33\n<0.001\n64.96\n35.04\n-4.92\n<0.001\nC2\nSS\n80.56\n19.44\n-8.21\n<0.001\n70.56\n29.44\n-6.29\n<0.001\nC3\nSS\n80.8\n19.2\n-8.3\n<0.001\n69.12\n30.88\n-5.53\n<0.001\nTS\nSS\n82.08\n17.92\n-8.43\n<0.001\n67.2\n32.8\n-4.85\n<0.001\nC0\nC1\n49.76\n50.24\n-0.13\n1\n39.68\n60.32\n-3.61\n0.003\nC0\nC2\n46.32\n53.68\n-1.5\n0.669\n40.96\n59.04\n-3.14\n0.012\nC1\nC2\n44.08\n55.92\n-3.27\n0.011\n50.24\n49.76\n-0.22\n1\nC0\nC3\n44\n56\n-2.6\n0.065\n41.04\n58.96\n-3.47\n0.004\nC1\nC3\n45.44\n54.56\n-2.98\n0.026\n49.52\n50.48\n-0.01\n1\nC2\nC3\n48.48\n51.52\n-0.96\n1\n50.96\n49.04", "perspectives. IEEE intelligent systems, 21(4):70–73.\nKosinski, M. (2024). Evaluating large language models in theory of mind tasks. Proceedings of the\nNational Academy of Sciences, 121(45):e2405460121.\nKuratov, Y., Bulatov, A., Anokhin, P., Sorokin, D., Sorokin, A., and Burtsev, M. (2024). In search\nof needles in a 11m haystack: Recurrent memory finds what llms miss.\nLangChain (2024). Langchain graphs. https://langchain-graphrag.readthedocs.io/en/latest/.\nLaskar, M. T. R., Hoque, E., and Huang, J. (2020). Query focused abstractive summarization via", "generation, where the LLM is used to generate diverse and authentic sets of personas (Kosinski,\n2024; Salminen et al., 2024; Shin et al., 2024). Our adaptive benchmarking procedure uses persona\ngeneration to create queries that are representative of real-world RAG system usage. Specifically,\nour approach uses the LLM to infer the potential users would use the RAG system and their use\ncases, which guide the generation of corpus-specific sensemaking queries.\n2.4\nRAG evaluation criteria\nOur evaluation relies on the LLM to evaluate how well the RAG system answers the generated ques-", "Conclusion\nWe have presented GraphRAG, a RAG approach that combines knowledge graph generation and\nquery-focused summarization (QFS) to support human sensemaking over entire text corpora. Initial\nevaluations show substantial improvements over a vector RAG baseline for both the comprehensive-\nness and diversity of answers, as well as favorable comparisons to a global but graph-free approach\nusing map-reduce source text summarization. For situations requiring many global queries over the\nsame dataset, summaries of root-level communities in the entity-based graph index provide a data", "Jacomy, M., Venturini, T., Heymann, S., and Bastian, M. (2014). Forceatlas2, a continuous graph\nlayout algorithm for handy network visualization designed for the gephi software. PLoS ONE\n9(6): e98679. https://doi.org/10.1371/journal.pone.0098679.\nJin, D., Yu, Z., Jiao, P., Pan, S., He, D., Wu, J., Philip, S. Y., and Zhang, W. (2021). A survey of\ncommunity detection approaches: From statistical modeling to deep learning. IEEE Transactions\non Knowledge and Data Engineering, 35(2):1149–1170.\nKang, M., Kwak, J. M., Baek, J., and Hwang, S. J. (2023). Knowledge graph-augmented language", "summaries) are shuffled and chunked for the map-reduce summarization stages.\n• SS. An implementation of vector RAG in which text chunks are retrieved and added to the\navailable context window until the specified token limit is reached.\nThe size of the context window and the prompts used for answer generation are the same across\nall six conditions (except for minor modifications to reference styles to match the types of context\ninformation used). Conditions only differ in how the contents of the context window are created.", "are risks to downstream sensemaking and decision-making tasks if the generated answers do not\naccurately represent the source data. System use should be accompanied by clear disclosures of AI\nuse and the potential for errors in outputs. Compared to vector RAG, however, GraphRAG shows\npromise as a way to mitigate these downstream risks for questions of a global nature, which might\notherwise be answered by samples of retrieved facts falsely presented as global summaries.\n7\nConclusion\nWe have presented GraphRAG, a RAG approach that combines knowledge graph generation and", "3.1.1\nSource Documents →Text Chunks\nTo start, the documents in the corpus are split into text chunks. The LLM extracts information from\neach chunk for downstream processing. Selecting the size of the chunk is a fundamental design\ndecision; longer text chunks require fewer LLM calls for such extraction (which reduces cost) but\nsuffer from degraded recall of information that appears early in the chunk (Kuratov et al., 2024; Liu\net al., 2023). See Section A.1 for prompts and examples of the recall-precision trade-offs.\n3.1.2\nText Chunks →Entities & Relationships", "Elmagarmid, A. K., Ipeirotis, P. G., and Verykios, V. S. (2006). Duplicate record detection: A\nsurvey. IEEE Transactions on knowledge and data engineering, 19(1):1–16.\nEs, S., James, J., Espinosa-Anke, L., and Schockaert, S. (2023). Ragas: Automated evaluation of\nretrieval augmented generation. arXiv preprint arXiv:2309.15217.\nEtzioni, O., Cafarella, M., Downey, D., Kok, S., Popescu, A.-M., Shaked, T., Soderland, S., Weld,\nD. S., and Yates, A. (2004). Web-scale information extraction in knowitall: (preliminary re-", "to source text summarization: for low-level community summaries (C3), GraphRAG required 26-\n33% fewer context tokens, while for root-level community summaries (C0), it required over 97%\nfewer tokens. For a modest drop in performance compared with other global methods, root-level\nGraphRAG offers a highly efficient method for the iterative question answering that characterizes\nsensemaking activity, while retaining advantages in comprehensiveness (72% win rate) and diversity\n(62% win rate) over vector RAG.\n10", "Anil, R., Borgeaud, S., Wu, Y., Alayrac, J.-B., Yu, J., Soricut, R., Schalkwyk, J., Dai, A. M.,\nHauth, A., et al. (2023). Gemini: a family of highly capable multimodal models. arXiv preprint\narXiv:2312.11805.\nBaek, J., Aji, A. F., and Saffari, A. (2023). Knowledge-augmented language model prompting for\nzero-shot knowledge graph question answering. arXiv preprint arXiv:2306.04136.\nBan, T., Chen, L., Wang, X., and Chen, H. (2023). From query tools to causal architects: Harnessing\nlarge language models for advanced causal discovery from data.", "augmented generation for large language models: A survey. arXiv preprint arXiv:2312.10997.\nHe, X., Tian, Y., Sun, Y., Chawla, N. V., Laurent, T., LeCun, Y., Bresson, X., and Hooi, B. (2024).\nG-retriever: Retrieval-augmented generation for textual graph understanding and question an-\nswering. arXiv preprint arXiv:2402.07630.\nHuang, J., Chen, X., Mishra, S., Zheng, H. S., Yu, A. W., Song, X., and Zhou, D. (2023). Large\nlanguage models cannot self-correct reasoning yet. arXiv preprint arXiv:2310.01798.\n13", "tion detection for generative large language models. arXiv preprint arXiv:2303.08896.\nMao, Y., He, P., Liu, X., Shen, Y., Gao, J., Han, J., and Chen, W. (2020). Generation-augmented\nretrieval for open-domain question answering. arXiv preprint arXiv:2009.08553.\nMartin, S., Brown, W. M., Klavans, R., and Boyack, K. (2011). Openord: An open-source toolbox\nfor large graph layout. SPIE Conference on Visualization and Data Analysis (VDA).\nMelnyk, I., Dognin, P., and Das, P. (2022). Knowledge graph generation from text.\n14", "a good nlg evaluator? a preliminary study. arXiv preprint arXiv:2303.04048.\nWang, S., Khramtsova, E., Zhuang, S., and Zuccon, G. (2024). Feb4rag: Evaluating federated search\nin the context of retrieval augmented generation. arXiv preprint arXiv:2402.11891.\nWang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., and Zhou, D.\n(2022). Self-consistency improves chain of thought reasoning in language models. arXiv preprint\narXiv:2203.11171.\nWang, Y., Lipka, N., Rossi, R. A., Siu, A., Zhang, R., and Derr, T. (2023b). Knowledge graph", "Zhang, J. (2023). Graph-toolformer: To empower llms with graph reasoning ability via prompt\naugmented by chatgpt. arXiv preprint arXiv:2304.11116.\n16", "• Quantum Systems acquired NeoChip in 2016 and held ownership until NeoChip went pub-\nlic.\nSee Appendix A for prompts and details on our implementation of entity and claim extraction.\n3.1.3\nEntities & Relationships →Knowledge Graph\nThe use of an LLM to extract entities, relationships, and claims is a form of abstractive summariza-\ntion – these are meaningful summaries of concepts that, in the case of relationships and claims, may\nnot be explicitly stated in the text. The entity/relationship/claim extraction processes creates mul-", "QFS methods, meanwhile, do not scale to the quantities of text indexed by typ-\nical RAG systems. To combine the strengths of these contrasting methods, we\npropose GraphRAG, a graph-based approach to question answering over private\ntext corpora that scales with both the generality of user questions and the quantity\nof source text. Our approach uses an LLM to build a graph index in two stages:\nfirst, to derive an entity knowledge graph from the source documents, then to pre-\ngenerate community summaries for all groups of closely related entities. Given a", "generate community summaries for all groups of closely related entities. Given a\nquestion, each community summary is used to generate a partial response, before\nall partial responses are again summarized in a final response to the user. For a\nclass of global sensemaking questions over datasets in the 1 million token range,\nwe show that GraphRAG leads to substantial improvements over a conventional\nRAG baseline for both the comprehensiveness and diversity of generated answers.\n1\nIntroduction\nRetrieval augmented generation (RAG) (Lewis et al., 2020) is an established approach to using", "the entirety of a large text corpus. GraphRAG first uses an LLM to construct a knowledge graph,\nwhere nodes correspond to key entities in the corpus and edges represent relationships between those\nentities. Next, it partitions the graph into a hierarchy of communities of closely related entities,\nbefore using an LLM to generate community-level summaries. These summaries are generated in\na bottom-up manner following the hierarchical structure of extracted communities, with summaries\nat higher levels of the hierarchy recursively incorporating lower-level summaries. Together, these", "at higher levels of the hierarchy recursively incorporating lower-level summaries. Together, these\ncommunity summaries provide global descriptions and insights over the corpus. Finally, GraphRAG\nanswers queries through map-reduce processing of community summaries; in the map step, the\nsummaries are used to provide partial answers to the query independently and in parallel, then in the\nreduce step, the partial answers are combined and used to generate a final global answer.\nThe GraphRAG method and its ability to perform global sensemaking over an entire corpus form", "The GraphRAG method and its ability to perform global sensemaking over an entire corpus form\nthe main contribution of this work. To demonstrate this ability, we developed a novel application\nof the LLM-as-a-judge technique (Zheng et al., 2024) suitable for questions targeting broad issues\nand themes where there is no ground-truth answer. This approach first uses one LLM to generate\na diverse set of global sensemaking questions based on corpus-specific use cases, before using a\nsecond LLM to judge the answers of two different RAG systems using predefined criteria (defined", "second LLM to judge the answers of two different RAG systems using predefined criteria (defined\nin Section 3.3). We use this approach to compare GraphRAG to vector RAG on two representative\nreal-world text datasets. Results show GraphRAG strongly outperforms vector RAG when using\nGPT-4 as the LLM.\nGraphRAG is available as open-source software at https://github.com/microsoft/graphrag. In ad-\ndition, versions of the GraphRAG approach are also available as extensions to multiple open-\nsource libraries, including LangChain (LangChain, 2024), LlamaIndex (LlamaIndex, 2024), Nebu-", "in answer comprehensiveness and diversity, except for root-level summaries. Intermediate-level\nsummaries in the Podcast dataset and low-level community summaries in the News dataset achieved\ncomprehensiveness win rates of 57% (p<.001) and 64% (p<.001), respectively. Diversity win rates\nwere 57% (p=.036) for Podcast intermediate-level summaries and 60% (p<.001) for News low-level\ncommunity summaries. Table 2 also illustrates the scalability advantages of GraphRAG compared\nto source text summarization: for low-level community summaries (C3), GraphRAG required 26-", "few-shot exemplars for in-context learning (Brown et al., 2020). For example, while our default\nprompt extracts the broad class of “named entities” like people, places, and organizations and is\ngenerally applicable, domains with specialized knowledge (e.g., science, medicine, law) will benefit\nfrom few-shot exemplars specialized to those domains.\nThe LLM can also be prompted to extract claims about detected entities. Claims are important\nfactual statements about entities, such as dates, events, and interactions with other entities. As", "Given the lack of gold standard answers to our activity-based sensemaking questions, we adopt\nthe head-to-head comparison approach using an LLM evaluator that judges relative performance\naccording to specific criteria. We designed three target criteria capturing qualities that are desirable\nfor global sensemaking activities.\nAppendix F shows the prompts for our head-to-head measures computed using an LLM evaluator,\nsummarized as:\n• Comprehensiveness. How much detail does the answer provide to cover all aspects and\ndetails of the question?", "the LLM aligned with the winner based on the claim-based metrics. Since each pairwise comparison\nin Experiment 1 was performed five times, while the claim-based metrics provided only one outcome\nper comparison, we aggregated the Experiment 1 results into a single label using majority voting.\nFor example, if C0 won over SS in three out of five judgments for comprehensiveness on a given\nquestion, C0 was labeled the winner and SS the loser. However, if C0 won twice, SS won once, and\nthey tied twice, then there was no majority outcome, so the final label was a tie.", "plore the effects of varying the context window size for our combinations of datasets, questions, and\nmetrics. In particular, our goal was to determine the optimum context size for our baseline condition\n(SS) and then use this uniformly for all query-time LLM use. To that end, we tested four context\nwindow sizes: 8k, 16k, 32k and 64k. Surprisingly, the smallest context window size tested (8k)\nwas universally better for all comparisons on comprehensiveness (average win rate of 58.1%), while\nperforming comparably with larger context sizes on diversity (average win rate = 52.4%), and em-", "Furthermore, we use a “control criterion” called Directness that answers “How specifically and\nclearly does the answer address the question?”. In plain terms, directness evaluates the concision\nof an answer in a generic sense that applies to any generated LLM summarization. We include it to\nbehave as a reference against which we can judge the soundness of results for the other criteria. Since\ndirectness is effectively in opposition to comprehensiveness and diversity, we would not expect any\nmethod to win across all four criteria.", "50\n58\n50\n50\n48\n43\n42\n50\n42\n45\n44\n51\n50\n58\n50\n52\n51\n50\n50\n55\n48\n50\n50\n50\n52\n56\n49\n50\n50\nSS\nTS\nC0\nC1\nC2\nC3\nSS TS C0 C1 C2 C3\nEmpowerment\n50\n54\n59\n55\n55\n54\n46\n50\n55\n53\n52\n52\n41\n45\n50\n48\n48\n47\n45\n47\n52\n50\n49\n49\n45\n48\n52\n51\n50\n49\n46\n48\n53\n51\n51\n50\nSS\nTS\nC0\nC1\nC2\nC3\nSS TS C0 C1 C2 C3\nDirectness\nFigure 2: Head-to-head win rate percentages of (row condition) over (column condition) across two\ndatasets, four metrics, and 125 questions per comparison (each repeated five times and averaged).\nThe overall winner per dataset and metric is shown in bold. Self-win rates were not computed but", "source libraries, including LangChain (LangChain, 2024), LlamaIndex (LlamaIndex, 2024), Nebu-\nlaGraph (NebulaGraph, 2024), and Neo4J (Neo4J, 2024).\n2\nBackground\n2.1\nRAG Approaches and Systems\nRAG generally refers to any system where a user query is used to retrieve relevant information from\nexternal data sources, whereupon this information is incorporated into the generation of a response\nto the query by an LLM (or other generative AI model, such as a multi-media model). The query and\nretrieved records populate a prompt template, which is then passed to the LLM (Ram et al., 2023).", "Metropolitansky, D. and Larson, J. (2025). Towards effective extraction and evaluation of factual\nclaims.\nMicrosoft (2023). The impact of large language models on scientific discovery: a preliminary study\nusing gpt-4.\nMooney, R. J. and Bunescu, R. (2005). Mining knowledge from text using information extraction.\nSIGKDD Explor. Newsl., 7(1):3–10.\nNebulaGraph (2024). Nebulagraph launches industry-first graph rag: Retrieval-augmented genera-\ntion with llm based on knowledge graphs. https://www.nebula-graph.io/posts/graph-RAG.", "et al., 2018), GPT-4 extracted almost twice as many entity references when the chunk size was 600\ntokens than when it was 2400. To address this issue, we deploy a self-reflection prompt engineering\napproach. After entities are extracted from a chunk, we provide the extracted entities back to the\nLLM, prompting it to “glean” any entities that it may have missed. This is a multi-stage process\nin which we first ask the LLM to assess whether all entities were extracted, using a logit bias of\n100 to force a yes/no decision. If the LLM responds that entities were missed, then a continuation", "and intelligence analysis (Ranade and Joshi, 2023). Given a sensemaking query and a text with an\nimplicit and interconnected set of concepts, an LLM can generate a summary that answers the query.\nThe challenge, however, arises when the volume of data requires a RAG approach, since vector RAG\napproaches are unable to support sensemaking over an entire corpus.\nIn this paper, we present GraphRAG – a graph-based RAG approach that enables sensemaking over\nthe entirety of a large text corpus. GraphRAG first uses an LLM to construct a knowledge graph,", "100 to force a yes/no decision. If the LLM responds that entities were missed, then a continuation\nindicating that “MANY entities were missed in the last extraction” encourages the LLM to detect\nthese missing entities. This approach allows us to use larger chunk sizes without a drop in quality\n(Figure 3) or the forced introduction of noise. We interate self-reflection steps up to a specified\nmaximum number of times.\n0\n1\n2\n3\n0\n10000\n20000\n30000\nNumber of self-reflection iterations performed\nEntity references detected\n600 chunk size\n1200 chunk size\n2400 chunk size", "and structured overview of public figures across various sectors of the entertainment industry,\nincluding film, television, music, sports, and digital media. It lists multiple individuals, providing\nspecific examples of their contributions and the context in which they are mentioned in entertainment\narticles, along with references to data reports for each claim. This approach helps the reader\nunderstand the breadth of the topic and make informed judgments without being misled. In contrast,\nAnswer 2 focuses on a smaller group of public figures and primarily discusses their personal lives and", "\"summary\":\n<executive summary>,\n\"rating\":\n<impact severity rating>,\n\"rating explanation\":\n<rating explanation>,\n\"findings\":\n[\n{{\n\"summary\":<insight 1 summary>,\n\"explanation\":\n<insight 1 explanation>\n}},\n{{\n\"summary\":<insight 2 summary>,\n\"explanation\":\n<insight 2 explanation>\n}}\n]\n}}\n---Grounding Rules---\nPoints supported by data should list their data references as follows:\n\"This is an example sentence supported by multiple data references [Data:\n<dataset name> (record ids);\n<dataset name> (record ids)].\"\nDo not list more than 5 record ids in a single reference.", "nology (Scott, 2024). This corpus was divided into 1669 × 600-token text chunks, with 100-token\noverlaps between chunks (∼1 million tokens).\nNews articles. A benchmark dataset comprised of news articles published from September 2013\nto December 2023 in a range of categories, including entertainment, business, sports, technology,\nhealth, and science (Tang and Yang, 2024). The corpus is divided into 3197 × 600-token text\nchunks, with 100-token overlaps between chunks (∼1.7 million tokens).\n4.1.2\nConditions", "Each level of this hierarchy provides a community partition that covers the nodes of the graph in a\nmutually exclusive, collectively exhaustive way, enabling divide-and-conquer global summarization.\nAn illustration of such hierarchical partitioning on an example dataset can be found in Appendix B.\n3.1.5\nGraph Communities →Community Summaries\nThe next step creates report-like summaries of each community in the community hierarchy, using\na method designed to scale to very large datasets. These summaries are independently useful as a", "retrieved records populate a prompt template, which is then passed to the LLM (Ram et al., 2023).\nRAG is ideal when the total number of records in a data source is too large to include in a single\nprompt to the LLM, i.e. the amount of text in the data source exceeds the LLM’s context window.\nIn canonical RAG approaches, the retrieval process returns a set number of records that are seman-\ntically similar to the query and the generated answer uses only the information in those retrieved\nrecords. A common approach to conventional RAG is to use text embeddings, retrieving records", "Adaptive benchmarking refers to the process of dynamically generating evaluation benchmarks tai-\nlored to specific domains or use cases. Recent work has used LLMs for adaptive benchmarking\nto ensure relevance, diversity, and alignment with the target application or task (Yuan et al., 2024;\nZhang et al., 2024b). In this work, we propose an adaptive benchmarking approach to generating\nglobal sensemaking queries for the LLM. Our approach builds on prior work in LLM-based persona\ngeneration, where the LLM is used to generate diverse and authentic sets of personas (Kosinski,", "Our evaluation relies on the LLM to evaluate how well the RAG system answers the generated ques-\ntions. Prior work has shown LLMs to be good evaluators of natural language generation, includ-\ning work where LLMs evaluations were competitive with human evaluations (Wang et al., 2023a;\nZheng et al., 2024). Some prior work proposes criteria for having LLMs quantify the quality of\n3", "answering the target question. Answers with score 0 are filtered out.\n• Reduce to global answer. Intermediate community answers are sorted in descending order\nof helpfulness score and iteratively added into a new context window until the token limit\nis reached. This final context is used to generate the global answer returned to the user.\n3.2\nGlobal Sensemaking Question Generation\nTo evaluate the effectiveness of RAG systems for global sensemaking tasks, we use an LLM to\ngenerate a set of corpus-specific questions designed to asses high-level understanding of a given", "LLM is prompted to generate questions that require understanding of the entire corpus. Algorithm\n1 describes the approach.\n6", "method to win across all four criteria.\nIn our evaluations, the LLM is provided with the question, the generated answers from two compet-\ning systems, and prompted to compare the two answers according to the criterion before giving a\nfinal judgment of which answer is preferred. The LLM either indicates a winner; or, it returns a tie\nif they are fundamentally similar. To account for the inherent stochasticity of LLM generation, we\nrun each comparison with multiple replicates and average the results across replicates and questions.", "label was not a tie, representing 33% and 39% of pairwise comparisons for comprehensiveness and\ndiversity, respectively. In these cases, the aggregated LLM label matched the claim-based label in\n78% of pairwise comparisons for comprehensiveness and 69-70% for diversity (across all distance\nthresholds), indicating moderately strong alignment.\n6\nDiscussion\n6.1\nLimitations of evaluation approach\nOur evaluation to date has focused on sensemaking questions specific to two corpora each containing\napproximately 1 million tokens. More work is needed to understand how performance generalizes to", "Entity references detected\n600 chunk size\n1200 chunk size\n2400 chunk size\nFigure 3: How the entity references detected in the HotPotQA dataset (Yang et al., 2018)\nvaries with chunk size and self-reflection iterations for our generic entity extraction prompt with\ngpt-4-turbo.\nB\nExample Community Detection\n18", "a method designed to scale to very large datasets. These summaries are independently useful as a\nway to understand the global structure and semantics of the dataset, and may themselves be used to\nmake sense of a corpus in the absence of a specific query. For example, a user may scan through\ncommunity summaries at one level looking for general themes of interest, then read linked reports\nat a lower level that provide additional details for each subtopic. Here, however, we focus on their\nutility as part of a graph-based index used for answering global queries.", "W.-t., Rockt¨aschel, T., et al. (2020). Retrieval-augmented generation for knowledge-intensive nlp\ntasks. Advances in Neural Information Processing Systems, 33:9459–9474.\nLiu, N. F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqua, M., Petroni, F., and Liang, P. (2023). Lost\nin the middle: How language models use long contexts. arXiv:2307.03172.\nLlamaIndex (2024). GraphRAG Implementation with LlamaIndex - V2. https://github.com/run-\nllama/llama index/blob/main/docs/docs/examples/cookbooks/GraphRAG v2.ipynb."], "chunkRefs": {"COMPREHENSIVENESS": [{"index": 83, "source_id": "arxiv:2404.16130", "text_idx": 0}, {"index": 186, "source_id": "arxiv:2404.16130", "text_idx": 1}], "ASSOCIATION FOR COMPUTATIONAL LINGUISTICS": [{"index": 114, "source_id": "arxiv:2404.16130", "text_idx": 2}, {"index": 125, "source_id": "arxiv:2404.16130", "text_idx": 3}], "USER QUERY": [{"index": 45, "source_id": "arxiv:2404.16130", "text_idx": 4}], "OPENAI": [{"index": 18, "source_id": "arxiv:2404.16130", "text_idx": 5}, {"index": 66, "source_id": "arxiv:2404.16130", "text_idx": 6}, {"index": 114, "source_id": "arxiv:2404.16130", "text_idx": 2}], "DAVID TITTWORTH": [{"index": 95, "source_id": "arxiv:2404.16130", "text_idx": 7}], "RAG GENERATED ANSWERS": [{"index": 29, "source_id": "arxiv:2404.16130", "text_idx": 8}], "DOUGLAS ORBAKER": [{"index": 95, "source_id": "arxiv:2404.16130", "text_idx": 7}], "ETZIONI": [{"index": 17, "source_id": "arxiv:2404.16130", "text_idx": 9}], "ENTITY EXTRACTION": [{"index": 129, "source_id": "arxiv:2404.16130", "text_idx": 10}], "GRAPSELOGIC": [{"index": 67, "source_id": "arxiv:2404.16130", "text_idx": 11}], "GRAPH INDEX": [{"index": 43, "source_id": "arxiv:2404.16130", "text_idx": 12}, {"index": 91, "source_id": "arxiv:2404.16130", "text_idx": 13}], "VECTOR RAG _SS_": [{"index": 83, "source_id": "arxiv:2404.16130", "text_idx": 0}], "COACHES": [{"index": 140, "source_id": "arxiv:2404.16130", "text_idx": 14}], "COMPUTATIONAL LINGUISTICS": [{"index": 116, "source_id": "arxiv:2404.16130", "text_idx": 15}], "VERDANT OASIS PLAZA": [{"index": 161, "source_id": "arxiv:2404.16130", "text_idx": 16}, {"index": 163, "source_id": "arxiv:2404.16130", "text_idx": 17}, {"index": 164, "source_id": "arxiv:2404.16130", "text_idx": 18}, {"index": 165, "source_id": "arxiv:2404.16130", "text_idx": 19}], "ACTORS": [{"index": 140, "source_id": "arxiv:2404.16130", "text_idx": 14}], "ZHENG": [{"index": 28, "source_id": "arxiv:2404.16130", "text_idx": 20}], "NEW YORK": [{"index": 68, "source_id": "arxiv:2404.16130", "text_idx": 21}], "HUANG": [{"index": 108, "source_id": "arxiv:2404.16130", "text_idx": 22}], "PRIOR QFS METHODS": [{"index": 1, "source_id": "arxiv:2404.16130", "text_idx": 23}], "NEWMAN": [{"index": 20, "source_id": "arxiv:2404.16130", "text_idx": 24}, {"index": 113, "source_id": "arxiv:2404.16130", "text_idx": 25}], "COMUNITY": [{"index": 156, "source_id": "arxiv:2404.16130", "text_idx": 26}], "CHRIS TREVIÑO": [{"index": 95, "source_id": "arxiv:2404.16130", "text_idx": 7}], "JEROME POWELL": [{"index": 153, "source_id": "arxiv:2404.16130", "text_idx": 27}, {"index": 154, "source_id": "arxiv:2404.16130", "text_idx": 28}], "NEOCHIP": [{"index": 32, "source_id": "arxiv:2404.16130", "text_idx": 29}, {"index": 33, "source_id": "arxiv:2404.16130", "text_idx": 30}, {"index": 35, "source_id": "arxiv:2404.16130", "text_idx": 31}], "DOMAIN-TAILORED SUMMARIZATION": [{"index": 26, "source_id": "arxiv:2404.16130", "text_idx": 32}], "PADMAKUMAR": [{"index": 114, "source_id": "arxiv:2404.16130", "text_idx": 2}], "A_JOSHI": [{"index": 116, "source_id": "arxiv:2404.16130", "text_idx": 15}], "NAACL-HLT": [{"index": 125, "source_id": "arxiv:2404.16130", "text_idx": 3}], "ENTITY EXTRACTOR": [{"index": 26, "source_id": "arxiv:2404.16130", "text_idx": 32}], "MICROSOFT RESEARCH": [{"index": 0, "source_id": "arxiv:2404.16130", "text_idx": 33}], "COMMUNITY SUMMARIZATION": [{"index": 26, "source_id": "arxiv:2404.16130", "text_idx": 32}], "LASKAR": [{"index": 6, "source_id": "arxiv:2404.16130", "text_idx": 34}, {"index": 108, "source_id": "arxiv:2404.16130", "text_idx": 22}], "YAO ET AL_": [{"index": 18, "source_id": "arxiv:2404.16130", "text_idx": 5}], "CHUNG ET AL_": [{"index": 67, "source_id": "arxiv:2404.16130", "text_idx": 11}], "J_ D_": [{"index": 125, "source_id": "arxiv:2404.16130", "text_idx": 3}], "TRAAG": [{"index": 20, "source_id": "arxiv:2404.16130", "text_idx": 24}, {"index": 39, "source_id": "arxiv:2404.16130", "text_idx": 35}], "LEWIS": [{"index": 108, "source_id": "arxiv:2404.16130", "text_idx": 22}], "DIRECTORS": [{"index": 140, "source_id": "arxiv:2404.16130", "text_idx": 14}], "ENTREPRENEURS": [{"index": 140, "source_id": "arxiv:2404.16130", "text_idx": 14}], "TS": [{"index": 62, "source_id": "arxiv:2404.16130", "text_idx": 36}, {"index": 77, "source_id": "arxiv:2404.16130", "text_idx": 37}, {"index": 82, "source_id": "arxiv:2404.16130", "text_idx": 38}, {"index": 185, "source_id": "arxiv:2404.16130", "text_idx": 39}, {"index": 189, "source_id": "arxiv:2404.16130", "text_idx": 40}, {"index": 190, "source_id": "arxiv:2404.16130", "text_idx": 41}, {"index": 191, "source_id": "arxiv:2404.16130", "text_idx": 42}], "PODCAST": [{"index": 73, "source_id": "arxiv:2404.16130", "text_idx": 43}], "SCIENTIFIC REPORTS": [{"index": 121, "source_id": "arxiv:2404.16130", "text_idx": 44}], "TRAJANOSSKA ET AL_": [{"index": 18, "source_id": "arxiv:2404.16130", "text_idx": 5}], "RETRIEVAL-AUGMENTED GENERATION": [{"index": 1, "source_id": "arxiv:2404.16130", "text_idx": 23}], "ARXIV PREPRINT": [{"index": 116, "source_id": "arxiv:2404.16130", "text_idx": 15}], "TRAAG ET AL_": [{"index": 27, "source_id": "arxiv:2404.16130", "text_idx": 45}, {"index": 135, "source_id": "arxiv:2404.16130", "text_idx": 46}], "ANDR´ES MORALES ESQUIVEL": [{"index": 95, "source_id": "arxiv:2404.16130", "text_idx": 7}], "KNOWLEDGE GRAPH": [{"index": 26, "source_id": "arxiv:2404.16130", "text_idx": 32}], "ALONSO GUEVARA": [{"index": 95, "source_id": "arxiv:2404.16130", "text_idx": 7}], "MULTIHOPE-RAG": [{"index": 135, "source_id": "arxiv:2404.16130", "text_idx": 46}], "CIKM": [{"index": 106, "source_id": "arxiv:2404.16130", "text_idx": 47}], "PUBLIC FIGURES IN CONTROVERSY": [{"index": 140, "source_id": "arxiv:2404.16130", "text_idx": 14}], "QUERY-FOCUSED SUMMARIZATION": [{"index": 26, "source_id": "arxiv:2404.16130", "text_idx": 32}], "C2": [{"index": 82, "source_id": "arxiv:2404.16130", "text_idx": 38}, {"index": 188, "source_id": "arxiv:2404.16130", "text_idx": 48}, {"index": 189, "source_id": "arxiv:2404.16130", "text_idx": 40}, {"index": 191, "source_id": "arxiv:2404.16130", "text_idx": 42}], "BILLIE RINALDI": [{"index": 95, "source_id": "arxiv:2404.16130", "text_idx": 7}], "FORTUNATO": [{"index": 39, "source_id": "arxiv:2404.16130", "text_idx": 35}], "IEEE": [{"index": 106, "source_id": "arxiv:2404.16130", "text_idx": 47}, {"index": 107, "source_id": "arxiv:2404.16130", "text_idx": 49}], "KOSINKSI": [{"index": 24, "source_id": "arxiv:2404.16130", "text_idx": 50}], "ZHANG ET AL_": [{"index": 18, "source_id": "arxiv:2404.16130", "text_idx": 5}], "MAP-REDUCE SOURCE TEXT SUMMARIZATION": [{"index": 94, "source_id": "arxiv:2404.16130", "text_idx": 51}], "FEDERAL OPEN MARKET COMMITTEE": [{"index": 154, "source_id": "arxiv:2404.16130", "text_idx": 28}], "JIN": [{"index": 39, "source_id": "arxiv:2404.16130", "text_idx": 35}, {"index": 104, "source_id": "arxiv:2404.16130", "text_idx": 52}], "CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE": [{"index": 108, "source_id": "arxiv:2404.16130", "text_idx": 22}], "VECTOR RAG": [{"index": 64, "source_id": "arxiv:2404.16130", "text_idx": 53}, {"index": 73, "source_id": "arxiv:2404.16130", "text_idx": 43}, {"index": 93, "source_id": "arxiv:2404.16130", "text_idx": 54}], "SOURCE DOCUMENTS": [{"index": 26, "source_id": "arxiv:2404.16130", "text_idx": 32}, {"index": 30, "source_id": "arxiv:2404.16130", "text_idx": 55}], "MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES": [{"index": 0, "source_id": "arxiv:2404.16130", "text_idx": 33}], "LARGE LANGUAGE MODELS": [{"index": 1, "source_id": "arxiv:2404.16130", "text_idx": 23}], "UNITY MARCH": [{"index": 161, "source_id": "arxiv:2404.16130", "text_idx": 16}, {"index": 163, "source_id": "arxiv:2404.16130", "text_idx": 17}], "EXTERNAL KNOWLEDGE SOURCE": [{"index": 1, "source_id": "arxiv:2404.16130", "text_idx": 23}], "YATES ET AL_": [{"index": 18, "source_id": "arxiv:2404.16130", "text_idx": 5}], "ELMAGRAMARD": [{"index": 101, "source_id": "arxiv:2404.16130", "text_idx": 56}], "INFLUENCERS": [{"index": 140, "source_id": "arxiv:2404.16130", "text_idx": 14}], "HOQUE": [{"index": 108, "source_id": "arxiv:2404.16130", "text_idx": 22}], "GLOBAL ANSWER": [{"index": 26, "source_id": "arxiv:2404.16130", "text_idx": 32}, {"index": 45, "source_id": "arxiv:2404.16130", "text_idx": 4}], "LEEDEN ALGORITHM": [{"index": 135, "source_id": "arxiv:2404.16130", "text_idx": 46}], "SHIN ET AL_": [{"index": 24, "source_id": "arxiv:2404.16130", "text_idx": 50}], "P_P_RANADE": [{"index": 116, "source_id": "arxiv:2404.16130", "text_idx": 15}], "VECTOR RAG BASELINE": [{"index": 94, "source_id": "arxiv:2404.16130", "text_idx": 51}], "C3": [{"index": 81, "source_id": "arxiv:2404.16130", "text_idx": 57}, {"index": 82, "source_id": "arxiv:2404.16130", "text_idx": 38}, {"index": 188, "source_id": "arxiv:2404.16130", "text_idx": 48}, {"index": 189, "source_id": "arxiv:2404.16130", "text_idx": 40}, {"index": 191, "source_id": "arxiv:2404.16130", "text_idx": 42}], "AMBER HOAK": [{"index": 95, "source_id": "arxiv:2404.16130", "text_idx": 7}], "IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING": [{"index": 101, "source_id": "arxiv:2404.16130", "text_idx": 56}], "DEFAULT GRAPH EXTRACTION PROMPT": [{"index": 129, "source_id": "arxiv:2404.16130", "text_idx": 10}], "MUSICIANS": [{"index": 140, "source_id": "arxiv:2404.16130", "text_idx": 14}], "CLAIM EXTRACTION PROMPT": [{"index": 129, "source_id": "arxiv:2404.16130", "text_idx": 10}], "ARXIV": [{"index": 97, "source_id": "arxiv:2404.16130", "text_idx": 58}, {"index": 101, "source_id": "arxiv:2404.16130", "text_idx": 56}, {"index": 103, "source_id": "arxiv:2404.16130", "text_idx": 59}, {"index": 106, "source_id": "arxiv:2404.16130", "text_idx": 47}, {"index": 111, "source_id": "arxiv:2404.16130", "text_idx": 60}, {"index": 121, "source_id": "arxiv:2404.16130", "text_idx": 44}, {"index": 122, "source_id": "arxiv:2404.16130", "text_idx": 61}, {"index": 126, "source_id": "arxiv:2404.16130", "text_idx": 62}], "QUANTUM SYSTEMS": [{"index": 33, "source_id": "arxiv:2404.16130", "text_idx": 30}, {"index": 35, "source_id": "arxiv:2404.16130", "text_idx": 31}, {"index": 36, "source_id": "arxiv:2404.16130", "text_idx": 63}], "GRAPHRAG": [{"index": 2, "source_id": "arxiv:2404.16130", "text_idx": 64}, {"index": 3, "source_id": "arxiv:2404.16130", "text_idx": 65}, {"index": 9, "source_id": "arxiv:2404.16130", "text_idx": 66}, {"index": 10, "source_id": "arxiv:2404.16130", "text_idx": 67}, {"index": 11, "source_id": "arxiv:2404.16130", "text_idx": 68}, {"index": 12, "source_id": "arxiv:2404.16130", "text_idx": 69}, {"index": 17, "source_id": "arxiv:2404.16130", "text_idx": 9}, {"index": 43, "source_id": "arxiv:2404.16130", "text_idx": 12}, {"index": 62, "source_id": "arxiv:2404.16130", "text_idx": 36}, {"index": 73, "source_id": "arxiv:2404.16130", "text_idx": 43}, {"index": 80, "source_id": "arxiv:2404.16130", "text_idx": 70}, {"index": 93, "source_id": "arxiv:2404.16130", "text_idx": 54}, {"index": 94, "source_id": "arxiv:2404.16130", "text_idx": 51}, {"index": 113, "source_id": "arxiv:2404.16130", "text_idx": 25}, {"index": 129, "source_id": "arxiv:2404.16130", "text_idx": 10}], "MICROSOFT OFFICE OF THE CTO": [{"index": 0, "source_id": "arxiv:2404.16130", "text_idx": 33}], "ED": [{"index": 95, "source_id": "arxiv:2404.16130", "text_idx": 7}], "LAW": [{"index": 34, "source_id": "arxiv:2404.16130", "text_idx": 71}], "MELNYK ET AL_": [{"index": 18, "source_id": "arxiv:2404.16130", "text_idx": 5}], "ARXIV_20231210997": [{"index": 103, "source_id": "arxiv:2404.16130", "text_idx": 59}], "APPENDIX F": [{"index": 53, "source_id": "arxiv:2404.16130", "text_idx": 72}, {"index": 67, "source_id": "arxiv:2404.16130", "text_idx": 11}], "DAYENNE DE SOUZA": [{"index": 95, "source_id": "arxiv:2404.16130", "text_idx": 7}], "NI ET AL": [{"index": 68, "source_id": "arxiv:2404.16130", "text_idx": 21}], "COMMUNITY ANSWERS": [{"index": 45, "source_id": "arxiv:2404.16130", "text_idx": 4}], "FERN´ANDEZ": [{"index": 95, "source_id": "arxiv:2404.16130", "text_idx": 7}], "TEXT CHUNKS": [{"index": 26, "source_id": "arxiv:2404.16130", "text_idx": 32}, {"index": 30, "source_id": "arxiv:2404.16130", "text_idx": 55}], "BEN CUTLER": [{"index": 95, "source_id": "arxiv:2404.16130", "text_idx": 7}], "HARMONY ASSEMBLY": [{"index": 161, "source_id": "arxiv:2404.16130", "text_idx": 16}, {"index": 163, "source_id": "arxiv:2404.16130", "text_idx": 17}, {"index": 165, "source_id": "arxiv:2404.16130", "text_idx": 19}], "SS": [{"index": 62, "source_id": "arxiv:2404.16130", "text_idx": 36}, {"index": 82, "source_id": "arxiv:2404.16130", "text_idx": 38}, {"index": 86, "source_id": "arxiv:2404.16130", "text_idx": 73}, {"index": 137, "source_id": "arxiv:2404.16130", "text_idx": 74}, {"index": 189, "source_id": "arxiv:2404.16130", "text_idx": 40}, {"index": 190, "source_id": "arxiv:2404.16130", "text_idx": 41}, {"index": 191, "source_id": "arxiv:2404.16130", "text_idx": 42}], "PETRONI": [{"index": 108, "source_id": "arxiv:2404.16130", "text_idx": 22}], "AFACTA": [{"index": 113, "source_id": "arxiv:2404.16130", "text_idx": 25}], "DIRECTNESS": [{"index": 58, "source_id": "arxiv:2404.16130", "text_idx": 75}, {"index": 76, "source_id": "arxiv:2404.16130", "text_idx": 76}, {"index": 190, "source_id": "arxiv:2404.16130", "text_idx": 41}], "EXPERIMENT 2": [{"index": 67, "source_id": "arxiv:2404.16130", "text_idx": 11}, {"index": 82, "source_id": "arxiv:2404.16130", "text_idx": 38}], "NEBULAGRAPH": [{"index": 13, "source_id": "arxiv:2404.16130", "text_idx": 77}, {"index": 112, "source_id": "arxiv:2404.16130", "text_idx": 78}], "MEDICINE": [{"index": 34, "source_id": "arxiv:2404.16130", "text_idx": 71}], "GPT-4": [{"index": 12, "source_id": "arxiv:2404.16130", "text_idx": 69}, {"index": 129, "source_id": "arxiv:2404.16130", "text_idx": 10}, {"index": 132, "source_id": "arxiv:2404.16130", "text_idx": 79}], "APPENDIX E": [{"index": 67, "source_id": "arxiv:2404.16130", "text_idx": 11}], "EXAMPLE CORP": [{"index": 8, "source_id": "arxiv:2404.16130", "text_idx": 80}, {"index": 103, "source_id": "arxiv:2404.16130", "text_idx": 59}, {"index": 133, "source_id": "arxiv:2404.16130", "text_idx": 81}, {"index": 146, "source_id": "arxiv:2404.16130", "text_idx": 82}, {"index": 156, "source_id": "arxiv:2404.16130", "text_idx": 26}, {"index": 159, "source_id": "arxiv:2404.16130", "text_idx": 83}], "APPENDIX G": [{"index": 67, "source_id": "arxiv:2404.16130", "text_idx": 11}], "NEWS ARTICLES": [{"index": 73, "source_id": "arxiv:2404.16130", "text_idx": 43}], "GRAPH RAG PIPELINE": [{"index": 26, "source_id": "arxiv:2404.16130", "text_idx": 32}], "NI ET AL_": [{"index": 67, "source_id": "arxiv:2404.16130", "text_idx": 11}], "QUERY-FOCUSED SUMMARIZATION _QFS_": [{"index": 1, "source_id": "arxiv:2404.16130", "text_idx": 23}], "CALIFORNIA": [{"index": 68, "source_id": "arxiv:2404.16130", "text_idx": 21}], "P-VALUE": [{"index": 186, "source_id": "arxiv:2404.16130", "text_idx": 1}], "TANG AND YANG": [{"index": 61, "source_id": "arxiv:2404.16130", "text_idx": 84}, {"index": 135, "source_id": "arxiv:2404.16130", "text_idx": 46}], "NEWTECH EXCHANGE": [{"index": 35, "source_id": "arxiv:2404.16130", "text_idx": 31}], "GOALY": [{"index": 108, "source_id": "arxiv:2404.16130", "text_idx": 22}], "PRIVATE DOCUMENT COLLECTIONS": [{"index": 1, "source_id": "arxiv:2404.16130", "text_idx": 23}], "C1": [{"index": 82, "source_id": "arxiv:2404.16130", "text_idx": 38}, {"index": 188, "source_id": "arxiv:2404.16130", "text_idx": 48}, {"index": 189, "source_id": "arxiv:2404.16130", "text_idx": 40}, {"index": 191, "source_id": "arxiv:2404.16130", "text_idx": 42}], "ARXIV_202310_13848": [{"index": 116, "source_id": "arxiv:2404.16130", "text_idx": 15}], "COMMUNITY SUMMARIES": [{"index": 41, "source_id": "arxiv:2404.16130", "text_idx": 85}, {"index": 45, "source_id": "arxiv:2404.16130", "text_idx": 4}], "LLM": [{"index": 2, "source_id": "arxiv:2404.16130", "text_idx": 64}, {"index": 9, "source_id": "arxiv:2404.16130", "text_idx": 66}, {"index": 14, "source_id": "arxiv:2404.16130", "text_idx": 86}, {"index": 23, "source_id": "arxiv:2404.16130", "text_idx": 87}, {"index": 25, "source_id": "arxiv:2404.16130", "text_idx": 88}, {"index": 30, "source_id": "arxiv:2404.16130", "text_idx": 55}, {"index": 48, "source_id": "arxiv:2404.16130", "text_idx": 89}, {"index": 50, "source_id": "arxiv:2404.16130", "text_idx": 90}, {"index": 59, "source_id": "arxiv:2404.16130", "text_idx": 91}, {"index": 73, "source_id": "arxiv:2404.16130", "text_idx": 43}, {"index": 88, "source_id": "arxiv:2404.16130", "text_idx": 92}, {"index": 132, "source_id": "arxiv:2404.16130", "text_idx": 79}, {"index": 133, "source_id": "arxiv:2404.16130", "text_idx": 81}], "PEREZ": [{"index": 108, "source_id": "arxiv:2404.16130", "text_idx": 22}], "MOONEY AND BUNESCU": [{"index": 18, "source_id": "arxiv:2404.16130", "text_idx": 5}], "SCIENCE": [{"index": 34, "source_id": "arxiv:2404.16130", "text_idx": 71}], "ATHLETES": [{"index": 140, "source_id": "arxiv:2404.16130", "text_idx": 14}], "SALMINEN ET AL_": [{"index": 24, "source_id": "arxiv:2404.16130", "text_idx": 50}], "KNOWITALL": [{"index": 101, "source_id": "arxiv:2404.16130", "text_idx": 56}], "NEO4J": [{"index": 13, "source_id": "arxiv:2404.16130", "text_idx": 77}, {"index": 113, "source_id": "arxiv:2404.16130", "text_idx": 25}], "TURBO": [{"index": 134, "source_id": "arxiv:2404.16130", "text_idx": 93}], "TAN ET AL_": [{"index": 18, "source_id": "arxiv:2404.16130", "text_idx": 5}], "C0": [{"index": 81, "source_id": "arxiv:2404.16130", "text_idx": 57}, {"index": 82, "source_id": "arxiv:2404.16130", "text_idx": 38}, {"index": 86, "source_id": "arxiv:2404.16130", "text_idx": 73}, {"index": 185, "source_id": "arxiv:2404.16130", "text_idx": 39}, {"index": 188, "source_id": "arxiv:2404.16130", "text_idx": 48}, {"index": 189, "source_id": "arxiv:2404.16130", "text_idx": 40}, {"index": 191, "source_id": "arxiv:2404.16130", "text_idx": 42}], "VERIFIABLE FACTS": [{"index": 29, "source_id": "arxiv:2404.16130", "text_idx": 8}], "STARTUPXYZ": [{"index": 133, "source_id": "arxiv:2404.16130", "text_idx": 81}], "CHRIS SANCHEZ": [{"index": 95, "source_id": "arxiv:2404.16130", "text_idx": 7}], "ES": [{"index": 28, "source_id": "arxiv:2404.16130", "text_idx": 20}], "JOHN SMITH": [{"index": 146, "source_id": "arxiv:2404.16130", "text_idx": 82}, {"index": 156, "source_id": "arxiv:2404.16130", "text_idx": 26}], "HE HONG": [{"index": 114, "source_id": "arxiv:2404.16130", "text_idx": 2}], "RAG APPROACHES": [{"index": 91, "source_id": "arxiv:2404.16130", "text_idx": 13}], "YUAN ET AL_": [{"index": 23, "source_id": "arxiv:2404.16130", "text_idx": 87}], "BROWN": [{"index": 34, "source_id": "arxiv:2404.16130", "text_idx": 71}], "YANG ET AL": [{"index": 134, "source_id": "arxiv:2404.16130", "text_idx": 93}], "ZHAO ET AL_": [{"index": 23, "source_id": "arxiv:2404.16130", "text_idx": 87}], "A SURVEY": [{"index": 103, "source_id": "arxiv:2404.16130", "text_idx": 59}], "COMMUNITY DETECTION": [{"index": 26, "source_id": "arxiv:2404.16130", "text_idx": 32}], "KARPUKHIN": [{"index": 108, "source_id": "arxiv:2404.16130", "text_idx": 22}], "LANGCHAIN": [{"index": 12, "source_id": "arxiv:2404.16130", "text_idx": 69}, {"index": 13, "source_id": "arxiv:2404.16130", "text_idx": 77}], "EXPERIMENT 1": [{"index": 67, "source_id": "arxiv:2404.16130", "text_idx": 11}, {"index": 83, "source_id": "arxiv:2404.16130", "text_idx": 0}, {"index": 86, "source_id": "arxiv:2404.16130", "text_idx": 73}], "TRIBUNE SPOTLIGHT": [{"index": 163, "source_id": "arxiv:2404.16130", "text_idx": 17}], "COMMUNITIES": [{"index": 9, "source_id": "arxiv:2404.16130", "text_idx": 66}], "GLOBAL": [{"index": 29, "source_id": "arxiv:2404.16130", "text_idx": 8}, {"index": 42, "source_id": "arxiv:2404.16130", "text_idx": 94}], "EXECUTIVES": [{"index": 140, "source_id": "arxiv:2404.16130", "text_idx": 14}], "KAU": [{"index": 114, "source_id": "arxiv:2404.16130", "text_idx": 2}], "LLAMAINDEX": [{"index": 12, "source_id": "arxiv:2404.16130", "text_idx": 69}, {"index": 13, "source_id": "arxiv:2404.16130", "text_idx": 77}, {"index": 109, "source_id": "arxiv:2404.16130", "text_idx": 95}]}, "commSummaries": {"0": {"title": "Community Knowledge Hub", "summary": "The Community Knowledge Hub is a structured ecosystem where user queries are processed through various stages of summarization and entity extraction to generate comprehensive community summaries, domain-tailored summaries, and ultimately, global answers for users.", "key_entities": ["GLOBAL ANSWER", "QUERY-FOCUSED SUMMARIZATION", "ENTITY EXTRACTOR", "COMMUNITY ANSWERS", "KNOWLEDGE GRAPH"], "key_insights": ["User queries drive the entire process from start to finish in this knowledge hub.", "Entity extraction is a critical step that informs multiple downstream processes including community detection and summarization.", "The Knowledge Graph integrates all processed information to provide a comprehensive understanding of the domain.", "Community answers are generated by combining summaries, ensuring each user receives relevant and tailored responses.", "Query-focused summarization ensures that only pertinent information reaches the final global answer."]}, "1": {"title": "GraphRAG and Related Technologies Community", "summary": "This community focuses on the advancements in GraphRAG, a graph-based approach for question answering, integrating large language models (LLMs) and various database technologies like NebulaGraph, LangChain, LlamaIndex, Neo4j, and GPT-4.", "key_entities": ["NEBULAGRAPH", "LANGCHAIN", "LLAMAINDEX", "GRAPHRAG", "NEO4J"], "key_insights": ["GraphRAG leverages LLMs to partition graphs into communities of closely related entities.", "NebulaGraph is a leader in launching an industry-first graph RAG technology with LLM integration.", "LangChain and LlamaIndex are key libraries supporting GraphRAG, integrating seamlessly with other technologies like Neo4j.", "Vector RAG is compared to GraphRAG, highlighting its direct response production capabilities.", "GraphRAG's framework includes methods for entity and relationship extraction, community-level summaries, and global sensemaking over entire corpora."]}, "2": {"title": "Contributor Community Network", "summary": "This community network comprises various contributors who have worked on a project, including individuals such as Amber Hoak, Andrés Morales Esquivel, Ben Cutler, Billie Rinaldi, Chris Sanchez, Chris Trevino, David Tittsworth, Dayenne de Souza, Douglas Orbaker, and Ed.", "key_entities": ["", "AMBER HOAK", "ANDR´ES MORALES ESQUIVEL", "BEN CUTLER", "BILLIE RINALDI"], "key_insights": ["The community consists of multiple individual contributors who have worked on a project together.", "Contributors include both first names (e.g., Amber, Andrés) and last names (e.g., Morales Esquivel).", "There are no specific claims or additional information provided about the nature of their contributions or the project itself.", "The community is diverse in terms of contributors' names and roles.", "All contributors identified are individuals who have contributed to a collective effort."]}, "3": {"title": "Knowledge Graph Extraction Community", "summary": "This community focuses on the advancements and applications of knowledge graph extraction techniques, with contributions from various organizations including OpenAI, Association for Computational Linguistics (ACL), and NAACL-HLT. Key insights include collaborations between researchers and industry leaders in this field.", "key_entities": ["NAACL-HLT", "OPENAI", "KAU", "MELNYK ET AL.", "TRAJANOSSKA ET AL."], "key_insights": ["OpenAI is mentioned alongside Tan et al. in the context of LLMs for knowledge graph extraction", "TAN ET AL. collaborated with multiple authors including Melnyk et al., Trajanoska et al., Yao et al., Zhang et al., and Tan et al. themselves", "The Association for Computational Linguistics (ACL) is involved in publishing proceedings of the NAACL-HLT conference and OpenAI's ChatGPT paper", "TAN ET AL.'s work intersects with multiple studies on RAG approaches using a knowledge graph as an index, conducted by Melnyk et al., Trajanoska et al., Yao et al., Zhang et al., and Tan et al. themselves"]}, "4": {"title": "Text Summarization and Stock Market Analysis Community", "summary": "This community focuses on the analysis of text summarization methods in relation to stock market data, with a particular emphasis on comprehensiveness and directness.", "key_entities": ["SS", "TS", "VECTOR RAG (SS)", "COMPREHENSIVENESS", "C3"], "key_insights": ["Directness has strong correlations with both Text Summarization (TS) and Standard Setting (SS).", "C0 is strongly related to TS and SS, indicating its significant impact in these areas.", "Comprehensiveness scores for global text summarization are higher than those for vector RAG (SS), suggesting better coverage of information.", "Vector RAG (SS) has lower comprehensiveness compared to source text summarization methods.", "P-value and Comprehensiveness are the first two columns in the given data, likely representing statistical significance and comprehensiveness scores respectively."]}, "5": {"title": "Graph Analysis Community Report", "summary": "This community focuses on the use of Graspologic library for graph analysis, with discussions spanning from experimental validation to claim-based measures. It integrates insights from multiple studies and experiments.", "key_entities": ["APPENDIX E", "CHUNG ET AL.", "EXPERIMENT 1", "APPENDIX F", "APPENDIX G"], "key_insights": ["Graspologic is utilized in both Chung et al. and Ni et al. papers for various analyses.", "Chung et al. discusses the use of Graspologic in Appendix E, F, and G sections.", "Experiment 1 validates comprehensiveness and diversity results using Graspologic.", "Experiment 2 implements claim-based measures with Graspologic.", "Ni et al. is referenced for defining claims related to these experiments."]}, "6": {"title": "Knowledge Graph Community Analysis", "summary": "This community focuses on academic papers and projects related to knowledge graphs, including their extraction, evaluation, and construction. It encompasses various publications and datasets.", "key_entities": ["ARXIV", "ETZIONI", "IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING", "KNOWITALL", "ELMAGRAMARD"], "key_insights": ["Elmagaramid et al. published in IEEE Transactions on Knowledge and Data Engineering and ArXiv.", "Knowitall is a project that involves multiple researchers including Etzioni, O., Cafarella, M., Downey, D., Kok, S., Popescu, A.-M., Shaked, T., Soderland, S., Weld, D. S., and Yates, A.", "The community includes papers on duplicate record detection and knowledge graph construction using large language models.", "Scientific Reports references ArXiv for a specific paper.", "Elmagaramid et al. are also associated with the Knowitall project."]}, "7": {"title": "Knowledge Graph Community Overview", "summary": "This community focuses on the integration of large language models with retrieval-augmented generation techniques to enhance query-focused summarization and answer questions over private document collections, leveraging external knowledge sources.", "key_entities": ["PRIVATE DOCUMENT COLLECTIONS", "PRIOR QFS METHODS", "EXTERNAL KNOWLEDGE SOURCE", "LARGE LANGUAGE MODELS", "QUERY-FOCUSED SUMMARIZATION (QFS)"], "key_insights": ["Large Language Models use prior QFS methods for text corpora summarization.", "Retrieval-Augmented Generation (RAG) is used by Large Language Models in query-focused summarization tasks.", "Larger Language Models can answer questions over private document collections.", "RAG retrieves relevant information from external knowledge sources to improve summarization and answering capabilities.", "Private Document Collections are accessed through the use of Retrieval-Augmented Generation techniques."]}, "8": {"title": "Example Corp Community Overview", "summary": "This community focuses on the activities and acquisitions of Example Corp, including its recent merger with StartupXYZ. Key figures such as John Smith, who is associated with Example Corp, are also part of this community.", "key_entities": ["EXAMPLE CORP", "STARTUPXYZ", "JOHN SMITH", "COMUNITY"], "key_insights": ["Example Corp has acquired StartupXYZ through a merger", "John Smith, CEO of Example Corp, announced the merger to the public", "The community includes contributions from individuals like John Smith", "Example Corp is an active participant in the community", "Community members are involved with both Example Corp and its recent acquisition"]}, "9": {"title": "Science and Medicine Knowledge Community", "summary": "This community focuses on the specialized knowledge domains of science, medicine, and law. It highlights the contributions made by an author named Brown who has written about in-context learning.", "key_entities": ["SCIENCE", "MEDICINE", "LAW", "BROWN"], "key_insights": ["The community centers around three main domains: Science, Medicine, and Law.", "An author named Brown is associated with all three domains through their work on 'In-context learning'.", "No specific claims are provided for this community."]}, "10": {"title": "Knowledge Graph Collaboration Network", "summary": "This community focuses on the collaboration between authors of a specific paper at a conference, highlighting relationships and contributions among researchers in artificial intelligence.", "key_entities": ["CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE", "GOALY", "KARPUKHIN", "PETRONI"], "key_insights": ["Three authors (Karpukhin, Petroni, Goaly) collaborated on a single paper titled 'Retrieval-augmented generation for knowledge-intensive nlp'.", "Goal is cited by the author of this paper at the Canadian Conference on Artificial Intelligence where papers were presented.", "The relationships between these authors indicate a collaborative network within the field of artificial intelligence research."]}, "11": {"title": "Unity March Community", "summary": "The Unity March Community is centered around Verdant Oasis Plaza, where the main event, the Unity March, takes place. Harmony Assembly organizes marches at this location and is closely associated with both the plaza and other community organizations.", "key_entities": ["VERDANT OASIS PLAZA", "UNITY MARCH", "HARMONY ASSEMBLY", "TRIBUNE SPOTLIGHT"], "key_insights": ["Verdant Oasis Plaza serves as a central hub for multiple events in the community.", "The Unity March is held annually at Verdant Oasis Plaza.", "Harmony Assembly regularly organizes marches at Verdant Oasis Plaza, indicating its importance to the organization.", "Tribune Spotlight is also associated with the Unity March and likely operates out of or near Verdant Oasis Plaza.", "Verdant Oasis Plaza's central location facilitates multiple community events."]}, "12": {"title": "Microsoft Research and Strategic Missions Community", "summary": "This community focuses on the organizational structure within Microsoft, highlighting the parent-child relationships between Microsoft Research and its strategic missions entities.", "key_entities": ["MICROSOFT OFFICE OF THE CTO", "MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES", "MICROSOFT RESEARCH"], "key_insights": ["Microsoft Research is a parent entity of Microsoft Strategic Missions and Technologies.", "Microsoft Strategic Missions and Technologies is a sub-entity of Microsoft Office of the CTO.", "Both entities are part of the larger Microsoft ecosystem, illustrating hierarchical organizational structures."]}, "13": {"title": "Transformer Models in Summarization Community", "summary": "This community focuses on authors and their contributions to papers related to query-focused abstractive summarization using transformer models, with a particular emphasis on the collaborative efforts among researchers.", "key_entities": ["HOQUE", "LASKAR", "HUANG"], "key_insights": ["HOQUE is the second author of multiple papers on query-focused abstractive summarization.", "LASKAR and HOQUE have collaborated on one paper.", "HUANG has contributed as a third author to one of the papers in this community.", "The community highlights the collaborative nature among researchers working on transformer models for text summarization.", "No claims or additional information are provided about these papers."]}, "14": {"title": "Community Detection Analysis Network", "summary": "This community focuses on the analysis and development of algorithms for detecting communities within networks, with contributions from key authors including Traag, Fortunato, and Jin.", "key_entities": ["TRAAG", "FORTUNATO", "JIN"], "key_insights": ["Traag introduced a Leiden community detection algorithm in his paper.", "Fortunato authored a survey covering various community detection methods.", "Jin et al. contributed to the field by citing Traag's work on community detection approaches.", "Traag and Jin have cited each other’s works, indicating significant influence within the network analysis community.", "The community is characterized by interdisciplinary contributions from different authors."]}, "15": {"title": "Authorship Network in AI Research", "summary": "This community focuses on the collaborative relationships between authors of papers in artificial intelligence research, highlighting the co-authorship network among Kosinski, Salminen et al., and Shin et al.", "key_entities": ["SALMINEN ET AL.", "SHIN ET AL.", "KOSINKSI"], "key_insights": ["Kosinski has collaborated with both Salminen et al. and Shin et al. in AI research", "The community represents a network of authors working together on multiple papers within the field of artificial intelligence", "This network structure provides insights into collaborative patterns and potential areas of overlap or specialization among researchers"]}, "16": {"title": "GraphRAG Validation Community", "summary": "This community focuses on evaluating RAG-generated answers using verifiable facts, ensuring the accuracy and reliability of AI-generated responses.", "key_entities": ["RAG GENERATED ANSWERS", "VERIFIABLE FACTS", "GLOBAL"], "key_insights": ["Global concepts are crucial for understanding and validating RAG-generated answers.", "Verifiable facts play a pivotal role in confirming the correctness of generated answers.", "The community emphasizes the importance of structured evaluation to enhance AI performance.", "Evaluating RAG-generated answers requires a comprehensive approach involving both global sensemaking and verifiable data validation.", "This collaborative environment aims to improve the overall quality and trustworthiness of AI-generated content."]}, "17": {"title": "NeoChip Community Overview", "summary": "The NeoChip community focuses on the publicly traded technology firm, NeoChip, which was acquired by Quantum Systems in 2016 and listed its shares on the NewTech Exchange. Key events include NeoChip's successful debut and surge in share prices.", "key_entities": ["QUANTUM SYSTEMS", "NEWTECH EXCHANGE", "NEOCHIP"], "key_insights": ["NeoChip is a low-power processor specialist for wearables and IoT devices.", "Quantum Systems acquired NeoChip in 2016, indicating significant interest in its technology.", "NeoChip went public during its first week of trading on the NewTech Exchange, marking a pivotal moment in its history.", "The company's shares experienced a notable increase shortly after their debut on the exchange.", "As part of Quantum Systems' portfolio, NeoChip continues to be an important asset within the firm."]}, "18": {"title": "Factual Claim Community", "summary": "This community focuses on the definition provided by Ni et al., with California and New York serving as examples of states implementing incentives for renewable energy adoption.", "key_entities": ["NI ET AL", "CALIFORNIA", "NEW YORK"], "key_insights": ["California and New York are used as examples in the definition of a factual claim provided by Ni et al.", "Ni et al. defined a factual claim using examples from these two U.S. states.", "The community highlights the role of California and New York in demonstrating how incentives for renewable energy adoption work."]}, "19": {"title": "ArXiv Preprint Collaboration Network", "summary": "This community focuses on the collaboration between authors A.Joshi and P.P.Ranade, as evidenced by their joint contribution to a preprint identified by ARXIV:202310.13848.", "key_entities": ["ARXIV:202310.13848", "A.JOSHI", "P.P.RANADE"], "key_insights": ["A.Joshi and P.P.Ranade are co-authors of the arXiv submission", "Both authors have contributed equally to the paper as indicated by their authorship on the preprint identifier", "The community represents a single collaborative effort between two individuals in the field of research"]}, "20": {"title": "Entity Extraction Community", "summary": "This community focuses on the process of identifying entities in text, utilizing prompts for both default graph extraction and claim extraction to facilitate this task.", "key_entities": ["DEFAULT GRAPH EXTRACTION PROMPT", "CLAIM EXTRACTION PROMPT", "ENTITY EXTRACTION"], "key_insights": ["Entity Extraction is a core component that identifies entities within texts using specific prompts.", "The Entity Extraction process relies on two main prompts: Default Graph Extraction Prompt and Claim Extraction Prompt.", "These prompts work together to enhance the accuracy of entity identification in various text-based scenarios.", "Understanding these relationships helps improve the efficiency and effectiveness of text analysis tools and systems.", "The community aims to advance knowledge graph creation by refining entity extraction techniques."]}, "21": {"title": "Entrepreneurial Controversies and Influences", "summary": "This community focuses on the intersection of public figures in controversy, entrepreneurs, and influencers, highlighting their frequent interactions and collaborations.", "key_entities": ["ENTREPRENEURS", "PUBLIC FIGURES IN CONTROVERSY", "INFLUENCERS"], "key_insights": ["Public figures in controversy frequently involve themselves with entrepreneurial activities or are associated with entrepreneurs.", "Influencers often collaborate with entrepreneurs for social media endorsements and collaborations.", "These entities form a network where controversies can intersect with business practices and influence."]}, "22": {"title": "Knowledge Graph Extraction Studies Community", "summary": "This community focuses on studies related to knowledge graph extraction, with key contributions from authors YATES ET AL. and MOONEY AND BUNESCU.", "key_entities": ["YATES ET AL.", "MOONEY AND BUNESCU"], "key_insights": ["YATES ET AL. and MOONEY AND BUNESCU are both recognized in the field of knowledge graph extraction.", "MOONEY AND BUNESCU's work is referenced by YATES ET AL., indicating their influence on the community.", "No specific claims or advancements were mentioned, focusing instead on authorship and references."]}, "23": {"title": "AI Ethics and Collaboration Community", "summary": "This community focuses on the ethical aspects of AI, particularly in collaboration between researchers ES and ZHENG. Their work explores context relevance, faithfulness, answer relevance, and LLM-as-a-judge method.", "key_entities": ["ES", "ZHENG"], "key_insights": ["ES and ZHENG have collaborated on multiple papers related to AI ethics.", "Their research covers different aspects of AI reliability and fairness.", "ZHENG's work builds upon ES' previous contributions in the field."]}, "24": {"title": "Podcast vs. News Articles Community", "summary": "This community focuses on the analysis and comparison between podcast content and news articles, highlighting that podcasts have a higher success rate in terms of engagement.", "key_entities": ["NEWS ARTICLES", "PODCAST"], "key_insights": ["Podcasts outperform news articles in terms of audience engagement.", "Transcripts of podcasts are more successful than written news articles.", "This community aims to provide insights into the effectiveness of different media formats."]}, "25": {"title": "Graph Index and RAG Approaches Community", "summary": "This community focuses on the integration of Graph Index technology with RAG (Graph Retrieval Augmented) approaches, highlighting how graph-based indexing services support advanced retrieval methods in knowledge graphs.", "key_entities": ["RAG APPROACHES", "GRAPH INDEX"], "key_insights": ["Graph Index is a core component of RAG Approaches within this community.", "The community emphasizes the importance of combining graph index technologies with RAG methodologies for enhanced data retrieval and analysis.", "Members explore ways to optimize and integrate Graph Index services into existing RAG frameworks for improved performance and efficiency."]}, "26": {"title": "Text Summarization and Vector RAG Community", "summary": "This community focuses on the evaluation of text summarization methods, specifically comparing a vector-based RAG approach to map-reduce source text summarization.", "key_entities": ["MAP-REDUCE SOURCE TEXT SUMMARIZATION", "VECTOR RAG BASELINE"], "key_insights": ["The community evaluates two text summarization products: MAP-REDUCE SOURCE TEXT SUMMARIZATION and VECTOR RAG BASELINE.", "VECTOR RAG BASELINE is compared against the MAP-REDUCE SOURCE TEXT SUMMARIZATION method in terms of effectiveness and efficiency.", "This evaluation aims to provide insights into which approach might be more suitable for different text summarization tasks.", "The community's work contributes to advancements in natural language processing (NLP) by comparing alternative methods.", "Understanding these comparisons can help researchers and practitioners choose the most appropriate method based on their specific needs."]}, "27": {"title": "Fernández and Alonso Guevara Collaboration Community", "summary": "This community focuses on the collaborative efforts between Fernández and Alonso Guevara, two contributors who have worked together on a project. Their partnership is highlighted by their status as co-authors.", "key_entities": ["FERN´ANDEZ", "ALONSO GUEVARA"], "key_insights": ["Fernández and Alonso Guevara are both active members of this community", "They have collaborated on a significant project together", "Their relationship is characterized by being co-authors"]}, "28": {"title": "Survey Research Community", "summary": "This community focuses on survey papers in various fields, connecting preprints from platforms like arXiv to their corresponding published surveys.", "key_entities": ["A SURVEY", "ARXIV:20231210997"], "key_insights": ["The community bridges the gap between preprint research and its final publication as a survey paper.", "It facilitates the tracking of academic contributions through the lifecycle of research papers.", "Members can follow how preprints evolve into comprehensive survey articles in different fields."]}, "29": {"title": "CIKM and IEEE Community", "summary": "This community focuses on the Conference on Information and Knowledge Management (CIKM) organized by IEEE, a leading organization in electrical engineering and information technology.", "key_entities": ["CIKM", "IEEE"], "key_insights": ["IEEE publishes CIKM as part of its conference series.", "CIKM is an important event for researchers and practitioners in information management and knowledge systems.", "The community highlights the collaboration between academic conferences and industry organizations."]}, "30": {"title": "Retrieval-augmented Generation Community", "summary": "This community focuses on the collaborative work between authors Perez and Lewis, who are both first authors of papers titled 'Retrieval-augmented generation for knowledge-intensive nlp'.", "key_entities": ["PEREZ", "LEWIS"], "key_insights": ["Perez and Lewis co-author a paper in the field of natural language processing (NLP).", "They collaborate on research related to retrieval-augmented generation techniques.", "Their work highlights advancements in handling knowledge-intensive tasks within NLP."]}, "31": {"title": "Language Model Diversity Research Community", "summary": "This community focuses on the impact of language models on content diversity, with contributions from Padmakumar and He Hong who co-authored a paper at ICLR in 2024.", "key_entities": ["HE HONG", "PADMAKUMAR"], "key_insights": ["Padmakumar and He Hong are co-authors of a joint research paper presented at ICLR in 2024.", "The community explores the effects of language models on content diversity, as evidenced by their collaborative work.", "No other claims or additional relationships are provided for this community."]}, "32": {"title": "Computational Linguistics Preprint Community", "summary": "This community focuses on computational linguistics research, highlighting preprints from arXiv that are referenced in journal articles. It serves as a bridge between cutting-edge research and academic publications.", "key_entities": ["ARXIV PREPRINT", "COMPUTATIONAL LINGUISTICS"], "key_insights": ["The community includes references to Computational Linguistics journal articles and their associated arXiv preprints.", "It represents the latest developments in computational linguistics through preprint submissions before peer review.", "This network connects researchers, academics, and students interested in the intersection of language studies and computer science."]}, "33": {"title": "Turbo Product Analysis Community", "summary": "This community focuses on the Turbo product, with discussions centered around a paper by Yang et al. (2018) that explores the Turbo model.", "key_entities": ["TURBO", "YANG ET AL"], "key_insights": ["The Turbo product is discussed in detail through the work of Yang et al. (2018)", "Yang et al.'s research provides insights into the functionality and performance of the Turbo model", "This community serves as a platform for analyzing and discussing advancements in the Turbo technology"]}, "34": {"title": "Leiden Algorithm Community", "summary": "This community focuses on the Leiden algorithm, a method for community detection in networks. It highlights the work of Traag et al., who developed the algorithm and its underlying principles.", "key_entities": ["TRAAG ET AL.", "LEEDEN ALGORITHM"], "key_insights": ["The Leiden algorithm is based on the research by Traag et al.", "It is used for identifying communities within complex network structures.", "Traag et al.'s contributions form the foundation upon which the algorithm was built."]}, "35": {"title": "MultiHop-RAG Community Analysis", "summary": "This community focuses on the MultiHop-RAG dataset, which is based on research by TANG AND YANG. It represents a collaborative effort in the field of community detection.", "key_entities": ["TANG AND YANG", "MULTIHOPE-RAG"], "key_insights": ["The MultiHop-RAG dataset relies on Tang and Yang's foundational work for its development.", "TANG AND YANG are recognized as key contributors to the benchmark dataset used in this community.", "Community detection is an area where this research has significant impact, with MultiHop-RAG being a central component."]}, "36": {"title": "Actors and Directors Community", "summary": "This community focuses on the collaborative relationship between actors and directors in the entertainment industry, highlighting their frequent interactions and roles.", "key_entities": ["DIRECTORS", "ACTORS"], "key_insights": ["Directors often lead projects that involve multiple actors.", "Actors frequently work under the direction of a Director to bring scenes to life.", "The community emphasizes the importance of collaboration between these two key roles."]}, "37": {"title": "Music Industry Executives and Musicians Community", "summary": "This community focuses on the collaborative relationships between musicians, who often work closely with executives in the music industry, highlighting their professional interactions and influence.", "key_entities": ["EXECUTIVES", "MUSICIANS"], "key_insights": ["Executives frequently collaborate with musicians to shape musical projects and careers.", "Musicians and executives share common interests and responsibilities within the music industry.", "The community emphasizes the importance of mutual support and collaboration between these two groups."]}, "38": {"title": "Athlete-Coach Community", "summary": "This community focuses on the relationship between athletes and their coaches, highlighting how athletes benefit from coaching to enhance their sports careers.", "key_entities": ["COACHES", "ATHLETES"], "key_insights": ["Athletes frequently seek out coaches for career development in sports.", "Coaches play a crucial role in guiding athletes towards success in their respective fields.", "The community emphasizes the importance of mentorship and support within the athletic sphere."]}, "39": {"title": "Federal Reserve Committee Insights", "summary": "This community focuses on the Federal Open Market Committee and its chair, Jerome Powell. It covers key decisions related to interest rates and money supply.", "key_entities": ["JEROME POWELL", "FEDERAL OPEN MARKET COMMITTEE"], "key_insights": ["Jerome Powell is the current Chair of the Federal Reserve Committee.", "The committee makes important decisions about U.S. monetary policy.", "Interest rate changes are a central focus of the FOMC's activities."]}}, "semanticGroups": {"2": {"canonical": "ALONSO GUEVARA", "members": ["ALONSO GUEVARA", "FERN´ANDEZ", "AMBER HOAK", "ANDR´ES MORALES ESQUIVEL", "BEN CUTLER", "BILLIE RINALDI", "CHRIS SANCHEZ", "CHRIS TREVIÑO", "DAVID TITTWORTH", "DAYENNE DE SOUZA", "DOUGLAS ORBAKER", "ED"], "member_similarities": {"FERN´ANDEZ": 0.9985, "AMBER HOAK": 1.0, "ANDR´ES MORALES ESQUIVEL": 0.9994, "BEN CUTLER": 1.0, "BILLIE RINALDI": 1.0, "CHRIS SANCHEZ": 1.0, "CHRIS TREVIÑO": 1.0, "CHRISTINE CAGGA": 1.0, "DAVID TITTWORTH": 1.0, "DAYENNE DE SOUZA": 0.9994, "DOUGLAS ORBAKER": 1.0, "ED": 0.9985}}, "3": {"canonical": "BAUMEL", "members": ["LASKAR", "HOQUE", "HUANG"], "member_similarities": {"DANG": 0.8962, "LASKAR": 0.8841, "YAO": 0.9228, "M. EYAL": 0.9114, "M. ELHADAD": 0.9114, "HOQUE": 0.7942, "HUANG": 0.7942, "XU": 0.8343, "LAPATA": 0.8343, "WAN": 0.8451, "XIAO": 0.8451}}, "4": {"canonical": "W.-T.", "members": ["LEWIS", "PEREZ", "PETRONI", "KARPUKHIN", "GOALY"], "member_similarities": {"LEWIS": 0.9867, "PEREZ": 0.9867, "PIKTUS": 0.9867, "PETRONI": 0.9867, "KARPUKHIN": 0.9867, "GOALY": 0.9867, "KUTTLER": 0.9867, "YIH": 0.9867, "ROCKTASCHEL": 0.9867, "ROKTASCHEL, T.": 0.9977}}, "12": {"canonical": "KNOWITALL", "members": ["MICROSOFT RESEARCH", "MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES", "MICROSOFT OFFICE OF THE CTO", "KNOWITALL"], "member_similarities": {"MICROSOFT RESEARCH": 0.8592, "MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES": 0.852, "MICROSOFT OFFICE OF THE CTO": 0.852}}, "14": {"canonical": "QUANTUM SYSTEMS", "members": ["EXAMPLE CORP", "QUANTUM SYSTEMS", "STARTUPXYZ"], "member_similarities": {"EXAMPLE CORP": 0.7931, "NEOCIP": 0.8816, "STARTUPXYZ": 0.8707}}, "19": {"canonical": "MEDICINE", "members": ["SCIENCE", "MEDICINE", "LAW"], "member_similarities": {"SCIENCE": 0.922, "LAW": 0.8511}}, "26": {"canonical": "LLAMAINDEX", "members": ["LANGCHAIN", "LLAMAINDEX"], "member_similarities": {"LANGCHAIN": 0.9569}}, "28": {"canonical": "ENTITY EXTRACTOR", "members": ["ENTITY EXTRACTOR", "ENTITY EXTRACTION"], "member_similarities": {"ENTITY EXTRACTION": 0.8788}}, "30": {"canonical": "TS", "members": ["TS", "MAP-REDUCE SOURCE TEXT SUMMARIZATION"], "member_similarities": {"MAP-REDUCE SOURCE TEXT SUMMARIZATION": 0.9031}}, "31": {"canonical": "CALIFORNIA", "members": ["CALIFORNIA", "NEW YORK"], "member_similarities": {"NEW YORK": 0.9981}}, "33": {"canonical": "PODCAST", "members": ["PODCAST", "NEWS ARTICLES"], "member_similarities": {"NEWS ARTICLES": 0.9982}}, "34": {"canonical": "C0", "members": ["C3", "C0"], "member_similarities": {"C3": 0.8798}}, "35": {"canonical": "C1", "members": ["C1", "C2"], "member_similarities": {"C2": 1.0}}, "38": {"canonical": "IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING", "members": ["ELMAGRAMARD", "IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING"], "member_similarities": {"ELMAGRAMARD": 0.9438}}, "41": {"canonical": "PADMAKUMAR", "members": ["PADMAKUMAR", "HE HONG"], "member_similarities": {"HE HONG": 0.9988}}, "42": {"canonical": "ARXIV PREPRINT", "members": ["ARXIV PREPRINT", "ARXIV:202310.13848"], "member_similarities": {"ARXIV:202310.13848": 0.8832}}, "43": {"canonical": "DEFAULT GRAPH EXTRACTION PROMPT", "members": ["DEFAULT GRAPH EXTRACTION PROMPT", "CLAIM EXTRACTION PROMPT"], "member_similarities": {"CLAIM EXTRACTION PROMPT": 0.9993}}, "44": {"canonical": "VERDANT OASIS PLAZA", "members": ["VERDANT OASIS PLAZA", "HARMONY ASSEMBLY"], "member_similarities": {"HARMONY ASSEMBLY": 0.877}}}}